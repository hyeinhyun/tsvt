{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Mul_data(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.d_type=d_type\n",
    "        if d_type=='train':\n",
    "            with open('../../data/chat_feature_train.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        if d_type=='val':\n",
    "            with open('../../data/chat_feature_val.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        if d_type=='test':\n",
    "            with open('../../data/chat_feature_test.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        \n",
    "        with open('../../data/video_statistic_features_one2.pickle',\"rb\") as f2:  \n",
    "            self.image_result=pickle.load(f2)\n",
    "        with open('../../data/audio_entropy_emd.pickle',\"rb\") as f3:  \n",
    "            self.audio_result=pickle.load(f3)\n",
    "        with open('../../label/label.pickle',\"rb\") as f4:  \n",
    "            self.real_result=pickle.load(f4)\n",
    "            \n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "            \n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.real_result[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "        \n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[pos_idx] = len(sampling) / float(len(pos_idx))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        \n",
    "        self.sum=np.insert(np.cumsum([len(self.chat_result[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.WeightedSampling)\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)#sum으로 누적으로 히스토그램이 깔려있음/ 그중에 index의 위치\n",
    "            vid = np.where(vid[0]>0)[0][0]#몇번째 game을 쓸지!\n",
    "            vframe=index-self.sum[vid]#그 게임 안에서의 몇번째 프레임인지\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "            window=[]#batch*7(window size)*3(highlight result)\n",
    "            for idx in range(23): #7 : window size\n",
    "                s_window=[]\n",
    "                if vframe+idx<len(self.chat_result[game_id]):\n",
    "#                     s_window+=((self.chat_result[game_id][vframe+idx]))#vframe의 chat\n",
    "                    s_window+=list(self.audio_result[game_id][(vframe+idx)*10:(vframe+idx+1)*10])#vframe의 audio\n",
    "                    s_window+=[(self.image_result[game_id][vframe+idx])]#vframe의 image\n",
    "                else:\n",
    "                    #s_window=[0,0,0]#padding value\n",
    "                    s_window=[0]*11\n",
    "                window.append(s_window)\n",
    "\n",
    "\n",
    "            label=int(self.real_result[game_id][vframe])\n",
    "            return game_id,np.array(window),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n",
      "('102844412722519367', array([[ 5.28188175e-04, -2.60772944e-03, -6.42303089e-03,\n",
      "         5.93419674e-03,  4.28576542e-03,  3.60430944e-03,\n",
      "         1.76061821e-03, -3.37451883e-03,  3.59619475e-03,\n",
      "        -4.46354486e-03,  1.37379766e-03],\n",
      "       [-7.07925046e-04,  7.65639497e-03,  6.60309501e-03,\n",
      "        -1.16132757e-03, -1.27804309e-02,  1.37522797e-02,\n",
      "         8.39392149e-03, -6.83272836e-03, -1.36067919e-02,\n",
      "        -1.21897105e-02,  1.37379766e-03],\n",
      "       [-4.37973586e-03,  4.64145782e-03,  9.35147676e-03,\n",
      "         5.34418137e-03, -7.14635322e-03,  6.27936901e-03,\n",
      "        -3.65286729e-03, -5.03458177e-03, -1.22952435e-03,\n",
      "         4.21928000e-03,  2.00727582e-03],\n",
      "       [-3.91807628e-03,  1.14446836e-04,  2.56711422e-03,\n",
      "         3.25942224e-03,  3.36269885e-03,  2.55329375e-03,\n",
      "        -7.16273585e-04, -2.33919975e-03, -3.58056417e-03,\n",
      "        -4.01098511e-03,  7.20083714e-04],\n",
      "       [-3.39250482e-03, -2.00500236e-03, -2.74149209e-04,\n",
      "         4.72357848e-03,  5.07543970e-03,  3.71025593e-03,\n",
      "         3.41664693e-04, -5.09067939e-03,  4.88455945e-03,\n",
      "        -1.14203449e-03,  3.80885601e-03],\n",
      "       [-2.39559435e-03, -3.69146180e-03, -3.37477552e-03,\n",
      "        -2.20285360e-03, -1.32210414e-03, -4.63081620e-04,\n",
      "         1.04397308e-03,  1.38730609e-03, -1.38723330e-03,\n",
      "         1.56174938e-03,  4.09334898e-04],\n",
      "       [ 5.07390880e-04, -7.30353701e-04, -2.15705374e-03,\n",
      "        -3.47361594e-03, -4.54562873e-03, -5.30290651e-03,\n",
      "        -5.67526365e-03, -5.60793821e-03, -5.10786286e-03,\n",
      "        -4.11893504e-03,  3.73959541e-04],\n",
      "       [-2.27121654e-03,  5.62122428e-03,  7.77055324e-03,\n",
      "        -7.48618644e-03,  6.93010758e-03,  3.48522549e-03,\n",
      "        -1.61182481e-03, -3.92860258e-03,  2.76811728e-03,\n",
      "        -1.73017474e-03,  6.80625439e-04],\n",
      "       [ 3.74208275e-04,  3.01788836e-04,  1.68978452e-04,\n",
      "        -7.46920649e-05, -4.41208813e-04, -9.52894694e-04,\n",
      "        -1.61395646e-03, -2.34891049e-03, -3.10399788e-03,\n",
      "        -3.83656569e-03,  2.94536352e-04],\n",
      "       [-4.50396097e-03, -5.06353077e-03, -5.47334183e-03,\n",
      "        -5.69433968e-03, -5.68207976e-03, -5.37954820e-03,\n",
      "        -4.77110033e-03, -3.85296123e-03, -2.62135598e-03,\n",
      "        -1.07250968e-03,  0.00000000e+00],\n",
      "       [ 7.97352609e-04,  2.96538559e-03,  5.29018661e-03,\n",
      "         7.53657457e-03,  9.36271912e-03,  1.03151764e-02,\n",
      "         9.82827535e-03,  7.20563312e-03,  1.72221457e-03,\n",
      "        -7.34701541e-03,  5.33461571e-06],\n",
      "       [ 6.12174167e-03,  3.05518690e-03, -3.52264645e-03,\n",
      "         1.33140232e-03,  1.47395457e-03,  1.26729361e-03,\n",
      "         1.00023712e-03,  4.69992536e-04,  4.39817206e-04,\n",
      "         3.88070432e-04,  0.00000000e+00],\n",
      "       [ 3.54836849e-04,  3.09032043e-04,  2.41289048e-04,\n",
      "         1.55750989e-04,  6.72900282e-05, -2.02300948e-05,\n",
      "        -1.05245291e-04, -1.80702240e-04, -2.43445324e-04,\n",
      "        -2.90021686e-04,  4.89267707e-03],\n",
      "       [-3.11626809e-04, -3.03715786e-04, -2.62295611e-04,\n",
      "        -1.79925014e-04, -5.19236337e-05,  1.06869829e-04,\n",
      "         2.45453289e-04,  3.18646373e-04,  2.83089791e-04,\n",
      "         9.50955470e-05,  7.03334808e-06],\n",
      "       [-2.96576111e-04,  2.89902241e-04, -1.59940908e-04,\n",
      "        -4.61157288e-04, -5.84877613e-04, -7.99355977e-04,\n",
      "        -6.71304230e-04,  1.56519432e-03,  2.50526421e-03,\n",
      "         2.34027034e-03,  8.92013311e-04],\n",
      "       [ 1.23582783e-03, -5.60777691e-04, -2.83145047e-03,\n",
      "        -5.45190938e-03, -8.14636380e-03, -1.02603999e-02,\n",
      "        -1.09711102e-02, -9.24509253e-03, -4.51178962e-03,\n",
      "         3.24669064e-03,  8.09907913e-04],\n",
      "       [ 1.38109557e-02, -1.40322732e-02, -3.51925932e-03,\n",
      "         6.07114843e-03,  1.36457395e-02,  4.28221978e-03,\n",
      "        -1.30453238e-02, -1.77277307e-03,  1.55371481e-03,\n",
      "         4.31158317e-03,  1.13731623e-03],\n",
      "       [ 7.55154967e-03,  9.91070086e-03,  1.12249968e-02,\n",
      "         1.14516278e-02,  9.04459127e-03,  7.58892718e-03,\n",
      "         5.60599300e-03,  3.30682238e-03,  9.02448943e-04,\n",
      "        -3.22881523e-03,  1.30513310e-03],\n",
      "       [-7.48638554e-03, -9.12429845e-03, -9.81426341e-03,\n",
      "        -9.40859664e-03, -7.59157325e-03, -4.19017245e-03,\n",
      "         8.08958068e-04,  7.37420837e-03, -6.62082700e-03,\n",
      "         5.20497032e-04,  6.25550747e-05],\n",
      "       [ 4.91290451e-03, -7.98816541e-04, -3.28951022e-03,\n",
      "        -3.61331751e-04,  2.26498106e-03, -2.12626837e-03,\n",
      "        -7.87865549e-04,  7.18950761e-04,  1.75382103e-03,\n",
      "         2.16824577e-03,  1.55270100e-04],\n",
      "       [-3.91262256e-03, -4.07867583e-03, -3.29305914e-03,\n",
      "        -1.60001097e-03,  5.39453366e-04,  3.77992934e-03,\n",
      "        -3.62878556e-03, -4.22192635e-04,  1.91354366e-03,\n",
      "         3.05473938e-03,  0.00000000e+00],\n",
      "       [ 2.96205695e-03,  1.39927160e-03, -7.67016360e-05,\n",
      "        -1.28431705e-03, -1.65542089e-03, -9.15075103e-04,\n",
      "         8.69473287e-04,  6.71383702e-04, -1.62371441e-04,\n",
      "         4.06735896e-05,  1.43289566e-04],\n",
      "       [-3.40722056e-04, -8.17943366e-04, -1.18640977e-03,\n",
      "        -2.85184532e-03,  2.14640616e-03,  7.17953646e-03,\n",
      "         8.63974387e-03,  5.35640891e-03, -2.38230451e-03,\n",
      "        -1.40516128e-02,  0.00000000e+00]]), 0)\n"
     ]
    }
   ],
   "source": [
    "train=Mul_data('train')\n",
    "val=Mul_data('val')\n",
    "print(train[100])\n",
    "sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=44000)\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=32,sampler=sampler1)\n",
    "# train_loader=torch.utils.data.DataLoader(train,batch_size=32)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=11\n",
    "hidden_size=23\n",
    "length=7\n",
    "num_layers=3\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._clf1 = nn.LSTM(input_size, hidden_size,3,batch_first=True)\n",
    "        self._lin = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                 nn.Linear(hidden_size,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.cuda()\n",
    "        hidden = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).cuda() # (num_layers * num_directions, batch, hidden_size)\n",
    "        cell = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).cuda() # (num_layers * num_directions, batch, hidden_size)        out,hidden = self._clf1(x,h0)\n",
    "        feature,hidden = self._clf1(x,(hidden,cell))#batch*7*3\n",
    "        out = self._lin(feature[:,-1,:])\n",
    "        return feature[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=LSTM().cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01,momentum=0.9,weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0 train_loss : 0 , val_loss : 0.7171695232391357,p 0, r 0, f 0\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0 , val_loss : 0.6672632098197937,p 0, r 0, f 0\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0 , val_loss : 0.3891659080982208,p 0.5873655913978495, r 0.6752759381898454, f 0.6282604230848223\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0 , val_loss : 0.4389633536338806,p 0.5298804780876494, r 0.704635761589404, f 0.6048891415577031\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0 , val_loss : 0.47662296891212463,p 0.5219376936878161, r 0.7064017660044151, f 0.6003189194259452\n",
      "\n",
      "5\n",
      "epoch 5 train_loss : 0 , val_loss : 0.4261067509651184,p 0.5566205182818601, r 0.6922737306843267, f 0.6170798898071626\n",
      "\n",
      "6\n",
      "epoch 6 train_loss : 0 , val_loss : 0.4146990478038788,p 0.5486910994764398, r 0.6940397350993377, f 0.6128654970760234\n",
      "\n",
      "7\n",
      "epoch 7 train_loss : 0 , val_loss : 0.4289664924144745,p 0.5339039946290701, r 0.7022075055187638, f 0.606598016781083\n",
      "\n",
      "8\n",
      "epoch 8 train_loss : 0 , val_loss : 0.3833683729171753,p 0.5946999220576773, r 0.6737306843267108, f 0.6317532601945768\n",
      "\n",
      "9\n",
      "epoch 9 train_loss : 0 , val_loss : 0.402784138917923,p 0.5565418072075271, r 0.6920529801324503, f 0.6169438158024205\n",
      "\n",
      "10\n",
      "epoch 10 train_loss : 0 , val_loss : 0.42513179779052734,p 0.544687446185638, r 0.698233995584989, f 0.6119763954725742\n",
      "\n",
      "11\n",
      "epoch 11 train_loss : 0 , val_loss : 0.43891921639442444,p 0.5455958549222798, r 0.6973509933774834, f 0.6122093023255815\n",
      "\n",
      "12\n",
      "epoch 12 train_loss : 0 , val_loss : 0.3938923478126526,p 0.5867863280504105, r 0.6783664459161148, f 0.6292617999385687\n",
      "\n",
      "13\n",
      "epoch 13 train_loss : 0 , val_loss : 0.3905138075351715,p 0.5944260378093938, r 0.673289183222958, f 0.6314046164993272\n",
      "\n",
      "14\n",
      "epoch 14 train_loss : 0 , val_loss : 0.4142276346683502,p 0.5682481751824817, r 0.6874172185430464, f 0.6221778221778221\n",
      "\n",
      "15\n",
      "epoch 15 train_loss : 0 , val_loss : 0.4157264530658722,p 0.5684844063468903, r 0.6880794701986755, f 0.6225906321781685\n",
      "\n",
      "16\n",
      "epoch 16 train_loss : 0 , val_loss : 0.39733976125717163,p 0.5743268166728145, r 0.6874172185430464, f 0.6258038585209004\n",
      "\n",
      "17\n",
      "epoch 17 train_loss : 0 , val_loss : 0.4107063114643097,p 0.5740226051510098, r 0.6838852097130242, f 0.6241563412914274\n",
      "\n",
      "18\n",
      "epoch 18 train_loss : 0 , val_loss : 0.4276394844055176,p 0.5608144311484193, r 0.6931567328918322, f 0.6200019745285813\n",
      "\n",
      "19\n",
      "epoch 19 train_loss : 0 , val_loss : 0.4294760227203369,p 0.5285359801488834, r 0.7052980132450332, f 0.604255319148936\n",
      "\n",
      "20\n",
      "epoch 20 train_loss : 0 , val_loss : 0.4343993663787842,p 0.5416951469583049, r 0.6997792494481236, f 0.6106723174725487\n",
      "\n",
      "21\n",
      "epoch 21 train_loss : 0 , val_loss : 0.40315476059913635,p 0.5967584456160906, r 0.6746136865342164, f 0.633302248471661\n",
      "\n",
      "22\n",
      "epoch 22 train_loss : 0 , val_loss : 0.41956213116645813,p 0.5597081331197722, r 0.6942604856512141, f 0.6197654941373534\n",
      "\n",
      "23\n",
      "epoch 23 train_loss : 0 , val_loss : 0.42268699407577515,p 0.5250655307994757, r 0.7075055187637969, f 0.6027835245439156\n",
      "\n",
      "24\n",
      "epoch 24 train_loss : 0 , val_loss : 0.41749584674835205,p 0.5508784136371543, r 0.6991169977924945, f 0.6162078023154003\n",
      "\n",
      "25\n",
      "epoch 25 train_loss : 0 , val_loss : 0.4148724377155304,p 0.5468642315644383, r 0.7006622516556291, f 0.6142829494871299\n",
      "\n",
      "26\n",
      "epoch 26 train_loss : 0 , val_loss : 0.4239657521247864,p 0.559871703492516, r 0.693598233995585, f 0.6196016564780122\n",
      "\n",
      "27\n",
      "epoch 27 train_loss : 0 , val_loss : 0.41277700662612915,p 0.553740779768177, r 0.6960264900662252, f 0.6167840375586855\n",
      "\n",
      "28\n",
      "epoch 28 train_loss : 0 , val_loss : 0.3898296654224396,p 0.5761089637401068, r 0.6909492273730684, f 0.6283248017665363\n",
      "\n",
      "29\n",
      "epoch 29 train_loss : 0 , val_loss : 0.40882211923599243,p 0.5518802228412256, r 0.6997792494481236, f 0.6170916877554993\n",
      "\n",
      "30\n",
      "epoch 30 train_loss : 0 , val_loss : 0.4243525266647339,p 0.5491040661612681, r 0.7035320088300221, f 0.6167989161989549\n",
      "\n",
      "31\n",
      "epoch 31 train_loss : 0 , val_loss : 0.4248088300228119,p 0.5259719046063378, r 0.7108167770419426, f 0.604581299286519\n",
      "\n",
      "32\n",
      "epoch 32 train_loss : 0 , val_loss : 0.41186124086380005,p 0.611735841341239, r 0.6604856512141281, f 0.6351767328309096\n",
      "\n",
      "33\n",
      "epoch 33 train_loss : 0 , val_loss : 0.41789793968200684,p 0.5485428522158993, r 0.7022075055187638, f 0.6159357149772484\n",
      "\n",
      "34\n",
      "epoch 34 train_loss : 0 , val_loss : 0.4052921235561371,p 0.5759249033683048, r 0.6907284768211921, f 0.628124059018368\n",
      "\n",
      "35\n",
      "epoch 35 train_loss : 0 , val_loss : 0.39090704917907715,p 0.5800481214140293, r 0.691832229580574, f 0.6310278868418403\n",
      "\n",
      "36\n",
      "epoch 36 train_loss : 0 , val_loss : 0.3732529878616333,p 0.6187080536912751, r 0.6512141280353201, f 0.6345450634545062\n",
      "\n",
      "37\n",
      "epoch 37 train_loss : 0 , val_loss : 0.47412538528442383,p 0.5133259738211639, r 0.7185430463576159, f 0.5988409529942048\n",
      "\n",
      "38\n",
      "epoch 38 train_loss : 0 , val_loss : 0.3981434404850006,p 0.5806213017751479, r 0.6931567328918322, f 0.6319178909237272\n",
      "\n",
      "39\n",
      "epoch 39 train_loss : 0 , val_loss : 0.4440637528896332,p 0.5618929895814939, r 0.7024282560706402, f 0.6243500441479447\n",
      "\n",
      "40\n",
      "epoch 40 train_loss : 0 , val_loss : 0.4283163845539093,p 0.5417227456258412, r 0.7108167770419426, f 0.6148558334924575\n",
      "\n",
      "41\n",
      "epoch 41 train_loss : 0 , val_loss : 0.42275306582450867,p 0.556195462478185, r 0.7035320088300221, f 0.6212475633528266\n",
      "\n",
      "42\n",
      "epoch 42 train_loss : 0 , val_loss : 0.38174083828926086,p 0.5879235282983154, r 0.6856512141280353, f 0.6330378069907266\n",
      "\n",
      "43\n",
      "epoch 43 train_loss : 0 , val_loss : 0.4312802255153656,p 0.5424528301886793, r 0.7108167770419426, f 0.6153258169310147\n",
      "\n",
      "44\n",
      "epoch 44 train_loss : 0 , val_loss : 0.38818442821502686,p 0.5849877103422197, r 0.6830022075055188, f 0.6302067420307568\n",
      "\n",
      "45\n",
      "epoch 45 train_loss : 0 , val_loss : 0.39197567105293274,p 0.5721005970689343, r 0.6980132450331126, f 0.6288157502237247\n",
      "\n",
      "46\n",
      "epoch 46 train_loss : 0 , val_loss : 0.38341841101646423,p 0.6022209002577831, r 0.6704194260485651, f 0.6344928444583725\n",
      "\n",
      "47\n",
      "epoch 47 train_loss : 0 , val_loss : 0.3900129199028015,p 0.5723684210526315, r 0.6913907284768211, f 0.6262747450509898\n",
      "\n",
      "48\n",
      "epoch 48 train_loss : 0 , val_loss : 0.3998192250728607,p 0.5583871530808169, r 0.7061810154525386, f 0.6236475289989278\n",
      "\n",
      "49\n",
      "epoch 49 train_loss : 0 , val_loss : 0.3990620970726013,p 0.5660142348754449, r 0.7022075055187638, f 0.6267980295566503\n",
      "\n",
      "50\n",
      "epoch 50 train_loss : 0 , val_loss : 0.3716948330402374,p 0.6073194856577646, r 0.6777041942604857, f 0.640584246218049\n",
      "\n",
      "51\n",
      "epoch 51 train_loss : 0 , val_loss : 0.42196252942085266,p 0.5569155446756426, r 0.7030905077262694, f 0.6215240511269393\n",
      "\n",
      "52\n",
      "epoch 52 train_loss : 0 , val_loss : 0.3774108290672302,p 0.6159903089036948, r 0.6735099337748345, f 0.6434672571970896\n",
      "\n",
      "53\n",
      "epoch 53 train_loss : 0 , val_loss : 0.3817214369773865,p 0.5961685823754789, r 0.6869757174392936, f 0.6383589743589743\n",
      "\n",
      "54\n",
      "epoch 54 train_loss : 0 , val_loss : 0.41426292061805725,p 0.5494618144541261, r 0.7099337748344371, f 0.6194741404218435\n",
      "\n",
      "55\n",
      "epoch 55 train_loss : 0 , val_loss : 0.41834768652915955,p 0.5346420323325635, r 0.7154525386313466, f 0.6119712990936554\n",
      "\n",
      "56\n",
      "epoch 56 train_loss : 0 , val_loss : 0.41029566526412964,p 0.5545783755819969, r 0.7099337748344371, f 0.6227127505082777\n",
      "\n",
      "57\n",
      "epoch 57 train_loss : 0 , val_loss : 0.4023512005805969,p 0.5580264072272412, r 0.7090507726269316, f 0.6245382072720201\n",
      "\n",
      "58\n",
      "epoch 58 train_loss : 0 , val_loss : 0.3941103518009186,p 0.5902503293807642, r 0.6922737306843267, f 0.6372041044397033\n",
      "\n",
      "59\n",
      "epoch 59 train_loss : 0 , val_loss : 0.41466447710990906,p 0.5651101321585903, r 0.7079470198675497, f 0.6285154336109751\n",
      "\n",
      "60\n",
      "epoch 60 train_loss : 0 , val_loss : 0.401479572057724,p 0.5766544117647059, r 0.692494481236203, f 0.6292878635907723\n",
      "\n",
      "61\n",
      "epoch 61 train_loss : 0 , val_loss : 0.4152224659919739,p 0.5552285318559557, r 0.7079470198675497, f 0.6223559091791189\n",
      "\n",
      "62\n",
      "epoch 62 train_loss : 0 , val_loss : 0.4251921772956848,p 0.5597429663077458, r 0.7114790286975717, f 0.6265552099533438\n",
      "\n",
      "63\n",
      "epoch 63 train_loss : 0 , val_loss : 0.3932138979434967,p 0.5641432856890771, r 0.7057395143487859, f 0.6270471707364911\n",
      "\n",
      "64\n",
      "epoch 64 train_loss : 0 , val_loss : 0.37727364897727966,p 0.5735267452402538, r 0.698233995584989, f 0.6297660527625684\n",
      "\n",
      "65\n",
      "epoch 65 train_loss : 0 , val_loss : 0.4167026877403259,p 0.540281973816717, r 0.7105960264900663, f 0.6138443935926774\n",
      "\n",
      "66\n",
      "epoch 66 train_loss : 0 , val_loss : 0.3961165249347687,p 0.5777411074440777, r 0.6955849889624725, f 0.6312099358974359\n",
      "\n",
      "67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67 train_loss : 0 , val_loss : 0.4082333743572235,p 0.5731729215298976, r 0.704635761589404, f 0.6321417962174473\n",
      "\n",
      "68\n",
      "epoch 68 train_loss : 0 , val_loss : 0.4222363531589508,p 0.5599512025095852, r 0.7092715231788079, f 0.6258278145695364\n",
      "\n",
      "69\n",
      "epoch 69 train_loss : 0 , val_loss : 0.40574729442596436,p 0.5658545197740112, r 0.7075055187637969, f 0.6288012556405729\n",
      "\n",
      "70\n",
      "epoch 70 train_loss : 0 , val_loss : 0.41614577174186707,p 0.5487057220708447, r 0.7112582781456953, f 0.6194962507210152\n",
      "\n",
      "71\n",
      "epoch 71 train_loss : 0 , val_loss : 0.42086029052734375,p 0.5515710382513661, r 0.7130242825607064, f 0.6219911419218179\n",
      "\n",
      "72\n",
      "epoch 72 train_loss : 0 , val_loss : 0.4442111849784851,p 0.529985372988786, r 0.7198675496688741, f 0.6105026677899467\n",
      "\n",
      "73\n",
      "epoch 73 train_loss : 0 , val_loss : 0.4304145276546478,p 0.5542896599344036, r 0.7088300220750552, f 0.6221059769446866\n",
      "\n",
      "74\n",
      "epoch 74 train_loss : 0 , val_loss : 0.40246862173080444,p 0.5507839127471029, r 0.7134657836644591, f 0.6216580111559915\n",
      "\n",
      "75\n",
      "epoch 75 train_loss : 0 , val_loss : 0.4155295193195343,p 0.5527397260273973, r 0.7125827814569536, f 0.6225650916104147\n",
      "\n",
      "76\n",
      "epoch 76 train_loss : 0 , val_loss : 0.3817783296108246,p 0.5926484448633365, r 0.6940397350993377, f 0.6393492628368073\n",
      "\n",
      "77\n",
      "epoch 77 train_loss : 0 , val_loss : 0.41619691252708435,p 0.5488632507634883, r 0.7141280353200883, f 0.6206830391404451\n",
      "\n",
      "78\n",
      "epoch 78 train_loss : 0 , val_loss : 0.4149203896522522,p 0.5742877749729535, r 0.7030905077262694, f 0.6321953156014292\n",
      "\n",
      "79\n",
      "epoch 79 train_loss : 0 , val_loss : 0.4091635048389435,p 0.566114245416079, r 0.7088300220750552, f 0.6294844148206233\n",
      "\n",
      "80\n",
      "epoch 80 train_loss : 0 , val_loss : 0.4011475443840027,p 0.5510204081632653, r 0.7092715231788079, f 0.6202104044011195\n",
      "\n",
      "81\n",
      "epoch 81 train_loss : 0 , val_loss : 0.3941259980201721,p 0.5818981311835837, r 0.7011037527593819, f 0.6359631557869443\n",
      "\n",
      "82\n",
      "epoch 82 train_loss : 0 , val_loss : 0.42548516392707825,p 0.5469912102772143, r 0.7143487858719647, f 0.6195672984874592\n",
      "\n",
      "83\n",
      "epoch 83 train_loss : 0 , val_loss : 0.43412068486213684,p 0.5185361216730038, r 0.7225165562913908, f 0.6037631433314886\n",
      "\n",
      "84\n",
      "epoch 84 train_loss : 0 , val_loss : 0.39778968691825867,p 0.5678026269080583, r 0.7061810154525386, f 0.6294765840220385\n",
      "\n",
      "85\n",
      "epoch 85 train_loss : 0 , val_loss : 0.3869897723197937,p 0.575189325640101, r 0.7041942604856513, f 0.6331877729257642\n",
      "\n",
      "86\n",
      "epoch 86 train_loss : 0 , val_loss : 0.38057658076286316,p 0.609497645211931, r 0.6856512141280353, f 0.6453355495532932\n",
      "\n",
      "87\n",
      "epoch 87 train_loss : 0 , val_loss : 0.4154493808746338,p 0.5399403380841896, r 0.7192052980132451, f 0.6168118137069292\n",
      "\n",
      "88\n",
      "epoch 88 train_loss : 0 , val_loss : 0.3537193536758423,p 0.622031122031122, r 0.6706401766004415, f 0.6454217123433185\n",
      "\n",
      "89\n",
      "epoch 89 train_loss : 0 , val_loss : 0.4323714077472687,p 0.5354200988467874, r 0.717439293598234, f 0.6132075471698113\n",
      "\n",
      "90\n",
      "epoch 90 train_loss : 0 , val_loss : 0.40777119994163513,p 0.5294689119170984, r 0.7218543046357616, f 0.6108724079955166\n",
      "\n",
      "91\n",
      "epoch 91 train_loss : 0 , val_loss : 0.39299455285072327,p 0.6023099133782484, r 0.6907284768211921, f 0.6434961439588689\n",
      "\n",
      "92\n",
      "epoch 92 train_loss : 0 , val_loss : 0.40048471093177795,p 0.5708682474594402, r 0.7068432671081678, f 0.6316204753920505\n",
      "\n",
      "93\n",
      "epoch 93 train_loss : 0 , val_loss : 0.4175308346748352,p 0.5467250378851658, r 0.7167770419426048, f 0.6203075747444837\n",
      "\n",
      "94\n",
      "epoch 94 train_loss : 0 , val_loss : 0.40012797713279724,p 0.554357130628317, r 0.7147902869757174, f 0.624433516536496\n",
      "\n",
      "95\n",
      "epoch 95 train_loss : 0 , val_loss : 0.4175184965133667,p 0.5740368815044733, r 0.6940397350993377, f 0.6283601478964725\n",
      "\n",
      "96\n",
      "epoch 96 train_loss : 0 , val_loss : 0.4084952473640442,p 0.5517774343122102, r 0.7092715231788079, f 0.6206896551724137\n",
      "\n",
      "97\n",
      "epoch 97 train_loss : 0 , val_loss : 0.43833640217781067,p 0.5358843816718672, r 0.720309050772627, f 0.6145588096807609\n",
      "\n",
      "98\n",
      "epoch 98 train_loss : 0 , val_loss : 0.5032399296760559,p 0.515748031496063, r 0.7229580573951435, f 0.6020220588235293\n",
      "\n",
      "99\n",
      "epoch 99 train_loss : 0 , val_loss : 0.4009818136692047,p 0.554429945054945, r 0.7128035320088301, f 0.6237203013328182\n",
      "\n",
      "100\n",
      "epoch 100 train_loss : 0 , val_loss : 0.44574227929115295,p 0.5539408445888186, r 0.7152317880794702, f 0.6243376047788805\n",
      "\n",
      "101\n",
      "epoch 101 train_loss : 0 , val_loss : 0.4166471064090729,p 0.5439946470391436, r 0.7178807947019867, f 0.6189569851541683\n",
      "\n",
      "102\n",
      "epoch 102 train_loss : 0 , val_loss : 0.3826372027397156,p 0.5873660879202068, r 0.7019867549668874, f 0.6395816572807723\n",
      "\n",
      "103\n",
      "epoch 103 train_loss : 0 , val_loss : 0.41389262676239014,p 0.5352941176470588, r 0.7231788079470198, f 0.6152112676056338\n",
      "\n",
      "104\n",
      "epoch 104 train_loss : 0 , val_loss : 0.40002474188804626,p 0.5580380520160586, r 0.7057395143487859, f 0.6232576274490691\n",
      "\n",
      "105\n",
      "epoch 105 train_loss : 0 , val_loss : 0.43214449286460876,p 0.5359973579920739, r 0.7165562913907285, f 0.6132627999244284\n",
      "\n",
      "106\n",
      "epoch 106 train_loss : 0 , val_loss : 0.3734983801841736,p 0.5934252786699414, r 0.6933774834437086, f 0.6395194950626081\n",
      "\n",
      "107\n",
      "epoch 107 train_loss : 0 , val_loss : 0.46898043155670166,p 0.5149922720247295, r 0.7355408388520971, f 0.6058181818181817\n",
      "\n",
      "108\n",
      "epoch 108 train_loss : 0 , val_loss : 0.3869452476501465,p 0.5797260273972603, r 0.7006622516556291, f 0.6344827586206896\n",
      "\n",
      "109\n",
      "epoch 109 train_loss : 0 , val_loss : 0.39085298776626587,p 0.567949170490646, r 0.7103752759381898, f 0.6312279325225579\n",
      "\n",
      "110\n",
      "epoch 110 train_loss : 0 , val_loss : 0.3894408345222473,p 0.5957284515636918, r 0.6896247240618102, f 0.6392469817884183\n",
      "\n",
      "111\n",
      "epoch 111 train_loss : 0 , val_loss : 0.4317282736301422,p 0.5498812351543944, r 0.7154525386313466, f 0.6218342287029932\n",
      "\n",
      "112\n",
      "epoch 112 train_loss : 0 , val_loss : 0.43225064873695374,p 0.5477642276422764, r 0.713907284768212, f 0.6198964922369177\n",
      "\n",
      "113\n",
      "epoch 113 train_loss : 0 , val_loss : 0.4192672669887543,p 0.5341838403663722, r 0.720971302428256, f 0.6136790680195414\n",
      "\n",
      "114\n",
      "epoch 114 train_loss : 0 , val_loss : 0.4170021414756775,p 0.5345193406234698, r 0.7229580573951435, f 0.6146194989208971\n",
      "\n",
      "115\n",
      "epoch 115 train_loss : 0 , val_loss : 0.4164149761199951,p 0.5400598404255319, r 0.7172185430463576, f 0.6161577849421581\n",
      "\n",
      "116\n",
      "epoch 116 train_loss : 0 , val_loss : 0.40292680263519287,p 0.5783588818755636, r 0.7079470198675497, f 0.6366253101736974\n",
      "\n",
      "117\n",
      "epoch 117 train_loss : 0 , val_loss : 0.41694822907447815,p 0.5446488294314381, r 0.7189845474613686, f 0.619790675547098\n",
      "\n",
      "118\n",
      "epoch 118 train_loss : 0 , val_loss : 0.40227973461151123,p 0.5694963516639971, r 0.7064017660044151, f 0.6306040003941276\n",
      "\n",
      "119\n",
      "epoch 119 train_loss : 0 , val_loss : 0.38260361552238464,p 0.5743145743145743, r 0.7028697571743929, f 0.6321222950168751\n",
      "\n",
      "120\n",
      "epoch 120 train_loss : 0 , val_loss : 0.4115050733089447,p 0.5487474610697359, r 0.7156732891832229, f 0.6211917991952481\n",
      "\n",
      "121\n",
      "epoch 121 train_loss : 0 , val_loss : 0.4239938259124756,p 0.5317947062621046, r 0.7273730684326711, f 0.6143949282118217\n",
      "\n",
      "122\n",
      "epoch 122 train_loss : 0 , val_loss : 0.4272650480270386,p 0.5664972840371474, r 0.7136865342163355, f 0.6316303604571653\n",
      "\n",
      "123\n",
      "epoch 123 train_loss : 0 , val_loss : 0.3900279104709625,p 0.5826325411334552, r 0.7035320088300221, f 0.6374\n",
      "\n",
      "124\n",
      "epoch 124 train_loss : 0 , val_loss : 0.3938491642475128,p 0.5693574369071058, r 0.7022075055187638, f 0.6288425422556094\n",
      "\n",
      "125\n",
      "epoch 125 train_loss : 0 , val_loss : 0.44211605191230774,p 0.5335068314899154, r 0.7240618101545254, f 0.6143472560404571\n",
      "\n",
      "126\n",
      "epoch 126 train_loss : 0 , val_loss : 0.38690659403800964,p 0.5862701908957415, r 0.7050772626931567, f 0.6402084586089397\n",
      "\n",
      "127\n",
      "epoch 127 train_loss : 0 , val_loss : 0.39340904355049133,p 0.5702731847591661, r 0.7004415011037528, f 0.6286903110758868\n",
      "\n",
      "128\n",
      "epoch 128 train_loss : 0 , val_loss : 0.4048137068748474,p 0.5782569631626235, r 0.7103752759381898, f 0.6375433382862804\n",
      "\n",
      "129\n",
      "epoch 129 train_loss : 0 , val_loss : 0.39631080627441406,p 0.556390977443609, r 0.7187637969094923, f 0.6272394528992488\n",
      "\n",
      "130\n",
      "epoch 130 train_loss : 0 , val_loss : 0.3993668854236603,p 0.5811872146118722, r 0.7024282560706402, f 0.6360819590204898\n",
      "\n",
      "131\n",
      "epoch 131 train_loss : 0 , val_loss : 0.41366899013519287,p 0.5471445319042036, r 0.7211920529801324, f 0.6222264546233691\n",
      "\n",
      "132\n",
      "epoch 132 train_loss : 0 , val_loss : 0.398243248462677,p 0.5799963761551006, r 0.7066225165562914, f 0.6370783162503731\n",
      "\n",
      "133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 133 train_loss : 0 , val_loss : 0.4025893211364746,p 0.5777737816939399, r 0.7092715231788079, f 0.6368050738281636\n",
      "\n",
      "134\n",
      "epoch 134 train_loss : 0 , val_loss : 0.4127669930458069,p 0.5577219086711134, r 0.7198675496688741, f 0.6285053483665799\n",
      "\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "weight_dir='./2features_winlossone2+ent_emd_undersampling/'\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "with open(weight_dir+'train_result','a') as f:\n",
    "    f.write('=====result=======\\n')\n",
    "f1_best=0\n",
    "for epoch in range(200):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for i, (g,inputs,labels) in enumerate(train_loader):\n",
    "        inputs=inputs.float()\n",
    "        inputs=inputs.cuda()\n",
    "        labels=labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out=model(inputs)\n",
    "        out=out.cuda()\n",
    "        loss=criterion(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    val_losses=AverageMeter()\n",
    "    acc=0\n",
    "    gt_sum=0\n",
    "    tp_sum=0\n",
    "    fp_sum=0\n",
    "    fn_sum=0\n",
    "    acc=0\n",
    "    sum=0\n",
    "    pred_sum=0\n",
    "    with open(weight_dir+'train_result','a') as f:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "                inputs=inputs.float()\n",
    "                inputs=inputs.cuda()\n",
    "                labels=labels.cuda()\n",
    "                out=model(inputs)\n",
    "                out=out.cuda()\n",
    "                loss=criterion(out,labels)\n",
    "                val_losses.update(loss,labels.size(0))\n",
    "                TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(out.cpu(),labels.cpu())\n",
    "                tp_sum += TP\n",
    "                fp_sum += FP\n",
    "                fn_sum += FN\n",
    "                pred_sum += pred_len\n",
    "                gt_sum += gt_len\n",
    "                acc=acc+TP+TN\n",
    "                sum+=len(out)\n",
    "            if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "                precision = tp_sum/(tp_sum+fp_sum)\n",
    "                recall = tp_sum / (tp_sum+fn_sum)\n",
    "                f1 = (2*precision*recall / (precision + recall))\n",
    "                accuracy=acc/sum\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "                if f1_best<f1:\n",
    "                    f.write(\"== best epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+\"best\"))\n",
    "                    f1_best=f1\n",
    "\n",
    "            else:\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))                \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 4 23 0 tensor(9) tensor(5)\n",
      "9 0 23 0 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 23 0 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 0 16 14 tensor(2) tensor(16)\n",
      "16 0 15 1 tensor(16) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 7 13 1 tensor(18) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 14 18 tensor(0) tensor(18)\n",
      "0 5 19 8 tensor(5) tensor(8)\n",
      "0 21 11 0 tensor(21) tensor(0)\n",
      "13 1 18 0 tensor(14) tensor(13)\n",
      "6 21 5 0 tensor(27) tensor(6)\n",
      "3 0 27 2 tensor(3) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 4 15 0 tensor(17) tensor(13)\n",
      "3 6 23 0 tensor(9) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 19 13 tensor(0) tensor(13)\n",
      "15 9 0 8 tensor(24) tensor(23)\n",
      "10 8 14 0 tensor(18) tensor(10)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 2 30 tensor(0) tensor(30)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "9 2 19 2 tensor(11) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "9 3 20 0 tensor(12) tensor(9)\n",
      "14 0 13 5 tensor(14) tensor(19)\n",
      "8 1 22 1 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 0 10 4 tensor(18) tensor(22)\n",
      "17 15 0 0 tensor(32) tensor(17)\n",
      "28 4 0 0 tensor(32) tensor(28)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 4 11 3 tensor(18) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 6 8 0 tensor(24) tensor(18)\n",
      "6 3 22 1 tensor(9) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "2 24 0 6 tensor(26) tensor(8)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 7 15 0 tensor(17) tensor(10)\n",
      "18 1 13 0 tensor(19) tensor(18)\n",
      "4 5 22 1 tensor(9) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 9 7 0 tensor(25) tensor(16)\n",
      "25 0 7 0 tensor(25) tensor(25)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 6 15 0 tensor(17) tensor(11)\n",
      "17 8 6 1 tensor(25) tensor(18)\n",
      "18 13 1 0 tensor(31) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "14 18 0 0 tensor(32) tensor(14)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "26 0 6 0 tensor(26) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 4 21 0 tensor(11) tensor(7)\n",
      "15 0 17 0 tensor(15) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 0 27 1 tensor(4) tensor(5)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "17 5 10 0 tensor(22) tensor(17)\n",
      "4 0 27 1 tensor(4) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 3 20 0 tensor(12) tensor(9)\n",
      "13 7 12 0 tensor(20) tensor(13)\n",
      "10 0 22 0 tensor(10) tensor(10)\n",
      "0 20 12 0 tensor(20) tensor(0)\n",
      "11 8 13 0 tensor(19) tensor(11)\n",
      "12 2 18 0 tensor(14) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 25 7 0 tensor(25) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 7 22 0 tensor(10) tensor(3)\n",
      "20 8 4 0 tensor(28) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "6 26 0 0 tensor(32) tensor(6)\n",
      "5 1 26 0 tensor(6) tensor(5)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "27 5 0 0 tensor(32) tensor(27)\n",
      "25 7 0 0 tensor(32) tensor(25)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "12 20 0 0 tensor(32) tensor(12)\n",
      "19 13 0 0 tensor(32) tensor(19)\n",
      "6 19 7 0 tensor(25) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 7 18 0 tensor(14) tensor(7)\n",
      "23 5 4 0 tensor(28) tensor(23)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "6 0 24 2 tensor(6) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 1 29 0 tensor(3) tensor(2)\n",
      "28 0 3 1 tensor(28) tensor(29)\n",
      "9 11 5 7 tensor(20) tensor(16)\n",
      "16 7 9 0 tensor(23) tensor(16)\n",
      "19 13 0 0 tensor(32) tensor(19)\n",
      "11 0 21 0 tensor(11) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 1 30 0 tensor(2) tensor(1)\n",
      "16 0 14 2 tensor(16) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 0 27 1 tensor(4) tensor(5)\n",
      "16 1 4 11 tensor(17) tensor(27)\n",
      "11 6 14 1 tensor(17) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 0 5 8 tensor(19) tensor(27)\n",
      "21 7 4 0 tensor(28) tensor(21)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 17 15 tensor(0) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 4 15 8 tensor(9) tensor(13)\n",
      "0 0 18 14 tensor(0) tensor(14)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 16 16 tensor(0) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 8 15 tensor(9) tensor(24)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 16 16 tensor(0) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 21 2 tensor(9) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "7 19 0 6 tensor(26) tensor(13)\n",
      "10 6 16 0 tensor(16) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 21 11 0 tensor(21) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20 12 0 tensor(20) tensor(0)\n",
      "14 9 9 0 tensor(23) tensor(14)\n",
      "5 0 21 6 tensor(5) tensor(11)\n",
      "7 2 20 3 tensor(9) tensor(10)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "15 17 0 0 tensor(32) tensor(15)\n",
      "8 0 23 1 tensor(8) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "3 10 19 0 tensor(13) tensor(3)\n",
      "22 0 0 10 tensor(22) tensor(32)\n",
      "18 0 12 2 tensor(18) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "29 3 0 0 tensor(32) tensor(29)\n",
      "11 5 15 1 tensor(16) tensor(12)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 1 10 3 tensor(19) tensor(21)\n",
      "8 1 5 18 tensor(9) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "18 0 12 2 tensor(18) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 2 25 0 tensor(7) tensor(5)\n",
      "24 0 8 0 tensor(24) tensor(24)\n",
      "7 23 2 0 tensor(30) tensor(7)\n",
      "10 2 20 0 tensor(12) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 0 8 5 tensor(19) tensor(24)\n",
      "0 8 7 17 tensor(8) tensor(17)\n",
      "23 0 7 2 tensor(23) tensor(25)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "6 0 26 0 tensor(6) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "18 0 10 4 tensor(18) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 1 12 2 tensor(18) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 0 4 12 tensor(16) tensor(28)\n",
      "8 11 13 0 tensor(19) tensor(8)\n",
      "17 8 7 0 tensor(25) tensor(17)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "13 6 13 0 tensor(19) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 3 23 0 tensor(9) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 0 15 6 tensor(11) tensor(17)\n",
      "13 0 19 0 tensor(13) tensor(13)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 18 2 tensor(12) tensor(14)\n",
      "5 22 5 0 tensor(27) tensor(5)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 2 26 0 tensor(6) tensor(4)\n",
      "17 7 8 0 tensor(24) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 20 7 0 tensor(25) tensor(5)\n",
      "21 11 0 0 tensor(32) tensor(21)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "14 0 18 0 tensor(14) tensor(14)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 0 9 5 tensor(18) tensor(23)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 0 24 7 tensor(1) tensor(8)\n",
      "24 5 3 0 tensor(29) tensor(24)\n",
      "10 0 21 1 tensor(10) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 5 12 0 tensor(20) tensor(15)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "26 0 0 6 tensor(26) tensor(32)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 28 4 0 tensor(28) tensor(0)\n",
      "7 2 22 1 tensor(9) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 4 13 1 tensor(18) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 7 11 0 tensor(21) tensor(14)\n",
      "6 0 25 1 tensor(6) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 3 21 2 tensor(9) tensor(8)\n",
      "18 10 4 0 tensor(28) tensor(18)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "17 11 0 4 tensor(28) tensor(21)\n",
      "29 3 0 0 tensor(32) tensor(29)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "12 17 3 0 tensor(29) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 22 10 0 tensor(22) tensor(0)\n",
      "25 7 0 0 tensor(32) tensor(25)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 0 11 2 tensor(19) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 0 23 4 tensor(5) tensor(9)\n",
      "28 0 2 2 tensor(28) tensor(30)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "13 2 15 2 tensor(15) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 5 17 0 tensor(15) tensor(10)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 22 1 tensor(9) tensor(8)\n",
      "0 22 10 0 tensor(22) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 22 1 tensor(9) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 22 10 0 tensor(22) tensor(0)\n",
      "12 8 12 0 tensor(20) tensor(12)\n",
      "2 2 28 0 tensor(4) tensor(2)\n",
      "5 0 26 1 tensor(5) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 9 23 tensor(0) tensor(23)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "5 27 0 0 tensor(32) tensor(5)\n",
      "5 0 23 4 tensor(5) tensor(9)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 8 21 3 tensor(8) tensor(3)\n",
      "7 25 0 0 tensor(32) tensor(7)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 3 13 0 tensor(19) tensor(16)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "6 6 20 0 tensor(12) tensor(6)\n",
      "6 0 26 0 tensor(6) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 6 16 1 tensor(15) tensor(10)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "4 4 24 0 tensor(8) tensor(4)\n",
      "13 0 17 2 tensor(13) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 6 16 0 tensor(16) tensor(10)\n",
      "2 0 29 1 tensor(2) tensor(3)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 3 29 tensor(0) tensor(29)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 4 28 tensor(0) tensor(28)\n",
      "8 1 22 1 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "4 4 24 0 tensor(8) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 26 3 0 tensor(29) tensor(3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0 9 10 tensor(13) tensor(23)\n",
      "0 7 16 9 tensor(7) tensor(9)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 12 20 tensor(0) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 23 0 tensor(9) tensor(9)\n",
      "7 25 0 0 tensor(32) tensor(7)\n",
      "2 3 27 0 tensor(5) tensor(2)\n",
      "22 10 0 0 tensor(32) tensor(22)\n",
      "26 6 0 0 tensor(32) tensor(26)\n",
      "8 0 24 0 tensor(8) tensor(8)\n",
      "19 4 5 4 tensor(23) tensor(23)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 0 13 1 tensor(18) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "12 5 15 0 tensor(17) tensor(12)\n",
      "1 0 30 1 tensor(1) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 6 7 1 tensor(24) tensor(19)\n",
      "2 7 23 0 tensor(9) tensor(2)\n",
      "9 0 13 10 tensor(9) tensor(19)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 27 5 0 tensor(27) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 0 3 14 tensor(15) tensor(29)\n",
      "11 0 19 2 tensor(11) tensor(13)\n",
      "3 15 13 1 tensor(18) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "13 18 1 0 tensor(31) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 0 13 3 tensor(16) tensor(19)\n",
      "23 0 8 1 tensor(23) tensor(24)\n",
      "3 0 29 0 tensor(3) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 0 13 1 tensor(18) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "7 12 11 2 tensor(19) tensor(9)\n",
      "13 7 12 0 tensor(20) tensor(13)\n",
      "21 11 0 0 tensor(32) tensor(21)\n",
      "16 0 15 1 tensor(16) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 20 12 0 tensor(20) tensor(0)\n",
      "11 4 17 0 tensor(15) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 10 19 0 tensor(13) tensor(3)\n",
      "12 0 17 3 tensor(12) tensor(15)\n",
      "6 3 20 3 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "20 0 7 5 tensor(20) tensor(25)\n",
      "12 0 9 11 tensor(12) tensor(23)\n",
      "0 26 6 0 tensor(26) tensor(0)\n",
      "6 26 0 0 tensor(32) tensor(6)\n",
      "10 8 14 0 tensor(18) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "24 1 7 0 tensor(25) tensor(24)\n",
      "12 15 5 0 tensor(27) tensor(12)\n",
      "3 12 16 1 tensor(15) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 2 14 0 tensor(18) tensor(16)\n",
      "6 0 17 9 tensor(6) tensor(15)\n",
      "10 0 20 2 tensor(10) tensor(12)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "10 0 20 2 tensor(10) tensor(12)\n",
      "1 4 27 0 tensor(5) tensor(1)\n",
      "4 0 27 1 tensor(4) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 3 8 4 tensor(20) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 27 5 0 tensor(27) tensor(0)\n",
      "24 8 0 0 tensor(32) tensor(24)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "3 3 26 0 tensor(6) tensor(3)\n",
      "25 0 3 4 tensor(25) tensor(29)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "1 30 0 1 tensor(31) tensor(2)\n",
      "7 25 0 0 tensor(32) tensor(7)\n",
      "13 0 19 0 tensor(13) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 4 27 0 tensor(5) tensor(1)\n",
      "20 12 0 0 tensor(32) tensor(20)\n",
      "22 4 6 0 tensor(26) tensor(22)\n",
      "11 0 20 1 tensor(11) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 0 11 3 tensor(18) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 21 2 tensor(9) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 3 20 0 tensor(12) tensor(9)\n",
      "6 0 25 1 tensor(6) tensor(7)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 6 16 0 tensor(16) tensor(10)\n",
      "20 3 0 9 tensor(23) tensor(29)\n",
      "14 4 6 8 tensor(18) tensor(22)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "0 31 1 0 tensor(31) tensor(0)\n",
      "15 3 13 1 tensor(18) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 2 7 5 tensor(20) tensor(23)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "18 0 0 14 tensor(18) tensor(32)\n",
      "21 4 0 7 tensor(25) tensor(28)\n",
      "1 0 30 1 tensor(1) tensor(2)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "8 24 0 0 tensor(32) tensor(8)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "21 0 11 0 tensor(21) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 0 25 1 tensor(6) tensor(7)\n",
      "3 0 29 0 tensor(3) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 2 18 0 tensor(14) tensor(12)\n",
      "4 0 27 1 tensor(4) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 0 7 4 tensor(21) tensor(25)\n",
      "19 2 11 0 tensor(21) tensor(19)\n",
      "13 5 14 0 tensor(18) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 15 9 tensor(8) tensor(17)\n",
      "24 3 5 0 tensor(27) tensor(24)\n",
      "0 25 7 0 tensor(25) tensor(0)\n",
      "18 12 2 0 tensor(30) tensor(18)\n",
      "7 2 15 8 tensor(9) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "15 1 0 16 tensor(16) tensor(31)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 13 10 tensor(9) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "26 6 0 0 tensor(32) tensor(26)\n",
      "6 4 22 0 tensor(10) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "7 4 21 0 tensor(11) tensor(7)\n",
      "18 14 0 0 tensor(32) tensor(18)\n",
      "30 1 1 0 tensor(31) tensor(30)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 3 11 3 tensor(18) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 8 11 3 tensor(18) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 6 24 0 tensor(8) tensor(2)\n",
      "1 0 30 1 tensor(1) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 11 21 tensor(0) tensor(21)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 4 28 tensor(0) tensor(28)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 9 23 tensor(0) tensor(23)\n",
      "1 0 18 13 tensor(1) tensor(14)\n",
      "6 2 24 0 tensor(8) tensor(6)\n",
      "7 5 20 0 tensor(12) tensor(7)\n",
      "29 2 1 0 tensor(31) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "22 10 0 0 tensor(32) tensor(22)\n",
      "7 8 17 0 tensor(15) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 3 23 0 tensor(9) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "21 11 0 0 tensor(32) tensor(21)\n",
      "8 8 16 0 tensor(16) tensor(8)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "16 16 0 0 tensor(32) tensor(16)\n",
      "26 0 6 0 tensor(26) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 10 22 tensor(0) tensor(22)\n",
      "19 0 3 10 tensor(19) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 24 0 tensor(8) tensor(7)\n",
      "1 0 30 1 tensor(1) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 2 13 1 tensor(18) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 3 22 1 tensor(9) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 2 28 0 tensor(4) tensor(2)\n",
      "5 0 26 1 tensor(5) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 8 1 5 tensor(26) tensor(23)\n",
      "11 5 16 0 tensor(16) tensor(11)\n",
      "2 2 28 0 tensor(4) tensor(2)\n",
      "5 0 27 0 tensor(5) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "6 26 0 0 tensor(32) tensor(6)\n",
      "8 0 20 4 tensor(8) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 1 22 tensor(9) tensor(31)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "9 23 0 0 tensor(32) tensor(9)\n",
      "25 0 7 0 tensor(25) tensor(25)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 2 12 2 tensor(18) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 19 5 tensor(8) tensor(13)\n",
      "18 0 10 4 tensor(18) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "18 0 6 8 tensor(18) tensor(26)\n",
      "0 9 21 2 tensor(9) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 0 17 0 tensor(15) tensor(15)\n",
      "29 0 0 3 tensor(29) tensor(32)\n",
      "6 0 26 0 tensor(6) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 8 5 19 tensor(8) tensor(19)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "7 3 22 0 tensor(10) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "24 7 0 1 tensor(31) tensor(25)\n",
      "12 6 14 0 tensor(18) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 7 17 0 tensor(15) tensor(8)\n",
      "12 10 10 0 tensor(22) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "23 6 3 0 tensor(29) tensor(23)\n",
      "21 3 8 0 tensor(24) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 9 15 0 tensor(17) tensor(8)\n",
      "17 15 0 0 tensor(32) tensor(17)\n",
      "20 1 0 11 tensor(21) tensor(31)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "3 6 23 0 tensor(9) tensor(3)\n",
      "27 0 0 5 tensor(27) tensor(32)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 0 13 6 tensor(13) tensor(19)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "22 3 4 3 tensor(25) tensor(25)\n",
      "10 2 20 0 tensor(12) tensor(10)\n",
      "22 0 9 1 tensor(22) tensor(23)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 0 11 8 tensor(13) tensor(21)\n",
      "13 10 9 0 tensor(23) tensor(13)\n",
      "21 11 0 0 tensor(32) tensor(21)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 4 25 0 tensor(7) tensor(3)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "27 5 0 0 tensor(32) tensor(27)\n",
      "9 0 21 2 tensor(9) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 14 5 0 tensor(27) tensor(13)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "9 0 23 0 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 2 12 1 tensor(19) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "30 1 0 1 tensor(31) tensor(31)\n",
      "18 0 11 3 tensor(18) tensor(21)\n",
      "11 0 20 1 tensor(11) tensor(12)\n",
      "7 0 24 1 tensor(7) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 22 1 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 9 15 0 tensor(17) tensor(8)\n",
      "11 0 17 4 tensor(11) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "26 0 6 0 tensor(26) tensor(26)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 0 10 4 tensor(18) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 1 13 0 tensor(19) tensor(18)\n",
      "21 11 0 0 tensor(32) tensor(21)\n",
      "12 6 14 0 tensor(18) tensor(12)\n",
      "14 0 18 0 tensor(14) tensor(14)\n",
      "20 9 3 0 tensor(29) tensor(20)\n",
      "5 4 23 0 tensor(9) tensor(5)\n",
      "13 8 11 0 tensor(21) tensor(13)\n",
      "14 7 11 0 tensor(21) tensor(14)\n",
      "6 6 20 0 tensor(12) tensor(6)\n",
      "6 0 22 4 tensor(6) tensor(10)\n",
      "3 1 28 0 tensor(4) tensor(3)\n",
      "16 8 8 0 tensor(24) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 14 18 tensor(0) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 21 2 tensor(9) tensor(9)\n",
      "0 0 2 30 tensor(0) tensor(30)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "10 0 0 22 tensor(10) tensor(32)\n",
      "29 3 0 0 tensor(32) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 3 7 14 tensor(11) tensor(22)\n",
      "0 32 0 0 tensor(32) tensor(0)\n",
      "5 11 16 0 tensor(16) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 7 25 tensor(0) tensor(25)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "20 0 11 1 tensor(20) tensor(21)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 10 13 1 tensor(18) tensor(9)\n",
      "3 13 16 0 tensor(16) tensor(3)\n",
      "2 0 24 6 tensor(2) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "1 8 9 14 tensor(9) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 1 30 0 tensor(2) tensor(1)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "1 21 10 0 tensor(22) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 10 10 4 tensor(18) tensor(12)\n",
      "20 12 0 0 tensor(32) tensor(20)\n",
      "22 10 0 0 tensor(32) tensor(22)\n",
      "12 5 0 0 tensor(17) tensor(12)\n",
      "4846 2921 1388\n",
      "[1100/1101], prec:0.6239217200978499, recall:0.7773500160410651, f1:69.22362688379401, acc: 0.8776443195047846\n"
     ]
    }
   ],
   "source": [
    "weight_dir='./2features_winlossone2+ent_emd_undersampling/'\n",
    "\n",
    "test=Mul_data('test')\n",
    "test_loader=torch.utils.data.DataLoader(test,batch_size=32)\n",
    "dataset=weight_dir+'best'\n",
    "checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "pred_sum = 0#model output\n",
    "gt_sum = 0#label\n",
    "tp_sum=0\n",
    "fp_sum=0\n",
    "fn_sum=0\n",
    "acc=0\n",
    "sum=0\n",
    "result={}\n",
    "with torch.no_grad():\n",
    "    for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "        inputs=inputs.float()\n",
    "        labels=labels\n",
    "        output=model(inputs)\n",
    "        TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "        for idx,g in enumerate(game_id):\n",
    "            if g not in result.keys():\n",
    "                result[g]=pred[idx].tolist()\n",
    "            else:\n",
    "                result[g]+=pred[idx].tolist()\n",
    "        print(TP,FP,TN,FN,pred_len, gt_len)\n",
    "        tp_sum += TP\n",
    "        fp_sum += FP\n",
    "        fn_sum += FN\n",
    "        pred_sum += pred_len\n",
    "        gt_sum += gt_len\n",
    "        acc=acc+TP+TN\n",
    "        sum+=len(output)\n",
    "    with open(weight_dir+'/train_result','a') as f:\n",
    "        if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "            precision = tp_sum/(tp_sum+fp_sum)\n",
    "            recall = tp_sum / (tp_sum+fn_sum)\n",
    "            f1 = (2*precision*recall / (precision + recall)) * 100\n",
    "            accuracy=acc/sum\n",
    "            print( tp_sum, fp_sum, fn_sum)\n",
    "            print('[{}/{}], prec:{}, recall:{}, f1:{}, acc: {}'.format(it, len(test_loader), precision, recall, f1,accuracy))\n",
    "            f.write('{}, prec:{}, recall:{}, f1:{}, acc : {}\\n'.format(dataset, precision, recall, f1,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102844212431058132\n",
      "precision : 0.6015228426395939, recall : 0.6220472440944882, f1 : 0.6116129032258063, accuracy : 0.8778409090909091\n",
      "102844341902586509\n",
      "precision : 0.54739336492891, recall : 0.9130434782608695, f1 : 0.6844444444444445, accuracy : 0.9003741814780168\n",
      "102844401152267937\n",
      "precision : 0.608424336973479, recall : 0.9701492537313433, f1 : 0.74784276126558, accuracy : 0.8851026649191787\n",
      "102844212430927059\n",
      "precision : 0.6129032258064516, recall : 0.6621212121212121, f1 : 0.6365622723962128, accuracy : 0.8687877991059689\n",
      "102844412708953395\n",
      "precision : 0.625, recall : 0.8695652173913043, f1 : 0.7272727272727273, accuracy : 0.9124513618677043\n",
      "102844212429944013\n",
      "precision : 0.642023346303502, recall : 0.889487870619946, f1 : 0.7457627118644068, accuracy : 0.8900293255131965\n",
      "102844341912679064\n",
      "precision : 0.5105105105105106, recall : 0.7522123893805309, f1 : 0.6082289803220036, accuracy : 0.8871134020618556\n",
      "102844235753749959\n",
      "precision : 0.5934718100890207, recall : 0.5089058524173028, f1 : 0.5479452054794521, accuracy : 0.8510830324909747\n",
      "102844341908026005\n",
      "precision : 0.5925925925925926, recall : 0.849772382397572, f1 : 0.6982543640897756, accuracy : 0.8340761055879328\n",
      "102844283023206486\n",
      "precision : 0.5733082706766918, recall : 0.8543417366946778, f1 : 0.6861642294713161, accuracy : 0.847707423580786\n",
      "102844224147717245\n",
      "precision : 0.6779220779220779, recall : 0.8419354838709677, f1 : 0.7510791366906475, accuracy : 0.9056706652126499\n",
      "102844412704890154\n",
      "precision : 0.6156156156156156, recall : 0.6677524429967426, f1 : 0.6406249999999999, accuracy : 0.8891566265060241\n",
      "102844212430599377\n",
      "precision : 0.5924528301886792, recall : 0.6652542372881356, f1 : 0.626746506986028, accuracy : 0.9199143468950749\n",
      "102844412711443769\n",
      "precision : 0.758988015978695, recall : 0.8407079646017699, f1 : 0.7977606717984604, accuracy : 0.8863993710691824\n",
      "102844235747982779\n",
      "precision : 0.676039119804401, recall : 0.7627586206896552, f1 : 0.7167854828256642, accuracy : 0.8398093841642229\n",
      "==precision : 0.615211197335348, recall : 0.7780036924371012, f1 : 0.6818058265421684, accuracy : 0.8797011066362451\n"
     ]
    }
   ],
   "source": [
    "def fmeasure2(frames,label):\n",
    "    average = [0,0,0,0,0]\n",
    "    for key in frames.keys():\n",
    "        TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "        FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "        TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "        FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "        if precision==0 and recall == 0:\n",
    "            print('!')\n",
    "        else:\n",
    "            f1 = (2*precision*recall / (precision + recall))\n",
    "            print(key)\n",
    "            print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "            average[0]+= precision\n",
    "            average[1]+= recall\n",
    "            average[2]+= f1\n",
    "            average[3]+= accuracy\n",
    "            average[4]+=1\n",
    "    print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "with open('../../label/label.pickle',\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)\n",
    "fmeasure2(result,real_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=torch.transpose(b,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1380, 0.0111],\n",
       "         [0.8294, 0.4059],\n",
       "         [0.0521, 0.1911]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/chat_feature_pred_128_train.json',\"rb\") as f1:  \n",
    "    chat_result=json.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1654"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chat_result['102844235753356742'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('../data/audio_energy_2_normaized.pickle',\"rb\") as f3:  \n",
    "            audio_result=pickle.load(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.277879204882054e-07"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_result['102844235753356742'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('../data/audio_H.pickle',\"rb\") as f2:  \n",
    "            image_result=pickle.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16571"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_result['102844235753356742'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "102844412722519367\n",
      "102844212429550795\n",
      "102844401151219358\n",
      "102844401154430631\n",
      "102844412717014335\n",
      "102844401153971877\n",
      "102844224148503678\n",
      "102844412722847048\n",
      "102844401152857762\n",
      "102844412707380528\n",
      "102844212431516886\n",
      "102844283027925085\n",
      "102844412716227901\n",
      "102844412710001974\n",
      "102844294670878922\n",
      "102844294670551241\n",
      "102844283023599703\n",
      "102844412704496937\n",
      "102844235751783874\n",
      "102844401152071328\n",
      "102844412709674293\n",
      "102844401153447587\n",
      "102844224148896895\n",
      "102844235746868664\n",
      "102979081290790284\n",
      "102844283027531868\n",
      "102844212431975640\n",
      "102844401155937960\n",
      "102844212429092040\n",
      "102844341906649746\n",
      "102844412706987311\n",
      "102844412721339716\n",
      "102844212430402768\n",
      "102844341905011343\n",
      "102844235753356742\n",
      "102844235750997440\n",
      "102844412709346612\n",
      "102844412705217835\n",
      "102844235752963525\n",
      "102844412712164667\n",
      "102844412705545516\n",
      "102844341912220311\n",
      "102844341907370644\n",
      "102844235749424575\n",
      "102844212429419722\n",
      "102844294669568199\n",
      "102844212431779031\n",
      "102844294666422466\n",
      "102844224146472059\n",
      "102844212428895431\n",
      "102844212429747404\n",
      "102844235748703677\n",
      "102844224146930812\n",
      "102844212430730450\n",
      "102844294674876621\n",
      "102844341909598870\n",
      "102844283020453971\n",
      "102844294670026952\n",
      "102844412723174729\n",
      "102844341904683662\n",
      "102844283025696858\n",
      "102844235747261881\n",
      "102844401154168486\n",
      "102844235748310460\n",
      "102844412711836986\n",
      "102844412723567946\n",
      "102844235749031358\n",
      "102844294674286796\n",
      "102844294666881219\n",
      "102844412716686654\n"
     ]
    }
   ],
   "source": [
    "weight_dir='./2features_winlossone2+ent_emd_undersampling/'\n",
    "test=Mul_data('train')\n",
    "test_loader=torch.utils.data.DataLoader(test,batch_size=32)\n",
    "dataset=weight_dir+'best'\n",
    "checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "pred_sum = 0#model output\n",
    "gt_sum = 0#label\n",
    "tp_sum=0\n",
    "fp_sum=0\n",
    "fn_sum=0\n",
    "acc=0\n",
    "sum=0\n",
    "result={}\n",
    "with torch.no_grad():\n",
    "    for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "        inputs=inputs.float()\n",
    "        labels=labels\n",
    "        output=model(inputs)\n",
    "        for idx,g in enumerate(game_id):\n",
    "            if g not in result.keys():\n",
    "                print(g)\n",
    "                result[g]=[output[idx].tolist()]\n",
    "            else:\n",
    "                result[g].append(output[idx].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./2features_winlossone2+ent_emd_undersampling/lstm_feature_train2.json','a') as f:\n",
    "    json.dump(result,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyein",
   "language": "python",
   "name": "hyein"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
