{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Mul_data(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.d_type=d_type\n",
    "        if d_type=='train':\n",
    "            with open('./2features_ent_emd+채팅_undersampling/lstm_feature_train3.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        if d_type=='val':\n",
    "            with open('./2features_ent_emd+채팅_undersampling/lstm_feature_val3.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        if d_type=='test':\n",
    "            with open('./2features_ent_emd+채팅_undersampling/lstm_feature_test3.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        \n",
    "        with open('../../data/video_statistic_features_one2.pickle',\"rb\") as f2:  \n",
    "            self.image_result=pickle.load(f2)\n",
    "        with open('../../data/audio_entropy_emd.pickle',\"rb\") as f3:  \n",
    "            self.audio_result=pickle.load(f3)\n",
    "        with open('../../label/label.pickle',\"rb\") as f4:  \n",
    "            self.real_result=pickle.load(f4)\n",
    "            \n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "            \n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.real_result[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "        \n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[pos_idx] = len(sampling) / float(len(pos_idx))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        \n",
    "        self.sum=np.insert(np.cumsum([len(self.chat_result[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.WeightedSampling)\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)#sum으로 누적으로 히스토그램이 깔려있음/ 그중에 index의 위치\n",
    "            vid = np.where(vid[0]>0)[0][0]#몇번째 game을 쓸지!\n",
    "            vframe=index-self.sum[vid]#그 게임 안에서의 몇번째 프레임인지\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "            window=[]#batch*7(window size)*3(highlight result)\n",
    "            for idx in range(23): #7 : window size\n",
    "                s_window=[]\n",
    "                if vframe+idx<len(self.chat_result[game_id]):\n",
    "                    s_window+=((self.chat_result[game_id][vframe+idx]))#vframe의 chat\n",
    "#                     s_window+=list(self.audio_result[game_id][(vframe+idx)*10:(vframe+idx+1)*10])#vframe의 audio\n",
    "                    s_window+=[(self.image_result[game_id][vframe+idx])]#vframe의 image\n",
    "                else:\n",
    "                    #s_window=[0,0,0]#padding value\n",
    "                    s_window=[0]*24\n",
    "                window.append(s_window)\n",
    "\n",
    "\n",
    "            label=int(self.real_result[game_id][vframe])\n",
    "            return game_id,np.array(window),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n",
      "('102844412722519367', array([[ 7.81774372e-02, -9.09460038e-02,  7.78204650e-02,\n",
      "         9.61409733e-02,  1.08621843e-01,  1.11259036e-01,\n",
      "         8.87645483e-02,  7.18758106e-02, -1.09420896e-01,\n",
      "         4.75965701e-02, -2.98951436e-02, -6.20251102e-03,\n",
      "         4.93307738e-03,  7.52217099e-02, -4.72272933e-02,\n",
      "         1.06537908e-01,  7.55111203e-02, -5.54302149e-02,\n",
      "         8.91942605e-02,  8.26181173e-02, -2.40726307e-01,\n",
      "        -6.17996342e-02,  9.95216295e-02,  1.37379766e-03],\n",
      "       [ 6.81920797e-02, -7.89245814e-02,  6.62365481e-02,\n",
      "         8.11836347e-02,  9.15589035e-02,  1.00506157e-01,\n",
      "         7.63600469e-02,  6.16151430e-02, -9.27567407e-02,\n",
      "         4.14573923e-02,  5.30841313e-02, -3.88414203e-03,\n",
      "         5.57345152e-03,  6.25080466e-02, -3.85850780e-02,\n",
      "         9.09765288e-02,  6.39608204e-02, -4.57151942e-02,\n",
      "         7.85905272e-02,  7.02649206e-02, -2.31150031e-01,\n",
      "        -5.20319156e-02,  8.43341351e-02,  1.37379766e-03],\n",
      "       [ 5.80033511e-02, -6.69933110e-02,  5.67624010e-02,\n",
      "         6.96476400e-02,  7.91616663e-02,  8.96027237e-02,\n",
      "         6.53401166e-02,  5.28862998e-02, -7.96127617e-02,\n",
      "         3.53417918e-02,  1.59420013e-01, -1.91174785e-03,\n",
      "         5.76631771e-03,  5.20854145e-02, -3.03885452e-02,\n",
      "         7.76674002e-02,  5.36479242e-02, -3.69279310e-02,\n",
      "         6.87343180e-02,  5.89919612e-02, -2.31060579e-01,\n",
      "        -4.26580347e-02,  7.01462403e-02,  2.00727582e-03],\n",
      "       [ 4.84841764e-02, -5.56309856e-02,  4.87228893e-02,\n",
      "         6.04385622e-02,  6.82362020e-02,  7.84859508e-02,\n",
      "         5.51704727e-02,  4.57286127e-02, -6.75759390e-02,\n",
      "         3.09235938e-02,  2.27896631e-01,  4.13946575e-04,\n",
      "         6.21053157e-03,  4.36164178e-02, -2.42901240e-02,\n",
      "         6.50772154e-02,  4.46625985e-02, -2.98827868e-02,\n",
      "         5.98639660e-02,  4.90774810e-02, -2.37071738e-01,\n",
      "        -3.40597779e-02,  5.62900938e-02,  7.20083714e-04],\n",
      "       [ 4.65265587e-02, -5.30940667e-02,  4.92899232e-02,\n",
      "         6.22641556e-02,  6.83861226e-02,  7.48505071e-02,\n",
      "         5.40927164e-02,  4.69567589e-02, -6.66984469e-02,\n",
      "         3.24437208e-02,  2.39965841e-01,  1.83852459e-03,\n",
      "         7.05421111e-03,  4.47998419e-02, -2.57066693e-02,\n",
      "         6.26147017e-02,  4.45028506e-02, -3.10333017e-02,\n",
      "         5.88380806e-02,  4.83117253e-02, -2.49595761e-01,\n",
      "        -3.26679461e-02,  5.27480058e-02,  3.80885601e-03],\n",
      "       [ 3.83548923e-02, -4.33637723e-02,  3.87717858e-02,\n",
      "         4.85413149e-02,  4.79691140e-02,  6.47664145e-02,\n",
      "         4.17154692e-02,  3.80705409e-02, -4.74022292e-02,\n",
      "         2.89459974e-02,  2.38987789e-01,  3.68500291e-03,\n",
      "         7.24824518e-03,  3.43755856e-02, -2.10609995e-02,\n",
      "         4.67314571e-02,  3.42096873e-02, -2.40308400e-02,\n",
      "         4.93673310e-02,  3.77202742e-02, -2.39120722e-01,\n",
      "        -2.57727411e-02,  3.89186330e-02,  4.09334898e-04],\n",
      "       [ 2.00749021e-02, -2.05035079e-02,  1.90602839e-02,\n",
      "         2.29948647e-02,  1.39557114e-02,  4.09658886e-02,\n",
      "         1.66524630e-02,  1.96907613e-02, -1.42694563e-02,\n",
      "         1.85023751e-02,  2.71353900e-01,  6.19346509e-03,\n",
      "         6.27555838e-03,  1.41419396e-02, -9.87040624e-03,\n",
      "         1.67542566e-02,  1.39351450e-02, -8.90370924e-03,\n",
      "         2.88294274e-02,  1.62975062e-02, -2.22484231e-01,\n",
      "        -1.07828127e-02,  1.07131107e-02,  3.73959541e-04],\n",
      "       [-4.10935283e-03,  1.00508779e-02, -5.43320505e-03,\n",
      "        -8.61198641e-03, -2.61503272e-02,  7.90203456e-03,\n",
      "        -1.56820323e-02, -3.97820072e-03,  2.52327006e-02,\n",
      "         3.78710660e-03,  3.12538952e-01,  8.67184531e-03,\n",
      "         4.25279047e-03, -1.13080367e-02,  5.01146773e-03,\n",
      "        -2.08448209e-02, -1.16220713e-02,  1.07550304e-02,\n",
      "         1.66046445e-03, -1.09240534e-02, -2.04102531e-01,\n",
      "         8.67542904e-03, -2.56685670e-02,  6.80625439e-04],\n",
      "       [-2.16229428e-02,  3.10177281e-02, -2.02542413e-02,\n",
      "        -2.39948723e-02, -4.92049269e-02, -1.82799716e-02,\n",
      "        -3.77274118e-02, -1.72237884e-02,  5.06526418e-02,\n",
      "        -4.18515177e-03,  3.10218811e-01,  1.06128072e-02,\n",
      "         2.54611415e-03, -2.44442783e-02,  1.20743550e-02,\n",
      "        -4.58201654e-02, -2.75056195e-02,  2.15013586e-02,\n",
      "        -1.71266571e-02, -2.79073436e-02, -2.20068201e-01,\n",
      "         2.17386093e-02, -5.14545552e-02,  2.94536352e-04],\n",
      "       [-3.88363861e-02,  5.35537302e-02, -3.29210982e-02,\n",
      "        -3.91365848e-02, -6.94702119e-02, -4.62609380e-02,\n",
      "        -5.84531203e-02, -2.96508893e-02,  7.09181353e-02,\n",
      "        -1.31257484e-02,  3.34405303e-01,  1.21064754e-02,\n",
      "         1.45672448e-03, -3.68182585e-02,  1.85651146e-02,\n",
      "        -7.01619163e-02, -4.15395051e-02,  3.04726288e-02,\n",
      "        -3.62593494e-02, -4.42653298e-02, -2.17982441e-01,\n",
      "         3.37891951e-02, -7.62187392e-02,  0.00000000e+00],\n",
      "       [-5.21378480e-02,  7.10637569e-02, -3.95085104e-02,\n",
      "        -4.50095572e-02, -7.80397803e-02, -7.00654685e-02,\n",
      "        -7.24572837e-02, -3.62638049e-02,  8.04546773e-02,\n",
      "        -1.93122104e-02,  3.45874310e-01,  1.29955858e-02,\n",
      "         7.22152414e-04, -4.23272960e-02,  2.11849175e-02,\n",
      "        -8.62489864e-02, -4.94820103e-02,  3.43731679e-02,\n",
      "        -5.05375825e-02, -5.46229370e-02, -2.28219539e-01,\n",
      "         4.21067849e-02, -9.38344896e-02,  5.33461571e-06],\n",
      "       [-6.59204721e-02,  8.90815109e-02, -4.53285314e-02,\n",
      "        -4.97346483e-02, -8.49144235e-02, -9.56181288e-02,\n",
      "        -8.62800553e-02, -4.23648134e-02,  8.75231326e-02,\n",
      "        -2.60362308e-02,  3.55454355e-01,  1.35847991e-02,\n",
      "         2.86700903e-04, -4.71042991e-02,  2.32447553e-02,\n",
      "        -1.02320231e-01, -5.65541685e-02,  3.71294394e-02,\n",
      "        -6.55762926e-02, -6.47001117e-02, -2.36021802e-01,\n",
      "         5.01840077e-02, -1.11123748e-01,  0.00000000e+00],\n",
      "       [-8.31801072e-02,  1.09492533e-01, -5.96362650e-02,\n",
      "        -6.79911822e-02, -1.07863687e-01, -1.22651085e-01,\n",
      "        -1.07444108e-01, -5.68485148e-02,  1.07906640e-01,\n",
      "        -3.66269499e-02,  3.68709862e-01,  1.43104177e-02,\n",
      "        -5.23668656e-04, -6.23156503e-02,  3.16431969e-02,\n",
      "        -1.27834290e-01, -7.13154972e-02,  4.71125282e-02,\n",
      "        -8.59917402e-02, -8.20356235e-02, -2.26260096e-01,\n",
      "         6.19212836e-02, -1.34298667e-01,  4.89267707e-03],\n",
      "       [-9.95994136e-02,  1.29956141e-01, -7.06698075e-02,\n",
      "        -8.19326043e-02, -1.24872848e-01, -1.50889277e-01,\n",
      "        -1.25976473e-01, -6.83271140e-02,  1.22446977e-01,\n",
      "        -4.65176851e-02,  3.86059940e-01,  1.45952720e-02,\n",
      "        -8.73651414e-04, -7.40021914e-02,  3.77449878e-02,\n",
      "        -1.50280327e-01, -8.32331255e-02,  5.42339012e-02,\n",
      "        -1.05011471e-01, -9.69727561e-02, -2.16812924e-01,\n",
      "         7.23242015e-02, -1.55408204e-01,  7.03334808e-06],\n",
      "       [-1.27154350e-01,  1.60874248e-01, -9.73451585e-02,\n",
      "        -1.18834496e-01, -1.68071404e-01, -1.91529691e-01,\n",
      "        -1.61135599e-01, -9.56628695e-02,  1.60096020e-01,\n",
      "        -6.50617182e-02,  4.12803620e-01,  1.54254893e-02,\n",
      "        -2.69187475e-03, -1.04506403e-01,  5.53762317e-02,\n",
      "        -1.92838460e-01, -1.10203050e-01,  7.50507116e-02,\n",
      "        -1.38182312e-01, -1.27084866e-01, -1.83338836e-01,\n",
      "         9.22423676e-02, -1.92245871e-01,  8.92013311e-04],\n",
      "       [-1.44977301e-01,  1.79708019e-01, -1.10131003e-01,\n",
      "        -1.34458438e-01, -1.85947523e-01, -2.20164284e-01,\n",
      "        -1.80591986e-01, -1.09175518e-01,  1.75715566e-01,\n",
      "        -7.63576403e-02,  4.21270013e-01,  1.53530817e-02,\n",
      "        -3.88382515e-03, -1.18951991e-01,  6.42167553e-02,\n",
      "        -2.16632769e-01, -1.23549223e-01,  8.46439153e-02,\n",
      "        -1.58675373e-01, -1.43218786e-01, -1.81002960e-01,\n",
      "         1.03671201e-01, -2.13100359e-01,  8.09907913e-04],\n",
      "       [-1.53876707e-01,  1.87985152e-01, -1.10373981e-01,\n",
      "        -1.30932182e-01, -1.81784779e-01, -2.37770945e-01,\n",
      "        -1.86140344e-01, -1.09996192e-01,  1.71825573e-01,\n",
      "        -8.09281468e-02,  4.18071508e-01,  1.47089250e-02,\n",
      "        -4.14480595e-03, -1.18562654e-01,  6.45357221e-02,\n",
      "        -2.23824561e-01, -1.24391429e-01,  8.33972767e-02,\n",
      "        -1.67767063e-01, -1.46819323e-01, -2.01753661e-01,\n",
      "         1.07172005e-01, -2.19871178e-01,  1.13731623e-03],\n",
      "       [-1.66062757e-01,  1.99657276e-01, -1.14154689e-01,\n",
      "        -1.33628175e-01, -1.84897333e-01, -2.59958535e-01,\n",
      "        -1.96190745e-01, -1.14776038e-01,  1.73348293e-01,\n",
      "        -8.76890048e-02,  4.23191369e-01,  1.45788649e-02,\n",
      "        -4.57151979e-03, -1.23049714e-01,  6.71191514e-02,\n",
      "        -2.36946583e-01, -1.28413185e-01,  8.47407430e-02,\n",
      "        -1.81196764e-01, -1.54301971e-01, -2.05845878e-01,\n",
      "         1.12864487e-01, -2.30998248e-01,  1.30513310e-03],\n",
      "       [-1.77033439e-01,  2.09627315e-01, -1.16748750e-01,\n",
      "        -1.35305181e-01, -1.86323717e-01, -2.80040830e-01,\n",
      "        -2.04540104e-01, -1.18733354e-01,  1.72954440e-01,\n",
      "        -9.36859325e-02,  4.27150190e-01,  1.46282306e-02,\n",
      "        -5.13156317e-03, -1.26798958e-01,  6.91598952e-02,\n",
      "        -2.48319685e-01, -1.30930796e-01,  8.53740796e-02,\n",
      "        -1.93412408e-01, -1.60389766e-01, -2.07947522e-01,\n",
      "         1.17554575e-01, -2.40123913e-01,  6.25550747e-05],\n",
      "       [-1.94150522e-01,  2.24734679e-01, -1.22477740e-01,\n",
      "        -1.41629502e-01, -1.92269519e-01, -3.10229421e-01,\n",
      "        -2.18519360e-01, -1.27044484e-01,  1.75289273e-01,\n",
      "        -1.03395365e-01,  4.35270637e-01,  1.50065012e-02,\n",
      "        -6.48802985e-03, -1.35545626e-01,  7.40112215e-02,\n",
      "        -2.67563522e-01, -1.36146873e-01,  8.85860696e-02,\n",
      "        -2.12874308e-01, -1.70891166e-01, -2.02967525e-01,\n",
      "         1.25386000e-01, -2.54829258e-01,  1.55270100e-04],\n",
      "       [-1.75730586e-01,  2.07558557e-01, -1.06004201e-01,\n",
      "        -1.18894197e-01, -1.65350705e-01, -2.83118516e-01,\n",
      "        -1.96593314e-01, -1.09694637e-01,  1.51829228e-01,\n",
      "        -9.18722153e-02,  4.22966629e-01,  1.43346572e-02,\n",
      "        -4.50968137e-03, -1.15464576e-01,  6.21796399e-02,\n",
      "        -2.39425242e-01, -1.19972833e-01,  7.52811953e-02,\n",
      "        -1.91024601e-01, -1.52298421e-01, -2.17902616e-01,\n",
      "         1.13082357e-01, -2.32657194e-01,  0.00000000e+00],\n",
      "       [-1.57554537e-01,  1.90725267e-01, -9.07268524e-02,\n",
      "        -9.87702385e-02, -1.41096756e-01, -2.55773664e-01,\n",
      "        -1.75610542e-01, -9.38046500e-02,  1.30554006e-01,\n",
      "        -8.09045956e-02,  4.11686867e-01,  1.36714159e-02,\n",
      "        -2.72504543e-03, -9.73146930e-02,  5.14017418e-02,\n",
      "        -2.12589473e-01, -1.04944803e-01,  6.33827448e-02,\n",
      "        -1.69710755e-01, -1.34687379e-01, -2.27430150e-01,\n",
      "         1.01358719e-01, -2.11233467e-01,  1.43289566e-04],\n",
      "       [-1.35222316e-01,  1.69769749e-01, -7.46823028e-02,\n",
      "        -7.91512877e-02, -1.17482781e-01, -2.20559269e-01,\n",
      "        -1.51620105e-01, -7.68759921e-02,  1.10150017e-01,\n",
      "        -6.77815601e-02,  3.99946243e-01,  1.30018769e-02,\n",
      "        -8.28537391e-04, -7.86070228e-02,  4.01690863e-02,\n",
      "        -1.82163432e-01, -8.90551060e-02,  5.15940562e-02,\n",
      "        -1.43935919e-01, -1.14939630e-01, -2.32271135e-01,\n",
      "         8.78526047e-02, -1.86255798e-01,  0.00000000e+00]]), 0)\n"
     ]
    }
   ],
   "source": [
    "train=Mul_data('train')\n",
    "val=Mul_data('val')\n",
    "print(train[100])\n",
    "sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=44000)\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=32,sampler=sampler1)\n",
    "# train_loader=torch.utils.data.DataLoader(train,batch_size=32)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=24\n",
    "hidden_size=23\n",
    "length=7\n",
    "num_layers=3\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._clf1 = nn.LSTM(input_size, hidden_size,3,batch_first=True)\n",
    "        self._lin = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                 nn.Linear(hidden_size,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.cuda()\n",
    "        hidden = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).cuda() # (num_layers * num_directions, batch, hidden_size)\n",
    "        cell = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).cuda() # (num_layers * num_directions, batch, hidden_size)        out,hidden = self._clf1(x,h0)\n",
    "        out,hidden = self._clf1(x,(hidden,cell))#batch*7*3\n",
    "        out = self._lin(out[:,-1,:])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=LSTM().cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01,momentum=0.9,weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0 train_loss : 0 , val_loss : 0.40665000677108765,p 0.5447843137254902, r 0.7666666666666667, f 0.6369555249885374\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0 , val_loss : 0.4146575629711151,p 0.5118496704529519, r 0.8057395143487859, f 0.6260183517708601\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0 , val_loss : 0.3009628355503082,p 0.6469312513554544, r 0.6584988962472407, f 0.6526638223389126\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0 , val_loss : 0.38263145089149475,p 0.516464718460442, r 0.7997792494481236, f 0.6276310090948463\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0 , val_loss : 0.40078940987586975,p 0.4915388683236383, r 0.8207505518763797, f 0.6148503390110799\n",
      "\n",
      "5\n",
      "epoch 5 train_loss : 0 , val_loss : 0.35131099820137024,p 0.555662188099808, r 0.766887417218543, f 0.64440734557596\n",
      "\n",
      "6\n",
      "epoch 6 train_loss : 0 , val_loss : 0.34097108244895935,p 0.5697771821075557, r 0.7507726269315673, f 0.6478712258310315\n",
      "\n",
      "7\n",
      "epoch 7 train_loss : 0 , val_loss : 0.364470899105072,p 0.5287950383933845, r 0.7905077262693156, f 0.6336931516545743\n",
      "\n",
      "8\n",
      "epoch 8 train_loss : 0 , val_loss : 0.39747393131256104,p 0.5064146778866051, r 0.8103752759381898, f 0.6233126750997539\n",
      "\n",
      "9\n",
      "epoch 9 train_loss : 0 , val_loss : 0.3735862374305725,p 0.5484175720358998, r 0.7688741721854304, f 0.6401985111662529\n",
      "\n",
      "10\n",
      "epoch 21 train_loss : 0 , val_loss : 0.3438844084739685,p 0.5701275045537341, r 0.7600441501103753, f 0.6515280537420759\n",
      "\n",
      "22\n",
      "epoch 22 train_loss : 0 , val_loss : 0.34449416399002075,p 0.548907146178887, r 0.7816777041942605, f 0.6449321555413897\n",
      "\n",
      "23\n",
      "epoch 23 train_loss : 0 , val_loss : 0.38331398367881775,p 0.5154085383093017, r 0.8048565121412804, f 0.6284039986211652\n",
      "\n",
      "24\n",
      "epoch 24 train_loss : 0 , val_loss : 0.33149418234825134,p 0.5583877648558229, r 0.7737306843267108, f 0.64865365041177\n",
      "\n",
      "25\n",
      "epoch 25 train_loss : 0 , val_loss : 0.3540503680706024,p 0.5438329013569142, r 0.7874172185430464, f 0.6433402470917126\n",
      "\n",
      "26\n",
      "epoch 26 train_loss : 0 , val_loss : 0.3612951338291168,p 0.5316958376231798, r 0.7980132450331126, f 0.6381851884544091\n",
      "\n",
      "27\n",
      "epoch 27 train_loss : 0 , val_loss : 0.3260868787765503,p 0.5761254425897825, r 0.7543046357615895, f 0.6532836248924577\n",
      "\n",
      "28\n",
      "epoch 28 train_loss : 0 , val_loss : 0.3582504987716675,p 0.537989829494466, r 0.7940397350993378, f 0.6414051355206848\n",
      "\n",
      "29\n",
      "epoch 29 train_loss : 0 , val_loss : 0.35355550050735474,p 0.5601401943603632, r 0.776158940397351, f 0.6506893680022208\n",
      "\n",
      "30\n",
      "epoch 30 train_loss : 0 , val_loss : 0.3551819920539856,p 0.5471987720644667, r 0.7869757174392936, f 0.6455409687641468\n",
      "\n",
      "31\n",
      "epoch 31 train_loss : 0 , val_loss : 0.3797270357608795,p 0.5122086570477248, r 0.8150110375275939, f 0.6290679843244165\n",
      "\n",
      "32\n",
      "epoch 32 train_loss : 0 , val_loss : 0.36617642641067505,p 0.518350573898257, r 0.807505518763797, f 0.6313972555450073\n",
      "\n",
      "33\n",
      "epoch 33 train_loss : 0 , val_loss : 0.3744971454143524,p 0.5324904439870626, r 0.7995584988962472, f 0.6392516766678432\n",
      "\n",
      "34\n",
      "epoch 34 train_loss : 0 , val_loss : 0.3891865611076355,p 0.5168666196189132, r 0.8083885209713024, f 0.6305639259578131\n",
      "\n",
      "35\n",
      "epoch 35 train_loss : 0 , val_loss : 0.3467547297477722,p 0.5690362830405516, r 0.765121412803532, f 0.6526692401845401\n",
      "\n",
      "36\n",
      "epoch 36 train_loss : 0 , val_loss : 0.39092782139778137,p 0.5092772085294932, r 0.8119205298013245, f 0.6259360108917631\n",
      "\n",
      "37\n",
      "epoch 37 train_loss : 0 , val_loss : 0.34838730096817017,p 0.533717834960071, r 0.7966887417218543, f 0.6392136025504782\n",
      "\n",
      "38\n",
      "epoch 38 train_loss : 0 , val_loss : 0.34809067845344543,p 0.5590713944983304, r 0.776158940397351, f 0.6499676495054995\n",
      "\n",
      "39\n",
      "epoch 39 train_loss : 0 , val_loss : 0.39170828461647034,p 0.5053983873172065, r 0.8163355408388521, f 0.6242930699755213\n",
      "\n",
      "40\n",
      "epoch 40 train_loss : 0 , val_loss : 0.4070149064064026,p 0.497454448017149, r 0.8196467991169978, f 0.6191429047857262\n",
      "\n",
      "41\n",
      "epoch 41 train_loss : 0 , val_loss : 0.3952752649784088,p 0.5012155591572123, r 0.819205298013245, f 0.6219205630970337\n",
      "\n",
      "42\n",
      "epoch 42 train_loss : 0 , val_loss : 0.36423495411872864,p 0.5445665445665445, r 0.7876379690949228, f 0.6439270889731096\n",
      "\n",
      "43\n",
      "epoch 43 train_loss : 0 , val_loss : 0.3535235822200775,p 0.5621405750798723, r 0.7768211920529802, f 0.6522706209453197\n",
      "\n",
      "44\n",
      "epoch 44 train_loss : 0 , val_loss : 0.38722696900367737,p 0.4989871708305199, r 0.8156732891832229, f 0.6191872643485546\n",
      "\n",
      "45\n",
      "epoch 45 train_loss : 0 , val_loss : 0.34989941120147705,p 0.5702533728200065, r 0.765121412803532, f 0.6534690799396681\n",
      "\n",
      "46\n",
      "epoch 46 train_loss : 0 , val_loss : 0.38062748312950134,p 0.5195785276947174, r 0.8055187637969095, f 0.6316973946161171\n",
      "\n",
      "47\n",
      "epoch 47 train_loss : 0 , val_loss : 0.3809662461280823,p 0.5543427413067207, r 0.7847682119205298, f 0.6497304212738737\n",
      "\n",
      "48\n",
      "epoch 48 train_loss : 0 , val_loss : 0.38623422384262085,p 0.5030434194508319, r 0.8209713024282561, f 0.6238362828147278\n",
      "\n",
      "49\n",
      "epoch 49 train_loss : 0 , val_loss : 0.3389047086238861,p 0.5527008203064541, r 0.7883002207505518, f 0.6498043854062414\n",
      "\n",
      "50\n",
      "epoch 50 train_loss : 0 , val_loss : 0.3666726052761078,p 0.540990990990991, r 0.795364238410596, f 0.6439678284182305\n",
      "\n",
      "51\n",
      "epoch 51 train_loss : 0 , val_loss : 0.33582955598831177,p 0.5748057530170276, r 0.7675496688741722, f 0.6573400132337651\n",
      "\n",
      "52\n",
      "epoch 52 train_loss : 0 , val_loss : 0.3582671880722046,p 0.5498839907192575, r 0.7847682119205298, f 0.6466575716234652\n",
      "\n",
      "53\n",
      "epoch 53 train_loss : 0 , val_loss : 0.3503863215446472,p 0.5750841750841751, r 0.754083885209713, f 0.6525310410697229\n",
      "\n",
      "54\n",
      "epoch 54 train_loss : 0 , val_loss : 0.34966036677360535,p 0.5502466091245376, r 0.7880794701986755, f 0.6480304955527318\n",
      "\n",
      "55\n",
      "epoch 55 train_loss : 0 , val_loss : 0.3539300262928009,p 0.548646558391338, r 0.7830022075055187, f 0.6452023647112324\n",
      "\n",
      "56\n",
      "epoch 56 train_loss : 0 , val_loss : 0.3412940800189972,p 0.5708918654034629, r 0.7715231788079471, f 0.6562147953435975\n",
      "\n",
      "57\n",
      "epoch 93 train_loss : 0 , val_loss : 0.3043617606163025,p 0.635884973673552, r 0.6931567328918322, f 0.6632868610054922\n",
      "\n",
      "94\n",
      "epoch 94 train_loss : 0 , val_loss : 0.33263593912124634,p 0.584092080398557, r 0.7505518763796909, f 0.6569413583228674\n",
      "\n",
      "95\n",
      "epoch 95 train_loss : 0 , val_loss : 0.3695419132709503,p 0.5232153221125944, r 0.7960264900662252, f 0.6314130625109438\n",
      "\n",
      "96\n",
      "epoch 96 train_loss : 0 , val_loss : 0.35331377387046814,p 0.5534833538840938, r 0.7927152317880795, f 0.6518424396442186\n",
      "\n",
      "97\n",
      "epoch 97 train_loss : 0 , val_loss : 0.3959203362464905,p 0.4987236329437055, r 0.8194260485651215, f 0.6200618057295582\n",
      "\n",
      "98\n",
      "epoch 98 train_loss : 0 , val_loss : 0.3747234046459198,p 0.5202779353374929, r 0.8099337748344371, f 0.633569331721637\n",
      "\n",
      "99\n",
      "epoch 99 train_loss : 0 , val_loss : 0.3331843316555023,p 0.5595863166268894, r 0.7763796909492273, f 0.6503929727230698\n",
      "\n",
      "100\n",
      "epoch 100 train_loss : 0 , val_loss : 0.38254445791244507,p 0.48766383962991516, r 0.8377483443708609, f 0.6164717348927875\n",
      "\n",
      "101\n",
      "epoch 101 train_loss : 0 , val_loss : 0.36536315083503723,p 0.5403165033911078, r 0.7913907284768212, f 0.6421854008060904\n",
      "\n",
      "102\n",
      "epoch 102 train_loss : 0 , val_loss : 0.37210091948509216,p 0.5383115909431699, r 0.7924944812362031, f 0.6411286722028753\n",
      "\n",
      "103\n",
      "epoch 194 train_loss : 0 , val_loss : 0.3409103453159332,p 0.5668985601035431, r 0.7735099337748345, f 0.6542806460647932\n",
      "\n",
      "195\n",
      "epoch 195 train_loss : 0 , val_loss : 0.32408735156059265,p 0.5655844155844156, r 0.7690949227373068, f 0.6518241347053321\n",
      "\n",
      "196\n",
      "epoch 196 train_loss : 0 , val_loss : 0.333539754152298,p 0.5709454018360445, r 0.782560706401766, f 0.6602104479001769\n",
      "\n",
      "197\n",
      "epoch 197 train_loss : 0 , val_loss : 0.3453584909439087,p 0.5518302060904338, r 0.7920529801324503, f 0.6504713560551124\n",
      "\n",
      "198\n",
      "epoch 198 train_loss : 0 , val_loss : 0.3547336161136627,p 0.5314094155370938, r 0.8048565121412804, f 0.6401545079448688\n",
      "\n",
      "199\n",
      "epoch 199 train_loss : 0 , val_loss : 0.34228751063346863,p 0.5621835443037975, r 0.7843267108167771, f 0.6549308755760369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weight_dir='./2step_winlossone2+채팅&audio_undersampling/'\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "with open(weight_dir+'train_result','a') as f:\n",
    "    f.write('=====result=======\\n')\n",
    "f1_best=0\n",
    "for epoch in range(200):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for i, (g,inputs,labels) in enumerate(train_loader):\n",
    "        inputs=inputs.float()\n",
    "        inputs=inputs.cuda()\n",
    "        labels=labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out=model(inputs)\n",
    "        out=out.cuda()\n",
    "        loss=criterion(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    val_losses=AverageMeter()\n",
    "    acc=0\n",
    "    gt_sum=0\n",
    "    tp_sum=0\n",
    "    fp_sum=0\n",
    "    fn_sum=0\n",
    "    acc=0\n",
    "    sum=0\n",
    "    pred_sum=0\n",
    "    with open(weight_dir+'train_result','a') as f:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "                inputs=inputs.float()\n",
    "                inputs=inputs.cuda()\n",
    "                labels=labels.cuda()\n",
    "                out=model(inputs)\n",
    "                out=out.cuda()\n",
    "                loss=criterion(out,labels)\n",
    "                val_losses.update(loss,labels.size(0))\n",
    "                TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(out.cpu(),labels.cpu())\n",
    "                tp_sum += TP\n",
    "                fp_sum += FP\n",
    "                fn_sum += FN\n",
    "                pred_sum += pred_len\n",
    "                gt_sum += gt_len\n",
    "                acc=acc+TP+TN\n",
    "                sum+=len(out)\n",
    "            if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "                precision = tp_sum/(tp_sum+fp_sum)\n",
    "                recall = tp_sum / (tp_sum+fn_sum)\n",
    "                f1 = (2*precision*recall / (precision + recall))\n",
    "                accuracy=acc/sum\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "                if f1_best<f1:\n",
    "                    f.write(\"== best epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+\"best\"))\n",
    "                    f1_best=f1\n",
    "\n",
    "            else:\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))                \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 2 25 0 tensor(7) tensor(5)\n",
      "9 0 23 0 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 23 1 tensor(8) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 16 16 tensor(0) tensor(16)\n",
      "16 0 15 1 tensor(16) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 5 15 1 tensor(16) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 14 18 tensor(0) tensor(18)\n",
      "0 3 21 8 tensor(3) tensor(8)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "13 1 18 0 tensor(14) tensor(13)\n",
      "6 23 3 0 tensor(29) tensor(6)\n",
      "3 0 27 2 tensor(3) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 2 17 0 tensor(15) tensor(13)\n",
      "3 6 23 0 tensor(9) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 2 23 1 tensor(8) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 0 19 9 tensor(4) tensor(13)\n",
      "14 4 5 9 tensor(18) tensor(23)\n",
      "10 8 14 0 tensor(18) tensor(10)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 0 2 27 tensor(3) tensor(30)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "9 2 19 2 tensor(11) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 1 19 0 tensor(13) tensor(12)\n",
      "9 6 17 0 tensor(15) tensor(9)\n",
      "14 0 13 5 tensor(14) tensor(19)\n",
      "9 1 22 0 tensor(10) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 0 10 5 tensor(17) tensor(22)\n",
      "17 15 0 0 tensor(32) tensor(17)\n",
      "28 4 0 0 tensor(32) tensor(28)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "17 5 10 0 tensor(22) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 6 8 0 tensor(24) tensor(18)\n",
      "6 6 19 1 tensor(12) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "4 22 2 4 tensor(26) tensor(8)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 7 15 0 tensor(17) tensor(10)\n",
      "18 2 12 0 tensor(20) tensor(18)\n",
      "4 8 19 1 tensor(12) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 6 10 0 tensor(22) tensor(16)\n",
      "24 0 7 1 tensor(24) tensor(25)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 3 18 0 tensor(14) tensor(11)\n",
      "18 3 11 0 tensor(21) tensor(18)\n",
      "15 8 6 3 tensor(23) tensor(18)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "5 15 3 9 tensor(20) tensor(14)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "26 0 6 0 tensor(26) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 24 0 tensor(8) tensor(7)\n",
      "15 0 17 0 tensor(15) tensor(15)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 0 27 1 tensor(4) tensor(5)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "17 1 14 0 tensor(18) tensor(17)\n",
      "4 8 19 1 tensor(12) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 1 22 0 tensor(10) tensor(9)\n",
      "13 3 16 0 tensor(16) tensor(13)\n",
      "10 0 22 0 tensor(10) tensor(10)\n",
      "0 23 9 0 tensor(23) tensor(0)\n",
      "11 7 14 0 tensor(18) tensor(11)\n",
      "12 4 16 0 tensor(16) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 22 10 0 tensor(22) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 7 22 0 tensor(10) tensor(3)\n",
      "17 9 3 3 tensor(26) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 24 0 tensor(8) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 16 10 0 tensor(22) tensor(6)\n",
      "5 1 26 0 tensor(6) tensor(5)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "22 5 0 5 tensor(27) tensor(27)\n",
      "25 7 0 0 tensor(32) tensor(25)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "12 17 3 0 tensor(29) tensor(12)\n",
      "19 9 4 0 tensor(28) tensor(19)\n",
      "6 21 5 0 tensor(27) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 6 19 0 tensor(13) tensor(7)\n",
      "23 1 8 0 tensor(24) tensor(23)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "7 0 24 1 tensor(7) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 4 26 0 tensor(6) tensor(2)\n",
      "23 0 3 6 tensor(23) tensor(29)\n",
      "16 15 1 0 tensor(31) tensor(16)\n",
      "16 0 16 0 tensor(16) tensor(16)\n",
      "19 13 0 0 tensor(32) tensor(19)\n",
      "11 0 21 0 tensor(11) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 3 28 0 tensor(4) tensor(1)\n",
      "17 0 14 1 tensor(17) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 0 27 3 tensor(2) tensor(5)\n",
      "15 0 5 12 tensor(15) tensor(27)\n",
      "12 5 15 0 tensor(17) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "22 0 5 5 tensor(22) tensor(27)\n",
      "21 4 7 0 tensor(25) tensor(21)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 17 15 tensor(0) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 4 15 8 tensor(9) tensor(13)\n",
      "0 0 18 14 tensor(0) tensor(14)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 16 16 tensor(0) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 8 12 tensor(12) tensor(24)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 16 16 tensor(0) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 21 3 tensor(8) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "0 5 14 13 tensor(5) tensor(13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 6 16 0 tensor(16) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "14 7 11 0 tensor(21) tensor(14)\n",
      "5 0 21 6 tensor(5) tensor(11)\n",
      "9 4 18 1 tensor(13) tensor(10)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 9 8 0 tensor(24) tensor(15)\n",
      "9 0 23 0 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "3 10 19 0 tensor(13) tensor(3)\n",
      "20 0 0 12 tensor(20) tensor(32)\n",
      "19 0 12 1 tensor(19) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "29 1 2 0 tensor(30) tensor(29)\n",
      "11 3 17 1 tensor(14) tensor(12)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 2 9 0 tensor(23) tensor(21)\n",
      "8 1 5 18 tensor(9) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "19 0 12 1 tensor(19) tensor(20)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 1 26 0 tensor(6) tensor(5)\n",
      "24 0 8 0 tensor(24) tensor(24)\n",
      "7 3 22 0 tensor(10) tensor(7)\n",
      "10 2 20 0 tensor(12) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 0 8 7 tensor(17) tensor(24)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "23 0 7 2 tensor(23) tensor(25)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "6 0 26 0 tensor(6) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "20 0 10 2 tensor(20) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 1 12 0 tensor(20) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 0 4 11 tensor(17) tensor(28)\n",
      "8 13 11 0 tensor(21) tensor(8)\n",
      "17 10 5 0 tensor(27) tensor(17)\n",
      "4 2 26 0 tensor(6) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "13 8 11 0 tensor(21) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 3 23 1 tensor(8) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 0 15 7 tensor(10) tensor(17)\n",
      "13 1 18 0 tensor(14) tensor(13)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 0 18 4 tensor(10) tensor(14)\n",
      "5 18 9 0 tensor(23) tensor(5)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 3 25 0 tensor(7) tensor(4)\n",
      "17 10 5 0 tensor(27) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 1 26 0 tensor(6) tensor(5)\n",
      "21 3 8 0 tensor(24) tensor(21)\n",
      "28 0 1 3 tensor(28) tensor(31)\n",
      "14 0 18 0 tensor(14) tensor(14)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 0 9 6 tensor(17) tensor(23)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "23 1 7 1 tensor(24) tensor(24)\n",
      "11 0 21 0 tensor(11) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 13 4 0 tensor(28) tensor(15)\n",
      "12 13 7 0 tensor(25) tensor(12)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "31 0 0 1 tensor(31) tensor(32)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 25 7 0 tensor(25) tensor(0)\n",
      "6 2 22 2 tensor(8) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 2 15 1 tensor(16) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 6 12 0 tensor(20) tensor(14)\n",
      "7 0 25 0 tensor(7) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 3 21 3 tensor(8) tensor(8)\n",
      "18 11 3 0 tensor(29) tensor(18)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "16 11 0 5 tensor(27) tensor(21)\n",
      "29 3 0 0 tensor(32) tensor(29)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "29 0 0 3 tensor(29) tensor(32)\n",
      "12 11 9 0 tensor(23) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "25 7 0 0 tensor(32) tensor(25)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 0 11 2 tensor(19) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 0 23 7 tensor(2) tensor(9)\n",
      "28 0 2 2 tensor(28) tensor(30)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "13 2 15 2 tensor(15) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 3 19 0 tensor(13) tensor(10)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 3 21 1 tensor(10) tensor(8)\n",
      "0 21 11 0 tensor(21) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 22 1 tensor(9) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "12 8 12 0 tensor(20) tensor(12)\n",
      "2 2 28 0 tensor(4) tensor(2)\n",
      "4 0 26 2 tensor(4) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 9 23 tensor(0) tensor(23)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 24 0 tensor(8) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 13 14 0 tensor(18) tensor(5)\n",
      "5 0 23 4 tensor(5) tensor(9)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 3 26 3 tensor(3) tensor(3)\n",
      "7 25 0 0 tensor(32) tensor(7)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 1 15 0 tensor(17) tensor(16)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "6 3 23 0 tensor(9) tensor(6)\n",
      "6 0 26 0 tensor(6) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 9 13 0 tensor(19) tensor(10)\n",
      "30 0 0 2 tensor(30) tensor(32)\n",
      "4 2 26 0 tensor(6) tensor(4)\n",
      "13 0 17 2 tensor(13) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 13 9 0 tensor(23) tensor(10)\n",
      "3 0 29 0 tensor(3) tensor(3)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 3 29 tensor(0) tensor(29)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 4 28 tensor(0) tensor(28)\n",
      "9 1 22 0 tensor(10) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "4 4 24 0 tensor(8) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 5 24 0 tensor(8) tensor(3)\n",
      "13 0 9 10 tensor(13) tensor(23)\n",
      "0 7 16 9 tensor(7) tensor(9)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 12 20 tensor(0) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 2 21 0 tensor(11) tensor(9)\n",
      "7 15 10 0 tensor(22) tensor(7)\n",
      "0 3 27 2 tensor(3) tensor(2)\n",
      "20 10 0 2 tensor(30) tensor(22)\n",
      "26 6 0 0 tensor(32) tensor(26)\n",
      "8 0 24 0 tensor(8) tensor(8)\n",
      "23 5 4 0 tensor(28) tensor(23)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 0 13 2 tensor(17) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 3 22 0 tensor(10) tensor(7)\n",
      "12 6 14 0 tensor(18) tensor(12)\n",
      "2 0 30 0 tensor(2) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 4 9 0 tensor(23) tensor(19)\n",
      "2 11 19 0 tensor(13) tensor(2)\n",
      "12 0 13 7 tensor(12) tensor(19)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 28 4 0 tensor(28) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 0 3 15 tensor(14) tensor(29)\n",
      "12 0 19 1 tensor(12) tensor(13)\n",
      "4 18 10 0 tensor(22) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "13 19 0 0 tensor(32) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 0 13 3 tensor(16) tensor(19)\n",
      "23 1 7 1 tensor(24) tensor(24)\n",
      "3 0 29 0 tensor(3) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 1 12 0 tensor(20) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "6 10 13 3 tensor(16) tensor(9)\n",
      "13 5 14 0 tensor(18) tensor(13)\n",
      "21 11 0 0 tensor(32) tensor(21)\n",
      "17 0 15 0 tensor(17) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "11 4 17 0 tensor(15) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 9 20 0 tensor(12) tensor(3)\n",
      "15 1 16 0 tensor(16) tensor(15)\n",
      "6 5 18 3 tensor(11) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 0 7 6 tensor(19) tensor(25)\n",
      "15 0 9 8 tensor(15) tensor(23)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "6 13 13 0 tensor(19) tensor(6)\n",
      "10 13 9 0 tensor(23) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "24 0 8 0 tensor(24) tensor(24)\n",
      "12 20 0 0 tensor(32) tensor(12)\n",
      "3 12 16 1 tensor(15) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 2 14 0 tensor(18) tensor(16)\n",
      "7 0 17 8 tensor(7) tensor(15)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "11 0 20 1 tensor(11) tensor(12)\n",
      "1 7 24 0 tensor(8) tensor(1)\n",
      "4 0 27 1 tensor(4) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 2 9 2 tensor(21) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "24 8 0 0 tensor(32) tensor(24)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "3 6 23 0 tensor(9) tensor(3)\n",
      "22 0 3 7 tensor(22) tensor(29)\n",
      "2 0 21 9 tensor(2) tensor(11)\n",
      "2 27 3 0 tensor(29) tensor(2)\n",
      "7 24 1 0 tensor(31) tensor(7)\n",
      "13 0 19 0 tensor(13) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "1 5 26 0 tensor(6) tensor(1)\n",
      "20 12 0 0 tensor(32) tensor(20)\n",
      "22 10 0 0 tensor(32) tensor(22)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 1 10 3 tensor(19) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 21 3 tensor(8) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 3 20 0 tensor(12) tensor(9)\n",
      "7 0 25 0 tensor(7) tensor(7)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 7 15 0 tensor(17) tensor(10)\n",
      "29 3 0 0 tensor(32) tensor(29)\n",
      "17 10 0 5 tensor(27) tensor(22)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 20 12 0 tensor(20) tensor(0)\n",
      "0 30 2 0 tensor(30) tensor(0)\n",
      "16 7 9 0 tensor(23) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 2 7 5 tensor(20) tensor(23)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "17 0 0 15 tensor(17) tensor(32)\n",
      "23 4 0 5 tensor(27) tensor(28)\n",
      "1 0 30 1 tensor(1) tensor(2)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "8 24 0 0 tensor(32) tensor(8)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "21 0 11 0 tensor(21) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 0 25 1 tensor(6) tensor(7)\n",
      "3 0 29 0 tensor(3) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 4 16 0 tensor(16) tensor(12)\n",
      "5 0 27 0 tensor(5) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 0 7 4 tensor(21) tensor(25)\n",
      "19 1 12 0 tensor(20) tensor(19)\n",
      "13 4 15 0 tensor(17) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 15 8 tensor(9) tensor(17)\n",
      "22 0 8 2 tensor(22) tensor(24)\n",
      "0 23 9 0 tensor(23) tensor(0)\n",
      "18 12 2 0 tensor(30) tensor(18)\n",
      "8 7 10 7 tensor(15) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "26 1 0 5 tensor(27) tensor(31)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 0 13 3 tensor(16) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 5 19 0 tensor(13) tensor(8)\n",
      "26 6 0 0 tensor(32) tensor(26)\n",
      "6 4 22 0 tensor(10) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "7 3 22 0 tensor(10) tensor(7)\n",
      "18 14 0 0 tensor(32) tensor(18)\n",
      "30 1 1 0 tensor(31) tensor(30)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 5 9 1 tensor(22) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 7 12 2 tensor(18) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 6 24 0 tensor(8) tensor(2)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 11 9 tensor(12) tensor(21)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 0 4 14 tensor(14) tensor(28)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 0 9 16 tensor(7) tensor(23)\n",
      "1 0 18 13 tensor(1) tensor(14)\n",
      "6 2 24 0 tensor(8) tensor(6)\n",
      "1 0 25 6 tensor(1) tensor(7)\n",
      "29 3 0 0 tensor(32) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "22 10 0 0 tensor(32) tensor(22)\n",
      "7 10 15 0 tensor(17) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 3 23 1 tensor(8) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 0 20 1 tensor(11) tensor(12)\n",
      "21 7 4 0 tensor(28) tensor(21)\n",
      "8 8 16 0 tensor(16) tensor(8)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "16 1 15 0 tensor(17) tensor(16)\n",
      "26 0 6 0 tensor(26) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 10 22 tensor(0) tensor(22)\n",
      "24 0 3 5 tensor(24) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 24 0 tensor(8) tensor(7)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "17 3 12 0 tensor(20) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 3 22 2 tensor(8) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 2 28 0 tensor(4) tensor(2)\n",
      "4 0 26 2 tensor(4) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 6 3 18 tensor(11) tensor(23)\n",
      "11 5 16 0 tensor(16) tensor(11)\n",
      "2 4 26 0 tensor(6) tensor(2)\n",
      "5 0 27 0 tensor(5) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 24 0 tensor(8) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 8 18 0 tensor(14) tensor(6)\n",
      "12 7 13 0 tensor(19) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 0 1 21 tensor(10) tensor(31)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 15 8 0 tensor(24) tensor(9)\n",
      "25 0 7 0 tensor(25) tensor(25)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 6 8 0 tensor(24) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 0 19 6 tensor(7) tensor(13)\n",
      "20 0 10 2 tensor(20) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "20 0 6 6 tensor(20) tensor(26)\n",
      "0 12 18 2 tensor(12) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 0 17 2 tensor(13) tensor(15)\n",
      "27 0 0 5 tensor(27) tensor(32)\n",
      "6 0 26 0 tensor(6) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "1 13 0 18 tensor(14) tensor(19)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "0 22 10 0 tensor(22) tensor(0)\n",
      "6 3 22 1 tensor(9) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "23 7 0 2 tensor(30) tensor(25)\n",
      "12 6 14 0 tensor(18) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 6 18 0 tensor(14) tensor(8)\n",
      "12 11 9 0 tensor(23) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "23 7 2 0 tensor(30) tensor(23)\n",
      "21 5 6 0 tensor(26) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 8 16 0 tensor(16) tensor(8)\n",
      "17 15 0 0 tensor(32) tensor(17)\n",
      "22 1 0 9 tensor(23) tensor(31)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "3 9 20 0 tensor(12) tensor(3)\n",
      "28 0 0 4 tensor(28) tensor(32)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 1 12 0 tensor(20) tensor(19)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "22 2 5 3 tensor(24) tensor(25)\n",
      "10 2 20 0 tensor(12) tensor(10)\n",
      "23 0 9 0 tensor(23) tensor(23)\n",
      "7 1 23 1 tensor(8) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 0 11 3 tensor(18) tensor(21)\n",
      "13 3 16 0 tensor(16) tensor(13)\n",
      "20 2 9 1 tensor(22) tensor(21)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 7 22 0 tensor(10) tensor(3)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "27 5 0 0 tensor(32) tensor(27)\n",
      "11 0 21 0 tensor(11) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 2 17 0 tensor(15) tensor(13)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "9 0 23 0 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 1 13 0 tensor(19) tensor(18)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "28 0 1 3 tensor(28) tensor(31)\n",
      "16 0 11 5 tensor(16) tensor(21)\n",
      "11 0 20 1 tensor(11) tensor(12)\n",
      "8 0 24 0 tensor(8) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 22 2 tensor(8) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 7 17 0 tensor(15) tensor(8)\n",
      "11 0 17 4 tensor(11) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "24 0 6 2 tensor(24) tensor(26)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 0 10 5 tensor(17) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 0 14 3 tensor(15) tensor(18)\n",
      "18 5 6 3 tensor(23) tensor(21)\n",
      "12 6 14 0 tensor(18) tensor(12)\n",
      "13 0 18 1 tensor(13) tensor(14)\n",
      "20 10 2 0 tensor(30) tensor(20)\n",
      "5 6 21 0 tensor(11) tensor(5)\n",
      "0 0 19 13 tensor(0) tensor(13)\n",
      "14 7 11 0 tensor(21) tensor(14)\n",
      "6 4 22 0 tensor(10) tensor(6)\n",
      "6 0 22 4 tensor(6) tensor(10)\n",
      "2 0 29 1 tensor(2) tensor(3)\n",
      "16 8 8 0 tensor(24) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 14 18 tensor(0) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 2 21 3 tensor(8) tensor(9)\n",
      "0 0 2 30 tensor(0) tensor(30)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "13 0 0 19 tensor(13) tensor(32)\n",
      "20 3 0 9 tensor(23) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 3 7 16 tensor(9) tensor(22)\n",
      "0 27 5 0 tensor(27) tensor(0)\n",
      "5 11 16 0 tensor(16) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 7 25 tensor(0) tensor(25)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 2 9 0 tensor(23) tensor(21)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 8 15 1 tensor(16) tensor(9)\n",
      "3 10 19 0 tensor(13) tensor(3)\n",
      "2 0 24 6 tensor(2) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 23 9 0 tensor(23) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "2 8 9 13 tensor(10) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 2 29 0 tensor(3) tensor(1)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "1 22 9 0 tensor(23) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 1 19 0 tensor(13) tensor(12)\n",
      "20 8 4 0 tensor(28) tensor(20)\n",
      "22 10 0 0 tensor(32) tensor(22)\n",
      "12 5 0 0 tensor(17) tensor(12)\n",
      "4888 2603 1346\n",
      "[1100/1101], prec:0.6525163529568816, recall:0.7840872633942894, f1:71.22768670309655, acc: 0.8878666553085158\n"
     ]
    }
   ],
   "source": [
    "weight_dir='./2step_winlossone2+채팅&audio_undersampling/'\n",
    "\n",
    "test=Mul_data('test')\n",
    "test_loader=torch.utils.data.DataLoader(test,batch_size=32)\n",
    "dataset=weight_dir+'93train'\n",
    "checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "pred_sum = 0#model output\n",
    "gt_sum = 0#label\n",
    "tp_sum=0\n",
    "fp_sum=0\n",
    "fn_sum=0\n",
    "acc=0\n",
    "sum=0\n",
    "result={}\n",
    "with torch.no_grad():\n",
    "    for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "        inputs=inputs.float()\n",
    "        labels=labels\n",
    "        output=model(inputs)\n",
    "        TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "        for idx,g in enumerate(game_id):\n",
    "            if g not in result.keys():\n",
    "                result[g]=pred[idx].tolist()\n",
    "            else:\n",
    "                result[g]+=pred[idx].tolist()\n",
    "        print(TP,FP,TN,FN,pred_len, gt_len)\n",
    "        tp_sum += TP\n",
    "        fp_sum += FP\n",
    "        fn_sum += FN\n",
    "        pred_sum += pred_len\n",
    "        gt_sum += gt_len\n",
    "        acc=acc+TP+TN\n",
    "        sum+=len(output)\n",
    "    with open(weight_dir+'/train_result','a') as f:\n",
    "        if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "            precision = tp_sum/(tp_sum+fp_sum)\n",
    "            recall = tp_sum / (tp_sum+fn_sum)\n",
    "            f1 = (2*precision*recall / (precision + recall)) * 100\n",
    "            accuracy=acc/sum\n",
    "            print( tp_sum, fp_sum, fn_sum)\n",
    "            print('[{}/{}], prec:{}, recall:{}, f1:{}, acc: {}'.format(it, len(test_loader), precision, recall, f1,accuracy))\n",
    "            f.write('{}, prec:{}, recall:{}, f1:{}, acc : {}\\n'.format(dataset, precision, recall, f1,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102844212431058132\n",
      "precision : 0.6322751322751323, recall : 0.6272965879265092, f1 : 0.6297760210803689, accuracy : 0.8859577922077922\n",
      "102844341902586509\n",
      "precision : 0.5572139303482587, recall : 0.8853754940711462, f1 : 0.683969465648855, accuracy : 0.9031805425631432\n",
      "102844401152267937\n",
      "precision : 0.6150159744408946, recall : 0.9577114427860697, f1 : 0.7490272373540856, accuracy : 0.8872870249017037\n",
      "102844212430927059\n",
      "precision : 0.697452229299363, recall : 0.6636363636363637, f1 : 0.6801242236024844, accuracy : 0.8916644754141467\n",
      "102844412708953395\n",
      "precision : 0.6611111111111111, recall : 0.8623188405797102, f1 : 0.7484276729559748, accuracy : 0.9221789883268483\n",
      "102844212429944013\n",
      "precision : 0.6356589147286822, recall : 0.8840970350404312, f1 : 0.7395715896279593, accuracy : 0.8870967741935484\n",
      "102844341912679064\n",
      "precision : 0.5886524822695035, recall : 0.7345132743362832, f1 : 0.6535433070866141, accuracy : 0.9092783505154639\n",
      "102844235753749959\n",
      "precision : 0.6459016393442623, recall : 0.5012722646310432, f1 : 0.5644699140401146, accuracy : 0.8628158844765343\n",
      "102844341908026005\n",
      "precision : 0.6174282678002125, recall : 0.881638846737481, f1 : 0.72625, accuracy : 0.8498457319163524\n",
      "102844283023206486\n",
      "precision : 0.5693950177935944, recall : 0.896358543417367, f1 : 0.6964091403699674, accuracy : 0.847707423580786\n",
      "102844224147717245\n",
      "precision : 0.693069306930693, recall : 0.9032258064516129, f1 : 0.7843137254901961, accuracy : 0.916030534351145\n",
      "102844412704890154\n",
      "precision : 0.7138461538461538, recall : 0.755700325732899, f1 : 0.7341772151898734, accuracy : 0.9190361445783133\n",
      "102844212430599377\n",
      "precision : 0.6696035242290749, recall : 0.6440677966101694, f1 : 0.6565874730021598, accuracy : 0.9319057815845825\n",
      "102844412711443769\n",
      "precision : 0.7697368421052632, recall : 0.8628318584070797, f1 : 0.8136300417246175, accuracy : 0.8946540880503144\n",
      "102844235747982779\n",
      "precision : 0.6748387096774193, recall : 0.7213793103448276, f1 : 0.6973333333333334, accuracy : 0.8335777126099707\n",
      "==precision : 0.649413282413308, recall : 0.785428252713933, f1 : 0.7038406907004403, accuracy : 0.8894811499513764\n"
     ]
    }
   ],
   "source": [
    "def fmeasure2(frames,label):\n",
    "    average = [0,0,0,0,0]\n",
    "    for key in frames.keys():\n",
    "        TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "        FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "        TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "        FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "        if precision==0 and recall == 0:\n",
    "            print('!')\n",
    "        else:\n",
    "            f1 = (2*precision*recall / (precision + recall))\n",
    "            print(key)\n",
    "            print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "            average[0]+= precision\n",
    "            average[1]+= recall\n",
    "            average[2]+= f1\n",
    "            average[3]+= accuracy\n",
    "            average[4]+=1\n",
    "    print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "with open('../../label/label.pickle',\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)\n",
    "fmeasure2(result,real_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=torch.transpose(b,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1380, 0.0111],\n",
       "         [0.8294, 0.4059],\n",
       "         [0.0521, 0.1911]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/chat_feature_pred_128_train.json',\"rb\") as f1:  \n",
    "    chat_result=json.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1654"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chat_result['102844235753356742'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('../data/audio_energy_2_normaized.pickle',\"rb\") as f3:  \n",
    "            audio_result=pickle.load(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.277879204882054e-07"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_result['102844235753356742'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('../data/audio_H.pickle',\"rb\") as f2:  \n",
    "            image_result=pickle.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16571"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_result['102844235753356742'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['102844412711443769']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 27\n",
      "3 28\n",
      "3 29\n",
      "3 30\n",
      "3 31\n",
      "3 32\n",
      "3 33\n",
      "3 34\n",
      "3 35\n",
      "3 36\n",
      "3 37\n",
      "3 38\n",
      "3 39\n",
      "3 40\n",
      "3 41\n",
      "3 42\n",
      "3 43\n",
      "3 44\n",
      "3 45\n",
      "3 46\n",
      "3 47\n",
      "3 48\n",
      "3 49\n",
      "3 50\n",
      "7 28\n",
      "7 29\n",
      "7 30\n",
      "7 31\n",
      "7 32\n",
      "7 33\n",
      "7 34\n",
      "7 35\n",
      "7 36\n",
      "7 37\n",
      "7 38\n",
      "7 39\n",
      "7 40\n",
      "7 41\n",
      "7 42\n",
      "7 43\n",
      "7 44\n",
      "7 45\n",
      "7 46\n",
      "7 47\n",
      "7 48\n",
      "7 49\n",
      "7 50\n",
      "7 51\n",
      "7 52\n",
      "7 53\n",
      "7 54\n",
      "9 43\n",
      "9 44\n",
      "9 45\n",
      "9 46\n",
      "9 47\n",
      "9 48\n",
      "9 49\n",
      "9 50\n",
      "9 51\n",
      "9 52\n",
      "9 53\n",
      "9 54\n",
      "9 55\n",
      "9 56\n",
      "9 57\n",
      "9 58\n",
      "9 59\n",
      "10 0\n",
      "10 1\n",
      "10 2\n",
      "10 32\n",
      "10 33\n",
      "10 34\n",
      "10 35\n",
      "10 36\n",
      "10 37\n",
      "10 38\n",
      "10 39\n",
      "10 40\n",
      "10 41\n",
      "10 42\n",
      "10 43\n",
      "11 38\n",
      "11 39\n",
      "11 40\n",
      "11 41\n",
      "11 42\n",
      "11 43\n",
      "11 44\n",
      "11 45\n",
      "11 46\n",
      "11 47\n",
      "11 48\n",
      "11 49\n",
      "11 50\n",
      "11 51\n",
      "11 52\n",
      "11 53\n",
      "11 54\n",
      "12 0\n",
      "12 1\n",
      "12 2\n",
      "12 3\n",
      "12 4\n",
      "12 5\n",
      "12 6\n",
      "12 7\n",
      "12 8\n",
      "12 9\n",
      "12 10\n",
      "12 11\n",
      "12 12\n",
      "12 13\n",
      "12 14\n",
      "12 15\n",
      "12 16\n",
      "12 17\n",
      "12 18\n",
      "12 19\n",
      "12 20\n",
      "12 21\n",
      "12 22\n",
      "12 23\n",
      "12 24\n",
      "12 25\n",
      "12 26\n",
      "12 27\n",
      "12 28\n",
      "13 51\n",
      "13 52\n",
      "13 53\n",
      "13 54\n",
      "13 55\n",
      "13 56\n",
      "13 57\n",
      "13 58\n",
      "13 59\n",
      "14 0\n",
      "14 1\n",
      "14 2\n",
      "14 3\n",
      "14 4\n",
      "14 5\n",
      "14 6\n",
      "14 7\n",
      "14 8\n",
      "14 9\n",
      "14 10\n",
      "14 11\n",
      "14 12\n",
      "15 13\n",
      "15 14\n",
      "15 15\n",
      "15 16\n",
      "15 17\n",
      "15 18\n",
      "15 19\n",
      "15 20\n",
      "15 21\n",
      "15 22\n",
      "15 23\n",
      "15 24\n",
      "15 25\n",
      "15 26\n",
      "15 27\n",
      "15 28\n",
      "15 29\n",
      "15 30\n",
      "15 31\n",
      "15 32\n",
      "15 33\n",
      "15 34\n",
      "15 35\n",
      "15 54\n",
      "15 55\n",
      "15 56\n",
      "15 57\n",
      "15 58\n",
      "15 59\n",
      "16 0\n",
      "16 1\n",
      "17 13\n",
      "17 14\n",
      "17 15\n",
      "17 16\n",
      "17 17\n",
      "17 18\n",
      "17 19\n",
      "17 20\n",
      "17 21\n",
      "17 22\n",
      "17 23\n",
      "17 24\n",
      "17 25\n",
      "17 26\n",
      "17 27\n",
      "17 28\n",
      "17 29\n",
      "17 30\n",
      "17 31\n",
      "17 32\n",
      "17 33\n",
      "17 34\n",
      "17 35\n",
      "17 36\n",
      "17 37\n",
      "17 38\n",
      "17 39\n",
      "17 40\n",
      "17 41\n",
      "17 42\n",
      "17 43\n",
      "17 44\n",
      "17 45\n",
      "17 46\n",
      "17 47\n",
      "17 48\n",
      "17 49\n",
      "17 50\n",
      "17 51\n",
      "17 52\n",
      "17 53\n",
      "17 54\n",
      "17 55\n",
      "17 56\n",
      "17 57\n",
      "17 58\n",
      "17 59\n",
      "18 0\n",
      "19 5\n",
      "19 6\n",
      "19 7\n",
      "19 8\n",
      "19 9\n",
      "19 10\n",
      "19 11\n",
      "19 12\n",
      "19 13\n",
      "19 14\n",
      "19 15\n",
      "19 16\n",
      "19 17\n",
      "19 18\n",
      "19 19\n",
      "19 20\n",
      "19 21\n",
      "19 22\n",
      "19 23\n",
      "19 24\n",
      "19 25\n",
      "19 26\n",
      "19 27\n",
      "19 28\n",
      "19 29\n",
      "19 30\n",
      "19 31\n",
      "19 32\n",
      "19 33\n",
      "19 34\n",
      "19 35\n",
      "19 36\n",
      "19 37\n",
      "19 38\n",
      "19 39\n",
      "19 40\n",
      "19 41\n",
      "21 23\n",
      "21 24\n",
      "21 25\n",
      "21 26\n",
      "21 27\n",
      "21 28\n",
      "21 29\n",
      "21 30\n",
      "22 33\n",
      "22 34\n",
      "22 35\n",
      "22 36\n",
      "22 37\n",
      "22 38\n",
      "22 39\n",
      "22 40\n",
      "22 41\n",
      "22 42\n",
      "22 43\n",
      "22 44\n",
      "22 45\n",
      "22 46\n",
      "22 47\n",
      "22 48\n",
      "22 49\n",
      "22 50\n",
      "22 51\n",
      "22 52\n",
      "22 53\n",
      "22 54\n",
      "22 55\n",
      "22 56\n",
      "22 57\n",
      "22 58\n",
      "22 59\n",
      "23 0\n",
      "23 1\n",
      "23 2\n",
      "23 3\n",
      "23 4\n",
      "23 5\n",
      "23 6\n",
      "23 7\n",
      "23 8\n",
      "23 9\n",
      "23 10\n",
      "23 11\n",
      "23 12\n",
      "23 13\n",
      "23 14\n",
      "23 15\n",
      "23 16\n",
      "23 17\n",
      "23 18\n",
      "23 19\n",
      "23 20\n",
      "23 21\n",
      "23 22\n",
      "23 23\n",
      "23 24\n",
      "23 25\n",
      "23 26\n",
      "23 27\n",
      "23 28\n",
      "24 23\n",
      "24 24\n",
      "24 25\n",
      "24 26\n",
      "24 27\n",
      "24 28\n",
      "24 29\n",
      "24 30\n",
      "24 31\n",
      "24 32\n",
      "24 33\n",
      "24 34\n",
      "24 35\n",
      "24 36\n",
      "24 37\n",
      "24 38\n",
      "24 39\n",
      "24 40\n",
      "24 41\n",
      "24 42\n",
      "24 43\n",
      "24 44\n",
      "24 45\n",
      "24 46\n",
      "24 47\n",
      "24 48\n",
      "24 49\n",
      "24 50\n",
      "24 51\n",
      "24 52\n",
      "24 53\n",
      "24 54\n",
      "24 55\n",
      "24 56\n",
      "24 57\n",
      "24 58\n",
      "24 59\n",
      "25 0\n",
      "25 1\n",
      "25 2\n",
      "25 3\n",
      "25 4\n",
      "25 5\n",
      "25 6\n",
      "25 7\n",
      "25 8\n",
      "25 9\n",
      "25 10\n",
      "25 11\n",
      "25 12\n",
      "25 13\n",
      "25 14\n",
      "25 15\n",
      "25 16\n",
      "25 17\n",
      "25 18\n",
      "25 19\n",
      "25 20\n",
      "25 21\n",
      "25 22\n",
      "25 23\n",
      "25 24\n",
      "25 25\n",
      "25 26\n",
      "25 27\n",
      "25 28\n",
      "25 29\n",
      "25 30\n",
      "25 31\n",
      "25 32\n",
      "25 33\n",
      "26 35\n",
      "26 36\n",
      "26 37\n",
      "26 38\n",
      "26 39\n",
      "26 40\n",
      "26 41\n",
      "26 42\n",
      "26 43\n",
      "26 44\n",
      "26 45\n",
      "26 46\n",
      "26 47\n",
      "26 48\n",
      "26 49\n",
      "26 50\n",
      "26 51\n",
      "26 52\n",
      "26 53\n",
      "26 54\n",
      "26 55\n",
      "26 56\n",
      "26 57\n",
      "26 58\n",
      "26 59\n",
      "27 0\n",
      "27 1\n",
      "27 2\n",
      "27 3\n",
      "27 4\n",
      "27 5\n",
      "27 6\n",
      "27 7\n",
      "27 8\n",
      "27 9\n",
      "27 10\n",
      "27 11\n",
      "27 12\n",
      "27 13\n",
      "27 14\n",
      "29 39\n",
      "29 40\n",
      "29 41\n",
      "29 42\n",
      "29 43\n",
      "29 44\n",
      "29 45\n",
      "29 46\n",
      "29 47\n",
      "29 48\n",
      "29 49\n",
      "29 50\n",
      "29 51\n",
      "29 52\n",
      "29 53\n",
      "29 54\n",
      "29 55\n",
      "29 56\n",
      "29 57\n",
      "29 58\n",
      "29 59\n",
      "30 0\n",
      "30 1\n",
      "30 2\n",
      "30 3\n",
      "30 4\n",
      "30 5\n",
      "30 6\n",
      "30 7\n",
      "30 8\n",
      "30 9\n",
      "30 10\n",
      "30 11\n",
      "30 12\n",
      "30 13\n",
      "30 14\n",
      "30 15\n",
      "30 16\n",
      "30 17\n",
      "30 18\n",
      "30 19\n",
      "30 20\n",
      "30 21\n",
      "30 22\n",
      "30 23\n",
      "30 24\n",
      "30 25\n",
      "30 26\n",
      "30 27\n",
      "30 28\n",
      "30 29\n",
      "30 30\n",
      "30 31\n",
      "30 40\n",
      "30 41\n",
      "30 42\n",
      "30 43\n",
      "30 44\n",
      "30 45\n",
      "30 46\n",
      "30 47\n",
      "30 48\n",
      "30 49\n",
      "30 50\n",
      "30 51\n",
      "30 52\n",
      "30 53\n",
      "30 54\n",
      "30 55\n",
      "30 56\n",
      "30 57\n",
      "30 58\n",
      "30 59\n",
      "31 0\n",
      "31 1\n",
      "31 2\n",
      "31 3\n",
      "31 24\n",
      "31 25\n",
      "31 26\n",
      "31 27\n",
      "31 28\n",
      "31 29\n",
      "31 30\n",
      "31 31\n",
      "31 32\n",
      "31 33\n",
      "31 34\n",
      "31 35\n",
      "31 36\n",
      "31 37\n",
      "31 38\n",
      "31 39\n",
      "31 40\n",
      "31 41\n",
      "31 42\n",
      "31 43\n",
      "31 44\n",
      "31 45\n",
      "31 46\n",
      "31 47\n",
      "31 48\n",
      "31 49\n",
      "31 50\n",
      "31 51\n",
      "31 52\n",
      "31 53\n",
      "31 54\n",
      "31 55\n",
      "31 56\n",
      "31 57\n",
      "32 11\n",
      "32 12\n",
      "32 13\n",
      "32 14\n",
      "32 15\n",
      "32 16\n",
      "32 17\n",
      "32 18\n",
      "33 57\n",
      "33 58\n",
      "33 59\n",
      "34 0\n",
      "34 1\n",
      "34 2\n",
      "34 3\n",
      "34 4\n",
      "34 5\n",
      "34 6\n",
      "34 7\n",
      "34 8\n",
      "34 9\n",
      "34 10\n",
      "34 11\n",
      "34 12\n",
      "34 13\n",
      "34 14\n",
      "34 15\n",
      "34 16\n",
      "34 17\n",
      "34 18\n",
      "34 19\n",
      "34 20\n",
      "34 21\n",
      "34 22\n",
      "34 23\n",
      "34 24\n",
      "34 25\n",
      "34 26\n",
      "34 27\n",
      "34 28\n",
      "34 29\n",
      "34 30\n",
      "34 57\n",
      "34 58\n",
      "34 59\n",
      "35 0\n",
      "35 1\n",
      "35 2\n",
      "35 3\n",
      "35 4\n",
      "35 5\n",
      "35 6\n",
      "35 7\n",
      "35 8\n",
      "35 9\n",
      "35 10\n",
      "35 11\n",
      "35 12\n",
      "35 13\n",
      "35 14\n",
      "35 15\n",
      "35 16\n",
      "35 17\n",
      "35 18\n",
      "35 19\n",
      "35 20\n",
      "37 17\n",
      "37 18\n",
      "37 19\n",
      "37 20\n",
      "37 21\n",
      "37 22\n",
      "37 23\n",
      "37 24\n",
      "37 25\n",
      "37 26\n",
      "37 27\n",
      "37 28\n",
      "37 29\n",
      "37 30\n",
      "37 31\n",
      "37 32\n",
      "37 33\n",
      "37 34\n",
      "37 35\n",
      "37 36\n",
      "37 37\n",
      "37 38\n",
      "37 39\n",
      "37 40\n",
      "37 41\n",
      "37 42\n",
      "37 43\n",
      "37 44\n",
      "37 45\n",
      "37 46\n",
      "37 47\n",
      "37 48\n",
      "37 49\n",
      "37 50\n",
      "37 51\n",
      "37 52\n",
      "37 53\n",
      "37 54\n",
      "37 55\n",
      "37 56\n",
      "37 57\n",
      "37 58\n",
      "37 59\n",
      "38 0\n",
      "38 1\n",
      "38 2\n",
      "38 3\n",
      "38 4\n",
      "38 5\n",
      "38 6\n",
      "38 7\n",
      "38 8\n",
      "38 9\n",
      "38 10\n",
      "38 11\n",
      "38 12\n",
      "38 13\n",
      "38 14\n",
      "38 15\n",
      "38 16\n",
      "38 17\n",
      "38 18\n",
      "38 19\n",
      "38 20\n",
      "38 21\n",
      "38 22\n",
      "38 23\n",
      "38 24\n",
      "38 25\n",
      "38 26\n",
      "38 27\n",
      "38 28\n",
      "38 29\n",
      "38 30\n",
      "38 31\n",
      "38 32\n",
      "38 33\n",
      "38 34\n",
      "38 35\n",
      "38 36\n",
      "38 37\n",
      "38 38\n",
      "38 39\n",
      "38 40\n",
      "38 41\n",
      "41 28\n",
      "41 29\n",
      "41 30\n",
      "41 31\n",
      "41 32\n",
      "41 33\n",
      "41 34\n",
      "41 35\n",
      "41 36\n",
      "41 37\n",
      "41 38\n",
      "41 39\n",
      "41 40\n",
      "41 41\n",
      "41 42\n",
      "41 43\n",
      "41 44\n",
      "41 45\n",
      "41 46\n",
      "41 47\n",
      "41 48\n",
      "41 49\n",
      "41 50\n",
      "41 51\n",
      "41 52\n",
      "41 53\n",
      "41 54\n",
      "41 55\n",
      "41 56\n",
      "41 57\n",
      "41 58\n",
      "41 59\n",
      "42 0\n",
      "42 1\n",
      "42 2\n",
      "42 3\n",
      "42 4\n",
      "42 5\n",
      "42 6\n",
      "42 7\n",
      "42 8\n",
      "42 9\n",
      "42 10\n",
      "42 11\n",
      "42 12\n",
      "42 13\n",
      "42 14\n",
      "42 15\n",
      "42 16\n",
      "42 17\n",
      "42 18\n",
      "42 19\n",
      "42 20\n",
      "42 21\n",
      "42 22\n",
      "42 23\n"
     ]
    }
   ],
   "source": [
    "for idx,i in enumerate(result['102844412711443769']):\n",
    "    if i==1:\n",
    "        print(idx//60,idx%60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyein",
   "language": "python",
   "name": "hyein"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
