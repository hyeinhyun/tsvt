{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Mul_data(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.d_type=d_type\n",
    "        if d_type=='train':\n",
    "            with open('../../data/chat_feature_train.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        if d_type=='val':\n",
    "            with open('../../data/chat_feature_val.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        if d_type=='test':\n",
    "            with open('../../data/chat_feature_test.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        \n",
    "        with open('../../data/video_statistic_features_one2.pickle',\"rb\") as f2:  \n",
    "            self.image_result=pickle.load(f2)\n",
    "        with open('../../data/audio_entropy_emd.pickle',\"rb\") as f3:  \n",
    "            self.audio_result=pickle.load(f3)\n",
    "        with open('../../label/label.pickle',\"rb\") as f4:  \n",
    "            self.real_result=pickle.load(f4)\n",
    "            \n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "            \n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.real_result[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "        \n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[pos_idx] = len(sampling) / float(len(pos_idx))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        \n",
    "        self.sum=np.insert(np.cumsum([len(self.chat_result[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.WeightedSampling)\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)#sum으로 누적으로 히스토그램이 깔려있음/ 그중에 index의 위치\n",
    "            vid = np.where(vid[0]>0)[0][0]#몇번째 game을 쓸지!\n",
    "            vframe=index-self.sum[vid]#그 게임 안에서의 몇번째 프레임인지\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "            window=[]#batch*7(window size)*3(highlight result)\n",
    "            for idx in range(23): #7 : window size\n",
    "                s_window=[]\n",
    "                if vframe+idx<len(self.chat_result[game_id]):\n",
    "                    s_window+=((self.chat_result[game_id][vframe+idx]))#vframe의 chat\n",
    "#                     s_window+=list(self.audio_result[game_id][(vframe+idx)*10:(vframe+idx+1)*10])#vframe의 audio\n",
    "                    s_window+=[(self.image_result[game_id][vframe+idx])]#vframe의 image\n",
    "                else:\n",
    "                    #s_window=[0,0,0]#padding value\n",
    "                    s_window=[0]*129\n",
    "                window.append(s_window)\n",
    "\n",
    "\n",
    "            label=int(self.real_result[game_id][vframe])\n",
    "            return game_id,np.array(window),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n",
      "('102844412722519367', array([[-4.23758756e-03,  8.49383231e-03,  1.44858090e-02, ...,\n",
      "        -1.06911631e-02,  8.68443027e-03,  1.37379766e-03],\n",
      "       [ 1.31821318e-04,  3.67566757e-03,  1.84836853e-02, ...,\n",
      "        -1.99008379e-02,  1.30263995e-02,  1.37379766e-03],\n",
      "       [ 2.78287055e-03, -2.53155967e-03,  2.11640801e-02, ...,\n",
      "        -2.81594452e-02,  1.92357656e-02,  2.00727582e-03],\n",
      "       ...,\n",
      "       [-9.56570916e-03,  2.41865851e-02,  5.35075879e-03, ...,\n",
      "         9.98431910e-03, -8.23678728e-03,  0.00000000e+00],\n",
      "       [-8.14033020e-03,  2.75277682e-02,  2.89613754e-03, ...,\n",
      "         1.18555529e-02, -1.07653122e-02,  1.43289566e-04],\n",
      "       [-7.51412148e-03,  2.00215783e-02,  8.99404753e-03, ...,\n",
      "         7.61067495e-05, -2.54225195e-03,  0.00000000e+00]]), 0)\n"
     ]
    }
   ],
   "source": [
    "train=Mul_data('train')\n",
    "val=Mul_data('val')\n",
    "print(train[100])\n",
    "sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=44000)\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=32,sampler=sampler1)\n",
    "# train_loader=torch.utils.data.DataLoader(train,batch_size=32)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=129\n",
    "hidden_size=23\n",
    "length=7\n",
    "num_layers=3\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._clf1 = nn.LSTM(input_size, hidden_size,3,batch_first=True)\n",
    "        self._lin = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                 nn.Linear(hidden_size,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.cuda()\n",
    "        hidden = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).cuda() # (num_layers * num_directions, batch, hidden_size)\n",
    "        cell = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).cuda() # (num_layers * num_directions, batch, hidden_size)        out,hidden = self._clf1(x,h0)\n",
    "        feature,hidden = self._clf1(x,(hidden,cell))#batch*7*3\n",
    "        out = self._lin(feature[:,-1,:])\n",
    "        return feature[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=LSTM().cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01,momentum=0.9,weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0 train_loss : 0 , val_loss : 0.38313132524490356,p 0.5198034113905753, r 0.7938189845474614, f 0.6282320055904961\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0 , val_loss : 0.36074498295783997,p 0.5461311831291673, r 0.7774834437086092, f 0.6415884871117589\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0 , val_loss : 0.3507436513900757,p 0.5551168147416914, r 0.7448123620309051, f 0.6361236802413274\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0 , val_loss : 0.36478498578071594,p 0.5379547836502471, r 0.7931567328918322, f 0.6410919796592025\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0 , val_loss : 0.45652103424072266,p 0.4606891531181752, r 0.8381898454746137, f 0.5945818979016599\n",
      "\n",
      "5\n",
      "epoch 5 train_loss : 0 , val_loss : 0.3577969968318939,p 0.5384615384615384, r 0.7849889624724061, f 0.6387641458595293\n",
      "\n",
      "6\n",
      "epoch 6 train_loss : 0 , val_loss : 0.36118242144584656,p 0.5466497703152225, r 0.7618101545253864, f 0.6365397030342156\n",
      "\n",
      "7\n",
      "epoch 7 train_loss : 0 , val_loss : 0.3360035717487335,p 0.5576861617130073, r 0.7704194260485652, f 0.6470152020763811\n",
      "\n",
      "8\n",
      "epoch 8 train_loss : 0 , val_loss : 0.36777517199516296,p 0.5441245136186771, r 0.7717439293598234, f 0.6382473756275673\n",
      "\n",
      "9\n",
      "epoch 9 train_loss : 0 , val_loss : 0.3934924304485321,p 0.48667194510424916, r 0.8141280353200883, f 0.609184010571523\n",
      "\n",
      "10\n",
      "epoch 10 train_loss : 0 , val_loss : 0.36089056730270386,p 0.5475141598489616, r 0.7682119205298014, f 0.6393532978137056\n",
      "\n",
      "11\n",
      "epoch 11 train_loss : 0 , val_loss : 0.3381398022174835,p 0.54265625, r 0.7666666666666667, f 0.635498627630375\n",
      "\n",
      "12\n",
      "epoch 12 train_loss : 0 , val_loss : 0.380647212266922,p 0.5271409554799585, r 0.7867549668874172, f 0.6312992649012487\n",
      "\n",
      "13\n",
      "epoch 13 train_loss : 0 , val_loss : 0.35020920634269714,p 0.5364014160381715, r 0.7693156732891833, f 0.6320848825609866\n",
      "\n",
      "14\n",
      "epoch 14 train_loss : 0 , val_loss : 0.38095977902412415,p 0.5313253012048192, r 0.7788079470198676, f 0.6316920322291854\n",
      "\n",
      "15\n",
      "epoch 15 train_loss : 0 , val_loss : 0.3464847505092621,p 0.5440970601959869, r 0.7721854304635761, f 0.6383794141801259\n",
      "\n",
      "16\n",
      "epoch 16 train_loss : 0 , val_loss : 0.363036185503006,p 0.5558068163463091, r 0.7596026490066226, f 0.6419177315548923\n",
      "\n",
      "17\n",
      "epoch 17 train_loss : 0 , val_loss : 0.39411407709121704,p 0.5043992301347264, r 0.8099337748344371, f 0.621653676719756\n",
      "\n",
      "18\n",
      "epoch 18 train_loss : 0 , val_loss : 0.3622194528579712,p 0.5516159397552557, r 0.776158940397351, f 0.6449009537784299\n",
      "\n",
      "19\n",
      "epoch 19 train_loss : 0 , val_loss : 0.39088666439056396,p 0.4957541447634452, r 0.8119205298013245, f 0.6156163695706753\n",
      "\n",
      "20\n",
      "epoch 20 train_loss : 0 , val_loss : 0.341292142868042,p 0.5683910932529717, r 0.7494481236203091, f 0.646481957535942\n",
      "\n",
      "21\n",
      "epoch 21 train_loss : 0 , val_loss : 0.41806700825691223,p 0.49563230748555304, r 0.8141280353200883, f 0.6161557096316098\n",
      "\n",
      "22\n",
      "epoch 22 train_loss : 0 , val_loss : 0.3608154058456421,p 0.5348975348975349, r 0.7951434878587197, f 0.6395596590909091\n",
      "\n",
      "23\n",
      "epoch 23 train_loss : 0 , val_loss : 0.36049261689186096,p 0.5644422636571802, r 0.7618101545253864, f 0.6484404359263435\n",
      "\n",
      "24\n",
      "epoch 24 train_loss : 0 , val_loss : 0.3766113221645355,p 0.5112139052425007, r 0.8050772626931567, f 0.6253429355281206\n",
      "\n",
      "25\n",
      "epoch 25 train_loss : 0 , val_loss : 0.33975300192832947,p 0.5569537506128452, r 0.752317880794702, f 0.640060099539863\n",
      "\n",
      "26\n",
      "epoch 26 train_loss : 0 , val_loss : 0.36990422010421753,p 0.5315758117366697, r 0.7878587196467991, f 0.6348274635361082\n",
      "\n",
      "27\n",
      "epoch 27 train_loss : 0 , val_loss : 0.3867984712123871,p 0.5115887062789718, r 0.8039735099337748, f 0.6252897244398661\n",
      "\n",
      "28\n",
      "epoch 28 train_loss : 0 , val_loss : 0.3964552581310272,p 0.5072825634623388, r 0.8072847682119205, f 0.6230513672374137\n",
      "\n",
      "29\n",
      "epoch 29 train_loss : 0 , val_loss : 0.37139445543289185,p 0.5209003215434084, r 0.7867549668874172, f 0.6268026732325009\n",
      "\n",
      "30\n",
      "epoch 30 train_loss : 0 , val_loss : 0.37335845828056335,p 0.5336196682464455, r 0.795364238410596, f 0.6387165396206346\n",
      "\n",
      "31\n",
      "epoch 31 train_loss : 0 , val_loss : 0.34381893277168274,p 0.5559924504561182, r 0.7803532008830022, f 0.6493387215282879\n",
      "\n",
      "32\n",
      "epoch 32 train_loss : 0 , val_loss : 0.33306729793548584,p 0.5965192683359971, r 0.7415011037527593, f 0.6611553980907391\n",
      "\n",
      "33\n",
      "epoch 33 train_loss : 0 , val_loss : 0.38898560404777527,p 0.5097379851478212, r 0.8030905077262693, f 0.6236393245907259\n",
      "\n",
      "34\n",
      "epoch 34 train_loss : 0 , val_loss : 0.41746899485588074,p 0.47876004592422505, r 0.828476821192053, f 0.6068396798447733\n",
      "\n",
      "35\n",
      "epoch 35 train_loss : 0 , val_loss : 0.3412508964538574,p 0.5398028809704322, r 0.7858719646799117, f 0.6400000000000001\n",
      "\n",
      "36\n",
      "epoch 36 train_loss : 0 , val_loss : 0.376173198223114,p 0.5050560262366767, r 0.8158940397350993, f 0.6239027683997299\n",
      "\n",
      "37\n",
      "epoch 37 train_loss : 0 , val_loss : 0.3904450535774231,p 0.5010845986984815, r 0.8158940397350993, f 0.6208634302032588\n",
      "\n",
      "38\n",
      "epoch 38 train_loss : 0 , val_loss : 0.39227521419525146,p 0.5142494356659142, r 0.804635761589404, f 0.6274746083663281\n",
      "\n",
      "39\n",
      "epoch 39 train_loss : 0 , val_loss : 0.34833472967147827,p 0.5455666923670007, r 0.7810154525386314, f 0.6423967317294598\n",
      "\n",
      "40\n",
      "epoch 40 train_loss : 0 , val_loss : 0.36035647988319397,p 0.5488241706899237, r 0.7779249448123621, f 0.6435941923112044\n",
      "\n",
      "41\n",
      "epoch 41 train_loss : 0 , val_loss : 0.3761287331581116,p 0.5251339997102709, r 0.8002207505518764, f 0.6341292749059739\n",
      "\n",
      "42\n",
      "epoch 42 train_loss : 0 , val_loss : 0.3679119050502777,p 0.5340267459138187, r 0.7933774834437086, f 0.6383658969804619\n",
      "\n",
      "43\n",
      "epoch 43 train_loss : 0 , val_loss : 0.35774359107017517,p 0.556120826709062, r 0.7721854304635761, f 0.6465804066543438\n",
      "\n",
      "44\n",
      "epoch 44 train_loss : 0 , val_loss : 0.41421738266944885,p 0.45768956501069646, r 0.8501103752759381, f 0.5950247218788629\n",
      "\n",
      "45\n",
      "epoch 45 train_loss : 0 , val_loss : 0.3667318522930145,p 0.5453697949036669, r 0.7748344370860927, f 0.640160496078789\n",
      "\n",
      "46\n",
      "epoch 46 train_loss : 0 , val_loss : 0.40409204363822937,p 0.49707840739230874, r 0.807505518763797, f 0.6153587349650939\n",
      "\n",
      "47\n",
      "epoch 47 train_loss : 0 , val_loss : 0.35101211071014404,p 0.539601667438629, r 0.7715231788079471, f 0.6350504224584356\n",
      "\n",
      "48\n",
      "epoch 48 train_loss : 0 , val_loss : 0.32527002692222595,p 0.5960170697012802, r 0.7399558498896247, f 0.6602324207208982\n",
      "\n",
      "49\n",
      "epoch 49 train_loss : 0 , val_loss : 0.3279167115688324,p 0.5794102431453699, r 0.7417218543046358, f 0.6505954109787975\n",
      "\n",
      "50\n",
      "epoch 50 train_loss : 0 , val_loss : 0.36034780740737915,p 0.5389845874886673, r 0.7874172185430464, f 0.639935414424112\n",
      "\n",
      "51\n",
      "epoch 51 train_loss : 0 , val_loss : 0.32749828696250916,p 0.5886287625418061, r 0.7381898454746136, f 0.6549799236117911\n",
      "\n",
      "52\n",
      "epoch 52 train_loss : 0 , val_loss : 0.3821961283683777,p 0.5201033888569787, r 0.7995584988962472, f 0.630241865321037\n",
      "\n",
      "53\n",
      "epoch 53 train_loss : 0 , val_loss : 0.3048473000526428,p 0.6011307678278315, r 0.7275938189845474, f 0.6583441526016178\n",
      "\n",
      "54\n",
      "epoch 54 train_loss : 0 , val_loss : 0.35803040862083435,p 0.5395390872119296, r 0.7907284768211921, f 0.6414182111200645\n",
      "\n",
      "55\n",
      "epoch 55 train_loss : 0 , val_loss : 0.35931816697120667,p 0.5594138260592545, r 0.7752759381898455, f 0.6498889711324944\n",
      "\n",
      "56\n",
      "epoch 56 train_loss : 0 , val_loss : 0.3691253960132599,p 0.5509187169106198, r 0.7810154525386314, f 0.6460920379839299\n",
      "\n",
      "57\n",
      "epoch 57 train_loss : 0 , val_loss : 0.36830049753189087,p 0.5316176470588235, r 0.7980132450331126, f 0.6381288614298323\n",
      "\n",
      "58\n",
      "epoch 58 train_loss : 0 , val_loss : 0.35923948884010315,p 0.5473484848484849, r 0.7655629139072848, f 0.6383213694091663\n",
      "\n",
      "59\n",
      "epoch 59 train_loss : 0 , val_loss : 0.32067662477493286,p 0.5929251212066798, r 0.7289183222958058, f 0.6539261313001287\n",
      "\n",
      "60\n",
      "epoch 60 train_loss : 0 , val_loss : 0.3318083584308624,p 0.5744255744255744, r 0.7615894039735099, f 0.6548974943052391\n",
      "\n",
      "61\n",
      "epoch 61 train_loss : 0 , val_loss : 0.3567622900009155,p 0.5606060606060606, r 0.7759381898454746, f 0.6509259259259259\n",
      "\n",
      "62\n",
      "epoch 62 train_loss : 0 , val_loss : 0.41167721152305603,p 0.4795827502862231, r 0.8322295805739515, f 0.6085061738358486\n",
      "\n",
      "63\n",
      "epoch 63 train_loss : 0 , val_loss : 0.36168763041496277,p 0.5295324637256339, r 0.7975717439293598, f 0.6364837487888664\n",
      "\n",
      "64\n",
      "epoch 64 train_loss : 0 , val_loss : 0.3894052505493164,p 0.5021899808376676, r 0.8099337748344371, f 0.6199729638391349\n",
      "\n",
      "65\n",
      "epoch 65 train_loss : 0 , val_loss : 0.40833526849746704,p 0.5037707390648567, r 0.811037527593819, f 0.6215004651949589\n",
      "\n",
      "66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66 train_loss : 0 , val_loss : 0.3780016601085663,p 0.515868517993766, r 0.8037527593818985, f 0.6284086986537799\n",
      "\n",
      "67\n",
      "epoch 67 train_loss : 0 , val_loss : 0.4208879768848419,p 0.4801745155909149, r 0.8260485651214128, f 0.6073196461900511\n",
      "\n",
      "68\n",
      "epoch 68 train_loss : 0 , val_loss : 0.3697068691253662,p 0.5349408692981109, r 0.7688741721854304, f 0.6309211122180962\n",
      "\n",
      "69\n",
      "epoch 69 train_loss : 0 , val_loss : 0.3786676526069641,p 0.5206552706552706, r 0.8068432671081678, f 0.6329004329004329\n",
      "\n",
      "70\n",
      "epoch 70 train_loss : 0 , val_loss : 0.3990011513233185,p 0.5207552608820986, r 0.7975717439293598, f 0.6301011510289501\n",
      "\n",
      "71\n",
      "epoch 71 train_loss : 0 , val_loss : 0.35115301609039307,p 0.5356931279620853, r 0.7984547461368653, f 0.6411983690834958\n",
      "\n",
      "72\n",
      "epoch 72 train_loss : 0 , val_loss : 0.33077138662338257,p 0.5573109785587619, r 0.7631346578366446, f 0.6441814963197615\n",
      "\n",
      "73\n",
      "epoch 73 train_loss : 0 , val_loss : 0.37020185589790344,p 0.5252273393957172, r 0.7905077262693156, f 0.6311244272118435\n",
      "\n",
      "74\n",
      "epoch 74 train_loss : 0 , val_loss : 0.3916158080101013,p 0.5165021156558534, r 0.8083885209713024, f 0.6302925989672978\n",
      "\n",
      "75\n",
      "epoch 75 train_loss : 0 , val_loss : 0.33634087443351746,p 0.5650459921156373, r 0.7593818984547461, f 0.647956300621586\n",
      "\n",
      "76\n",
      "epoch 76 train_loss : 0 , val_loss : 0.3529245853424072,p 0.543547651618787, r 0.7894039735099337, f 0.6438023224412638\n",
      "\n",
      "77\n",
      "epoch 77 train_loss : 0 , val_loss : 0.36937031149864197,p 0.5326312666864432, r 0.7927152317880795, f 0.6371540099361249\n",
      "\n",
      "78\n",
      "epoch 78 train_loss : 0 , val_loss : 0.38892510533332825,p 0.5030583118118799, r 0.8169977924944812, f 0.6226970640195172\n",
      "\n",
      "79\n",
      "epoch 79 train_loss : 0 , val_loss : 0.3491351902484894,p 0.5544073900109597, r 0.7816777041942605, f 0.6487130163964459\n",
      "\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "weight_dir='./2features_winlossone2+채팅_undersampling/'\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "with open(weight_dir+'train_result','a') as f:\n",
    "    f.write('=====result=======\\n')\n",
    "f1_best=0\n",
    "for epoch in range(200):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for i, (g,inputs,labels) in enumerate(train_loader):\n",
    "        inputs=inputs.float()\n",
    "        inputs=inputs.cuda()\n",
    "        labels=labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out=model(inputs)\n",
    "        out=out.cuda()\n",
    "        loss=criterion(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    val_losses=AverageMeter()\n",
    "    acc=0\n",
    "    gt_sum=0\n",
    "    tp_sum=0\n",
    "    fp_sum=0\n",
    "    fn_sum=0\n",
    "    acc=0\n",
    "    sum=0\n",
    "    pred_sum=0\n",
    "    with open(weight_dir+'train_result','a') as f:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "                inputs=inputs.float()\n",
    "                inputs=inputs.cuda()\n",
    "                labels=labels.cuda()\n",
    "                out=model(inputs)\n",
    "                out=out.cuda()\n",
    "                loss=criterion(out,labels)\n",
    "                val_losses.update(loss,labels.size(0))\n",
    "                TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(out.cpu(),labels.cpu())\n",
    "                tp_sum += TP\n",
    "                fp_sum += FP\n",
    "                fn_sum += FN\n",
    "                pred_sum += pred_len\n",
    "                gt_sum += gt_len\n",
    "                acc=acc+TP+TN\n",
    "                sum+=len(out)\n",
    "            if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "                precision = tp_sum/(tp_sum+fp_sum)\n",
    "                recall = tp_sum / (tp_sum+fn_sum)\n",
    "                f1 = (2*precision*recall / (precision + recall))\n",
    "                accuracy=acc/sum\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "                if f1_best<f1:\n",
    "                    f.write(\"== best epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+\"best\"))\n",
    "                    f1_best=f1\n",
    "\n",
    "            else:\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))                \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 2 25 0 tensor(7) tensor(5)\n",
      "8 0 23 1 tensor(8) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 23 0 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 16 16 tensor(0) tensor(16)\n",
      "15 0 15 2 tensor(15) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 6 14 2 tensor(16) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 14 18 tensor(0) tensor(18)\n",
      "0 4 20 8 tensor(4) tensor(8)\n",
      "0 22 10 0 tensor(22) tensor(0)\n",
      "13 1 18 0 tensor(14) tensor(13)\n",
      "6 25 1 0 tensor(31) tensor(6)\n",
      "3 0 27 2 tensor(3) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 9 10 0 tensor(22) tensor(13)\n",
      "3 6 23 0 tensor(9) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 0 15 12 tensor(5) tensor(17)\n",
      "4 5 16 7 tensor(9) tensor(11)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 0 19 6 tensor(7) tensor(13)\n",
      "17 8 1 6 tensor(25) tensor(23)\n",
      "10 8 14 0 tensor(18) tensor(10)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 2 0 29 tensor(3) tensor(30)\n",
      "0 28 4 0 tensor(28) tensor(0)\n",
      "8 2 19 3 tensor(10) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 3 17 0 tensor(15) tensor(12)\n",
      "9 10 13 0 tensor(19) tensor(9)\n",
      "14 0 13 5 tensor(14) tensor(19)\n",
      "9 0 23 0 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 0 10 5 tensor(17) tensor(22)\n",
      "17 15 0 0 tensor(32) tensor(17)\n",
      "28 4 0 0 tensor(32) tensor(28)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "17 6 9 0 tensor(23) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 10 4 0 tensor(28) tensor(18)\n",
      "6 5 20 1 tensor(11) tensor(7)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "8 22 2 0 tensor(30) tensor(8)\n",
      "4 0 22 6 tensor(4) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 6 16 0 tensor(16) tensor(10)\n",
      "18 3 11 0 tensor(21) tensor(18)\n",
      "4 7 20 1 tensor(11) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 7 9 0 tensor(23) tensor(16)\n",
      "25 1 6 0 tensor(26) tensor(25)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 3 18 0 tensor(14) tensor(11)\n",
      "18 5 9 0 tensor(23) tensor(18)\n",
      "15 8 6 3 tensor(23) tensor(18)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "14 15 3 0 tensor(29) tensor(14)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "26 0 6 0 tensor(26) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 24 0 tensor(8) tensor(7)\n",
      "15 0 17 0 tensor(15) tensor(15)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "5 1 26 0 tensor(6) tensor(5)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "17 1 14 0 tensor(18) tensor(17)\n",
      "4 7 20 1 tensor(11) tensor(5)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 2 21 0 tensor(11) tensor(9)\n",
      "11 13 6 2 tensor(24) tensor(13)\n",
      "9 0 22 1 tensor(9) tensor(10)\n",
      "0 24 8 0 tensor(24) tensor(0)\n",
      "11 9 12 0 tensor(20) tensor(11)\n",
      "12 7 13 0 tensor(19) tensor(12)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 7 22 0 tensor(10) tensor(3)\n",
      "17 7 5 3 tensor(24) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 10 16 0 tensor(16) tensor(6)\n",
      "5 0 27 0 tensor(5) tensor(5)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "27 4 1 0 tensor(31) tensor(27)\n",
      "25 4 3 0 tensor(29) tensor(25)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "12 17 3 0 tensor(29) tensor(12)\n",
      "19 11 2 0 tensor(30) tensor(19)\n",
      "6 21 5 0 tensor(27) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 5 20 0 tensor(12) tensor(7)\n",
      "23 3 6 0 tensor(26) tensor(23)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "2 1 29 0 tensor(3) tensor(2)\n",
      "24 0 3 5 tensor(24) tensor(29)\n",
      "14 14 2 2 tensor(28) tensor(16)\n",
      "16 9 7 0 tensor(25) tensor(16)\n",
      "19 13 0 0 tensor(32) tensor(19)\n",
      "11 0 21 0 tensor(11) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 3 28 0 tensor(4) tensor(1)\n",
      "18 0 14 0 tensor(18) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 0 27 3 tensor(2) tensor(5)\n",
      "17 0 5 10 tensor(17) tensor(27)\n",
      "12 6 14 0 tensor(18) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 0 5 6 tensor(21) tensor(27)\n",
      "21 4 7 0 tensor(25) tensor(21)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 17 15 tensor(0) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 4 15 8 tensor(9) tensor(13)\n",
      "0 0 18 14 tensor(0) tensor(14)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 2 22 0 tensor(10) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 16 16 tensor(0) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 8 12 tensor(12) tensor(24)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "6 0 16 10 tensor(6) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 2 20 2 tensor(10) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "7 6 13 6 tensor(13) tensor(13)\n",
      "10 5 17 0 tensor(15) tensor(10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 21 11 0 tensor(21) tensor(0)\n",
      "0 21 11 0 tensor(21) tensor(0)\n",
      "14 8 10 0 tensor(22) tensor(14)\n",
      "5 1 20 6 tensor(6) tensor(11)\n",
      "10 7 15 0 tensor(17) tensor(10)\n",
      "2 8 22 0 tensor(10) tensor(2)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 8 9 0 tensor(23) tensor(15)\n",
      "9 1 22 0 tensor(10) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "3 19 10 0 tensor(22) tensor(3)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "20 1 11 0 tensor(21) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "29 2 1 0 tensor(31) tensor(29)\n",
      "11 3 17 1 tensor(14) tensor(12)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 2 9 0 tensor(23) tensor(21)\n",
      "17 1 5 9 tensor(18) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 0 30 0 tensor(2) tensor(2)\n",
      "20 0 12 0 tensor(20) tensor(20)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 0 27 0 tensor(5) tensor(5)\n",
      "24 1 7 0 tensor(25) tensor(24)\n",
      "7 4 21 0 tensor(11) tensor(7)\n",
      "10 2 20 0 tensor(12) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "23 4 4 1 tensor(27) tensor(24)\n",
      "0 5 10 17 tensor(5) tensor(17)\n",
      "22 0 7 3 tensor(22) tensor(25)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "6 0 26 0 tensor(6) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "22 2 8 0 tensor(24) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 0 13 0 tensor(19) tensor(19)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 0 4 11 tensor(17) tensor(28)\n",
      "8 18 6 0 tensor(26) tensor(8)\n",
      "17 15 0 0 tensor(32) tensor(17)\n",
      "4 2 26 0 tensor(6) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 2 22 0 tensor(10) tensor(8)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "13 6 13 0 tensor(19) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 6 20 0 tensor(12) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 0 15 7 tensor(10) tensor(17)\n",
      "13 1 18 0 tensor(14) tensor(13)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 0 18 4 tensor(10) tensor(14)\n",
      "5 19 8 0 tensor(24) tensor(5)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 3 25 0 tensor(7) tensor(4)\n",
      "17 12 3 0 tensor(29) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 2 25 1 tensor(6) tensor(5)\n",
      "21 11 0 0 tensor(32) tensor(21)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "14 0 18 0 tensor(14) tensor(14)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "20 0 9 3 tensor(20) tensor(23)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "21 8 0 3 tensor(29) tensor(24)\n",
      "10 0 21 1 tensor(10) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 13 4 0 tensor(28) tensor(15)\n",
      "12 15 5 0 tensor(27) tensor(12)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 0 30 1 tensor(1) tensor(2)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 26 6 0 tensor(26) tensor(0)\n",
      "7 3 21 1 tensor(10) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 1 16 2 tensor(14) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "14 17 1 0 tensor(31) tensor(14)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 5 19 0 tensor(13) tensor(8)\n",
      "18 14 0 0 tensor(32) tensor(18)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "17 11 0 4 tensor(28) tensor(21)\n",
      "29 3 0 0 tensor(32) tensor(29)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "31 0 0 1 tensor(31) tensor(32)\n",
      "12 12 8 0 tensor(24) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 21 11 0 tensor(21) tensor(0)\n",
      "25 7 0 0 tensor(32) tensor(25)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "20 0 11 1 tensor(20) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 0 23 8 tensor(1) tensor(9)\n",
      "30 0 2 0 tensor(30) tensor(30)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "14 2 15 1 tensor(16) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 3 19 0 tensor(13) tensor(10)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 3 21 1 tensor(10) tensor(8)\n",
      "0 20 12 0 tensor(20) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 22 1 tensor(9) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "12 9 11 0 tensor(21) tensor(12)\n",
      "2 3 27 0 tensor(5) tensor(2)\n",
      "5 0 26 1 tensor(5) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 9 14 tensor(9) tensor(23)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "5 14 13 0 tensor(19) tensor(5)\n",
      "6 0 23 3 tensor(6) tensor(9)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 2 27 3 tensor(2) tensor(3)\n",
      "7 20 5 0 tensor(27) tensor(7)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 1 15 0 tensor(17) tensor(16)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "6 4 22 0 tensor(10) tensor(6)\n",
      "6 0 26 0 tensor(6) tensor(6)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "10 7 15 0 tensor(17) tensor(10)\n",
      "30 0 0 2 tensor(30) tensor(32)\n",
      "4 2 26 0 tensor(6) tensor(4)\n",
      "13 0 17 2 tensor(13) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 17 5 0 tensor(27) tensor(10)\n",
      "3 1 28 0 tensor(4) tensor(3)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 3 29 tensor(0) tensor(29)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 16 9 7 tensor(16) tensor(7)\n",
      "0 0 4 28 tensor(0) tensor(28)\n",
      "9 6 17 0 tensor(15) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "4 4 24 0 tensor(8) tensor(4)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "6 2 20 4 tensor(8) tensor(10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 17 12 tensor(3) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 11 18 0 tensor(14) tensor(3)\n",
      "13 0 9 10 tensor(13) tensor(23)\n",
      "0 8 15 9 tensor(8) tensor(9)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 12 20 tensor(0) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 23 0 tensor(9) tensor(9)\n",
      "7 17 8 0 tensor(24) tensor(7)\n",
      "0 4 26 2 tensor(4) tensor(2)\n",
      "13 10 0 9 tensor(23) tensor(22)\n",
      "26 6 0 0 tensor(32) tensor(26)\n",
      "8 0 24 0 tensor(8) tensor(8)\n",
      "23 8 1 0 tensor(31) tensor(23)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 0 13 4 tensor(15) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "7 3 22 0 tensor(10) tensor(7)\n",
      "12 6 14 0 tensor(18) tensor(12)\n",
      "2 1 29 0 tensor(3) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 5 8 1 tensor(23) tensor(19)\n",
      "2 14 16 0 tensor(16) tensor(2)\n",
      "17 0 13 2 tensor(17) tensor(19)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 32 0 0 tensor(32) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 0 3 13 tensor(16) tensor(29)\n",
      "13 0 19 0 tensor(13) tensor(13)\n",
      "4 18 10 0 tensor(22) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "13 15 4 0 tensor(28) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 8 5 0 tensor(27) tensor(19)\n",
      "24 5 3 0 tensor(29) tensor(24)\n",
      "3 0 29 0 tensor(3) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 1 12 0 tensor(20) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "9 10 13 0 tensor(19) tensor(9)\n",
      "13 7 12 0 tensor(20) tensor(13)\n",
      "21 11 0 0 tensor(32) tensor(21)\n",
      "17 1 14 0 tensor(18) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "11 4 17 0 tensor(15) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 8 21 0 tensor(11) tensor(3)\n",
      "15 5 12 0 tensor(20) tensor(15)\n",
      "6 4 19 3 tensor(10) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "20 0 7 5 tensor(20) tensor(25)\n",
      "15 0 9 8 tensor(15) tensor(23)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "6 15 11 0 tensor(21) tensor(6)\n",
      "10 14 8 0 tensor(24) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "23 0 8 1 tensor(23) tensor(24)\n",
      "12 20 0 0 tensor(32) tensor(12)\n",
      "3 12 16 1 tensor(15) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 4 12 0 tensor(20) tensor(16)\n",
      "8 0 17 7 tensor(8) tensor(15)\n",
      "12 2 18 0 tensor(14) tensor(12)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "12 2 18 0 tensor(14) tensor(12)\n",
      "1 7 24 0 tensor(8) tensor(1)\n",
      "3 1 26 2 tensor(4) tensor(5)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 3 8 2 tensor(22) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 20 12 0 tensor(20) tensor(0)\n",
      "24 8 0 0 tensor(32) tensor(24)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "3 5 24 0 tensor(8) tensor(3)\n",
      "24 0 3 5 tensor(24) tensor(29)\n",
      "8 0 21 3 tensor(8) tensor(11)\n",
      "1 30 0 1 tensor(31) tensor(2)\n",
      "7 25 0 0 tensor(32) tensor(7)\n",
      "13 0 19 0 tensor(13) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "1 6 25 0 tensor(7) tensor(1)\n",
      "20 12 0 0 tensor(32) tensor(20)\n",
      "22 10 0 0 tensor(32) tensor(22)\n",
      "12 1 19 0 tensor(13) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 2 9 0 tensor(23) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 1 20 2 tensor(10) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 3 20 0 tensor(12) tensor(9)\n",
      "7 1 24 0 tensor(8) tensor(7)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 8 14 0 tensor(18) tensor(10)\n",
      "29 3 0 0 tensor(32) tensor(29)\n",
      "22 10 0 0 tensor(32) tensor(22)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 21 11 0 tensor(21) tensor(0)\n",
      "0 32 0 0 tensor(32) tensor(0)\n",
      "16 8 8 0 tensor(24) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 2 7 7 tensor(18) tensor(23)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "23 0 0 9 tensor(23) tensor(32)\n",
      "27 4 0 1 tensor(31) tensor(28)\n",
      "1 0 30 1 tensor(1) tensor(2)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "8 24 0 0 tensor(32) tensor(8)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "21 0 11 0 tensor(21) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "6 0 25 1 tensor(6) tensor(7)\n",
      "3 0 29 0 tensor(3) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 5 15 0 tensor(17) tensor(12)\n",
      "5 1 26 0 tensor(6) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "20 0 7 5 tensor(20) tensor(25)\n",
      "19 4 9 0 tensor(23) tensor(19)\n",
      "13 5 14 0 tensor(18) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 0 15 6 tensor(11) tensor(17)\n",
      "24 2 6 0 tensor(26) tensor(24)\n",
      "0 25 7 0 tensor(25) tensor(0)\n",
      "18 12 2 0 tensor(30) tensor(18)\n",
      "8 9 8 7 tensor(17) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "29 1 0 2 tensor(30) tensor(31)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 1 12 2 tensor(18) tensor(19)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "8 6 18 0 tensor(14) tensor(8)\n",
      "26 6 0 0 tensor(32) tensor(26)\n",
      "6 4 22 0 tensor(10) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 3 22 0 tensor(10) tensor(7)\n",
      "7 4 21 0 tensor(11) tensor(7)\n",
      "18 14 0 0 tensor(32) tensor(18)\n",
      "30 1 1 0 tensor(31) tensor(30)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 6 8 1 tensor(23) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 2 22 0 tensor(10) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 8 11 3 tensor(18) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 7 23 0 tensor(9) tensor(2)\n",
      "1 0 30 1 tensor(1) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 0 11 10 tensor(11) tensor(21)\n",
      "4 4 23 1 tensor(8) tensor(5)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 2 26 0 tensor(6) tensor(4)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "19 4 0 9 tensor(23) tensor(28)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 1 8 6 tensor(18) tensor(23)\n",
      "1 1 17 13 tensor(2) tensor(14)\n",
      "6 2 24 0 tensor(8) tensor(6)\n",
      "7 7 18 0 tensor(14) tensor(7)\n",
      "29 3 0 0 tensor(32) tensor(29)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "22 10 0 0 tensor(32) tensor(22)\n",
      "7 10 15 0 tensor(17) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 4 22 0 tensor(10) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "21 8 3 0 tensor(29) tensor(21)\n",
      "8 7 17 0 tensor(15) tensor(8)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "16 16 0 0 tensor(32) tensor(16)\n",
      "26 0 6 0 tensor(26) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 0 10 21 tensor(1) tensor(22)\n",
      "25 0 3 4 tensor(25) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "1 0 30 1 tensor(1) tensor(2)\n",
      "0 18 14 0 tensor(18) tensor(0)\n",
      "17 2 13 0 tensor(19) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 4 21 1 tensor(10) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 2 28 0 tensor(4) tensor(2)\n",
      "5 0 26 1 tensor(5) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 4 5 22 tensor(5) tensor(23)\n",
      "11 4 17 0 tensor(15) tensor(11)\n",
      "2 5 25 0 tensor(7) tensor(2)\n",
      "5 1 26 0 tensor(6) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 23 0 tensor(9) tensor(8)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "6 16 10 0 tensor(22) tensor(6)\n",
      "10 6 14 2 tensor(16) tensor(12)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 1 19 tensor(12) tensor(31)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "9 23 0 0 tensor(32) tensor(9)\n",
      "25 0 7 0 tensor(25) tensor(25)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 5 9 0 tensor(23) tensor(18)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 19 5 tensor(8) tensor(13)\n",
      "21 0 10 1 tensor(21) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "19 0 6 7 tensor(19) tensor(26)\n",
      "0 11 19 2 tensor(11) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 17 3 tensor(12) tensor(15)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "5 0 26 1 tensor(5) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "14 13 0 5 tensor(27) tensor(19)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "0 28 4 0 tensor(28) tensor(0)\n",
      "7 5 20 0 tensor(12) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "24 7 0 1 tensor(31) tensor(25)\n",
      "12 6 14 0 tensor(18) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 5 19 0 tensor(13) tensor(8)\n",
      "12 10 10 0 tensor(22) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "23 8 1 0 tensor(31) tensor(23)\n",
      "21 7 4 0 tensor(28) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 7 17 0 tensor(15) tensor(8)\n",
      "17 15 0 0 tensor(32) tensor(17)\n",
      "23 1 0 8 tensor(24) tensor(31)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "3 9 20 0 tensor(12) tensor(3)\n",
      "30 0 0 2 tensor(30) tensor(32)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 1 12 0 tensor(20) tensor(19)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "25 7 0 0 tensor(32) tensor(25)\n",
      "10 4 18 0 tensor(14) tensor(10)\n",
      "23 2 7 0 tensor(25) tensor(23)\n",
      "8 3 21 0 tensor(11) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 0 11 3 tensor(18) tensor(21)\n",
      "13 7 12 0 tensor(20) tensor(13)\n",
      "21 4 7 0 tensor(25) tensor(21)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 8 21 0 tensor(11) tensor(3)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "27 5 0 0 tensor(32) tensor(27)\n",
      "11 0 21 0 tensor(11) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 6 13 0 tensor(19) tensor(13)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "9 0 23 0 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 0 14 0 tensor(18) tensor(18)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "30 0 1 1 tensor(30) tensor(31)\n",
      "17 1 10 4 tensor(18) tensor(21)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "8 0 24 0 tensor(8) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 1 22 1 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 7 17 0 tensor(15) tensor(8)\n",
      "12 0 17 3 tensor(12) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "23 0 6 3 tensor(23) tensor(26)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 22 10 0 tensor(22) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 0 10 3 tensor(19) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 0 14 3 tensor(15) tensor(18)\n",
      "19 7 4 2 tensor(26) tensor(21)\n",
      "12 7 13 0 tensor(19) tensor(12)\n",
      "12 0 18 2 tensor(12) tensor(14)\n",
      "20 11 1 0 tensor(31) tensor(20)\n",
      "5 6 21 0 tensor(11) tensor(5)\n",
      "4 1 18 9 tensor(5) tensor(13)\n",
      "14 7 11 0 tensor(21) tensor(14)\n",
      "6 3 23 0 tensor(9) tensor(6)\n",
      "6 0 22 4 tensor(6) tensor(10)\n",
      "3 0 29 0 tensor(3) tensor(3)\n",
      "16 7 9 0 tensor(23) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "6 0 14 12 tensor(6) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 3 20 2 tensor(10) tensor(9)\n",
      "0 0 2 30 tensor(0) tensor(30)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "15 0 0 17 tensor(15) tensor(32)\n",
      "29 3 0 0 tensor(32) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 3 7 17 tensor(8) tensor(22)\n",
      "0 32 0 0 tensor(32) tensor(0)\n",
      "5 13 14 0 tensor(18) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "3 0 7 22 tensor(3) tensor(25)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 5 6 0 tensor(26) tensor(21)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 8 15 1 tensor(16) tensor(9)\n",
      "3 10 19 0 tensor(13) tensor(3)\n",
      "1 0 24 7 tensor(1) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 23 9 0 tensor(23) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "2 8 9 13 tensor(10) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 2 29 0 tensor(3) tensor(1)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "1 23 8 0 tensor(24) tensor(1)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "9 5 15 3 tensor(14) tensor(12)\n",
      "20 7 5 0 tensor(27) tensor(20)\n",
      "22 10 0 0 tensor(32) tensor(22)\n",
      "12 5 0 0 tensor(17) tensor(12)\n",
      "5121 3242 1113\n",
      "[1100/1101], prec:0.6123400693531029, recall:0.8214629451395573, f1:70.16510241830514, acc: 0.8763381321520857\n"
     ]
    }
   ],
   "source": [
    "weight_dir='./2features_winlossone2+채팅_undersampling/'\n",
    "\n",
    "\n",
    "test=Mul_data('test')\n",
    "test_loader=torch.utils.data.DataLoader(test,batch_size=32)\n",
    "dataset=weight_dir+'best'\n",
    "checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "pred_sum = 0#model output\n",
    "gt_sum = 0#label\n",
    "tp_sum=0\n",
    "fp_sum=0\n",
    "fn_sum=0\n",
    "acc=0\n",
    "sum=0\n",
    "result={}\n",
    "with torch.no_grad():\n",
    "    for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "        inputs=inputs.float()\n",
    "        labels=labels\n",
    "        output=model(inputs)\n",
    "        TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "        for idx,g in enumerate(game_id):\n",
    "            if g not in result.keys():\n",
    "                result[g]=pred[idx].tolist()\n",
    "            else:\n",
    "                result[g]+=pred[idx].tolist()\n",
    "        print(TP,FP,TN,FN,pred_len, gt_len)\n",
    "        tp_sum += TP\n",
    "        fp_sum += FP\n",
    "        fn_sum += FN\n",
    "        pred_sum += pred_len\n",
    "        gt_sum += gt_len\n",
    "        acc=acc+TP+TN\n",
    "        sum+=len(output)\n",
    "    with open(weight_dir+'/train_result','a') as f:\n",
    "        if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "            precision = tp_sum/(tp_sum+fp_sum)\n",
    "            recall = tp_sum / (tp_sum+fn_sum)\n",
    "            f1 = (2*precision*recall / (precision + recall)) * 100\n",
    "            accuracy=acc/sum\n",
    "            print( tp_sum, fp_sum, fn_sum)\n",
    "            print('[{}/{}], prec:{}, recall:{}, f1:{}, acc: {}'.format(it, len(test_loader), precision, recall, f1,accuracy))\n",
    "            f.write('{}, prec:{}, recall:{}, f1:{}, acc : {}\\n'.format(dataset, precision, recall, f1,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102844212431058132\n",
      "precision : 0.573394495412844, recall : 0.6561679790026247, f1 : 0.6119951040391677, accuracy : 0.8713474025974026\n",
      "102844341902586509\n",
      "precision : 0.5576036866359447, recall : 0.9565217391304348, f1 : 0.7045123726346434, accuracy : 0.9050514499532273\n",
      "102844401152267937\n",
      "precision : 0.5817091454272864, recall : 0.9651741293532339, f1 : 0.725912067352666, accuracy : 0.8719965050240279\n",
      "102844212430927059\n",
      "precision : 0.6458885941644562, recall : 0.7378787878787879, f1 : 0.6888260254596889, accuracy : 0.884301866947147\n",
      "102844412708953395\n",
      "precision : 0.6014851485148515, recall : 0.8804347826086957, f1 : 0.7147058823529412, accuracy : 0.9056420233463035\n",
      "102844212429944013\n",
      "precision : 0.5957446808510638, recall : 0.9056603773584906, f1 : 0.7187165775401069, accuracy : 0.8714565004887586\n",
      "102844341912679064\n",
      "precision : 0.6101694915254238, recall : 0.7964601769911505, f1 : 0.690978886756238, accuracy : 0.9170103092783505\n",
      "102844235753749959\n",
      "precision : 0.5171503957783641, recall : 0.49872773536895676, f1 : 0.5077720207253886, accuracy : 0.8285198555956679\n",
      "102844341908026005\n",
      "precision : 0.5812379110251451, recall : 0.9119878603945372, f1 : 0.7099822799763733, accuracy : 0.8316763798423037\n",
      "102844283023206486\n",
      "precision : 0.5542763157894737, recall : 0.9439775910364145, f1 : 0.6984455958549223, accuracy : 0.8411572052401747\n",
      "102844224147717245\n",
      "precision : 0.6449438202247191, recall : 0.9258064516129032, f1 : 0.7602649006622516, accuracy : 0.9013086150490731\n",
      "102844412704890154\n",
      "precision : 0.6482412060301508, recall : 0.8403908794788274, f1 : 0.7319148936170213, accuracy : 0.9089156626506024\n",
      "102844212430599377\n",
      "precision : 0.5503597122302158, recall : 0.6483050847457628, f1 : 0.595330739299611, accuracy : 0.9109207708779443\n",
      "102844412711443769\n",
      "precision : 0.7454323995127893, recall : 0.9026548672566371, f1 : 0.8165443629086058, accuracy : 0.8919025157232704\n",
      "102844235747982779\n",
      "precision : 0.6513002364066194, recall : 0.76, f1 : 0.7014640356460853, accuracy : 0.8280791788856305\n",
      "==precision : 0.6039291493019564, recall : 0.8220098961478304, f1 : 0.6918243829883808, accuracy : 0.8779524160999923\n"
     ]
    }
   ],
   "source": [
    "def fmeasure2(frames,label):\n",
    "    average = [0,0,0,0,0]\n",
    "    for key in frames.keys():\n",
    "        TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "        FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "        TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "        FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "        if precision==0 and recall == 0:\n",
    "            print('!')\n",
    "        else:\n",
    "            f1 = (2*precision*recall / (precision + recall))\n",
    "            print(key)\n",
    "            print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "            average[0]+= precision\n",
    "            average[1]+= recall\n",
    "            average[2]+= f1\n",
    "            average[3]+= accuracy\n",
    "            average[4]+=1\n",
    "    print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "with open('../../label/label.pickle',\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)\n",
    "fmeasure2(result,real_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=torch.transpose(b,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1380, 0.0111],\n",
       "         [0.8294, 0.4059],\n",
       "         [0.0521, 0.1911]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/chat_feature_pred_128_train.json',\"rb\") as f1:  \n",
    "    chat_result=json.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1654"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chat_result['102844235753356742'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('../data/audio_energy_2_normaized.pickle',\"rb\") as f3:  \n",
    "            audio_result=pickle.load(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.277879204882054e-07"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_result['102844235753356742'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('../data/audio_H.pickle',\"rb\") as f2:  \n",
    "            image_result=pickle.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.3852265775203705,\n",
       " 0.1067245751619339,\n",
       " -0.11002317070960999,\n",
       " 0.062157902866601944,\n",
       " 0.2836480438709259,\n",
       " -0.03488104045391083,\n",
       " -0.06694860011339188,\n",
       " -0.09063947945833206,\n",
       " -0.10282715409994125,\n",
       " -0.06906208395957947,\n",
       " 0.1274995058774948,\n",
       " 0.09727764129638672,\n",
       " -0.048087719827890396,\n",
       " 0.07348133623600006,\n",
       " 0.10109307616949081,\n",
       " 0.07329846173524857,\n",
       " 0.06325926631689072,\n",
       " -0.34434446692466736,\n",
       " 0.10614260286092758,\n",
       " 0.08139932155609131,\n",
       " -0.12833359837532043,\n",
       " 0.09292862564325333,\n",
       " 0.05589735507965088]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['102844294671796427'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "102844212431058132\n",
      "102844341902586509\n",
      "102844401152267937\n",
      "102844212430927059\n",
      "102844412708953395\n",
      "102844212429944013\n",
      "102844341912679064\n",
      "102844235753749959\n",
      "102844341908026005\n",
      "102844283023206486\n",
      "102844224147717245\n",
      "102844412704890154\n",
      "102844212430599377\n",
      "102844412711443769\n",
      "102844235747982779\n"
     ]
    }
   ],
   "source": [
    "weight_dir='./2features_winlossone2+채팅_undersampling/'\n",
    "test=Mul_data('test')\n",
    "test_loader=torch.utils.data.DataLoader(test,batch_size=32)\n",
    "dataset=weight_dir+'best'\n",
    "checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "pred_sum = 0#model output\n",
    "gt_sum = 0#label\n",
    "tp_sum=0\n",
    "fp_sum=0\n",
    "fn_sum=0\n",
    "acc=0\n",
    "sum=0\n",
    "result={}\n",
    "with torch.no_grad():\n",
    "    for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "        inputs=inputs.float()\n",
    "        labels=labels\n",
    "        output=model(inputs)\n",
    "        for idx,g in enumerate(game_id):\n",
    "            if g not in result.keys():\n",
    "                print(g)\n",
    "                result[g]=[output[idx].tolist()]\n",
    "            else:\n",
    "                result[g].append(output[idx].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./2features_winlossone2+채팅_undersampling/lstm_feature_test.json','a') as f:\n",
    "    json.dump(result,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyein",
   "language": "python",
   "name": "hyein"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
