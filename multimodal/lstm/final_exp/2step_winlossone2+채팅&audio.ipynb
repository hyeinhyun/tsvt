{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch.utils.data.sampler as sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class Mul_data(data.Dataset):\n",
    "    def __init__(self,d_type):\n",
    "        self.d_type=d_type\n",
    "        if d_type=='train':\n",
    "            with open('./2features_ent_emd+채팅_undersampling/lstm_feature_train.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        if d_type=='val':\n",
    "            with open('./2features_ent_emd+채팅_undersampling/lstm_feature_val.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        if d_type=='test':\n",
    "            with open('./2features_ent_emd+채팅_undersampling/lstm_feature_test.json',\"rb\") as f1:  \n",
    "                self.chat_result=json.load(f1)\n",
    "        \n",
    "        with open('../../data/video_statistic_features_one2.pickle',\"rb\") as f2:  \n",
    "            self.image_result=pickle.load(f2)\n",
    "        with open('../../data/audio_entropy_emd.pickle',\"rb\") as f3:  \n",
    "            self.audio_result=pickle.load(f3)\n",
    "        with open('../../label/label.pickle',\"rb\") as f4:  \n",
    "            self.real_result=pickle.load(f4)\n",
    "            \n",
    "        if d_type=='train':\n",
    "            self.sample = ['102844412722519367','102844212429550795','102844401151219358','102844401154430631','102844412717014335','102844401153971877','102844224148503678','102844412722847048','102844401152857762','102844412707380528','102844212431516886','102844283027925085','102844412716227901','102844412710001974','102844294670878922','102844294670551241','102844283023599703','102844412704496937','102844235751783874','102844401152071328','102844412709674293','102844401153447587','102844224148896895','102844235746868664','102979081290790284','102844283027531868','102844212431975640','102844401155937960','102844212429092040','102844341906649746','102844412706987311','102844412721339716','102844212430402768','102844341905011343','102844235753356742','102844235750997440','102844412709346612','102844412705217835','102844235752963525','102844412712164667','102844412705545516','102844341912220311','102844341907370644','102844235749424575','102844212429419722','102844294669568199','102844212431779031','102844294666422466','102844224146472059','102844212428895431','102844212429747404','102844235748703677','102844224146930812','102844212430730450','102844294674876621','102844341909598870','102844283020453971','102844294670026952','102844412723174729','102844341904683662','102844283025696858','102844235747261881','102844401154168486','102844235748310460','102844412711836986','102844412723567946','102844235749031358','102844294674286796','102844294666881219','102844412716686654']\n",
    "        if d_type=='val':\n",
    "            self.sample = ['102844294671796427','102844224145685626','102844412717407552','102844235751390657','102844401156069033','102904869420860038','102910307641576395','102844341905404560','102844341906977427','102844212430075086','102844412711116088','102844401153578660','102844294667405508','102844412706659630']\n",
    "        if d_type=='test':\n",
    "            self.sample = ['102844212431058132','102844341902586509','102844401152267937','102844212430927059','102844412708953395','102844212429944013','102844341912679064','102844235753749959','102844341908026005','102844283023206486','102844224147717245','102844412704890154','102844212430599377','102844412711443769','102844235747982779']\n",
    "            \n",
    "        self.WeightedSampling=[]\n",
    "        for i in self.sample:\n",
    "            self.WeightedSampling.extend(copy.copy(self.real_result[str(i)]))\n",
    "        \n",
    "        sampling = np.array(self.WeightedSampling)\n",
    "        neg_idx = np.where(sampling == 0)[0] #general\n",
    "        pos_idx = np.where(sampling == 1)[0] #highlight\n",
    "        sampling = sampling.astype(np.float32)\n",
    "        \n",
    "        sampling.fill(0)\n",
    "        sampling[neg_idx] = len(sampling) / float(len(neg_idx))\n",
    "       # self.WeightedSampling[pos_idx] = len(self.WeightedSampling) / float(len(pos_idx))\n",
    "        sampling[pos_idx] = len(sampling) / float(len(pos_idx))\n",
    "        self.WeightedSampling = sampling\n",
    "\n",
    "        \n",
    "        self.sum=np.insert(np.cumsum([len(self.chat_result[str(i)]) for i in self.sample]),0,0)\n",
    "        print(\"data load fin\")\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sum[-1]\n",
    "    def __getitem__(self,index):\n",
    "            vid=np.histogram(index,self.sum)#sum으로 누적으로 히스토그램이 깔려있음/ 그중에 index의 위치\n",
    "            vid = np.where(vid[0]>0)[0][0]#몇번째 game을 쓸지!\n",
    "            vframe=index-self.sum[vid]#그 게임 안에서의 몇번째 프레임인지\n",
    "            game_id=str(self.sample[vid])\n",
    "\n",
    "            window=[]#batch*7(window size)*3(highlight result)\n",
    "            for idx in range(23): #7 : window size\n",
    "                s_window=[]\n",
    "                if vframe+idx<len(self.chat_result[game_id]):\n",
    "                    s_window+=((self.chat_result[game_id][vframe+idx]))#vframe의 chat\n",
    "#                     s_window+=list(self.audio_result[game_id][(vframe+idx)*10:(vframe+idx+1)*10])#vframe의 audio\n",
    "                    s_window+=[(self.image_result[game_id][vframe+idx])]#vframe의 image\n",
    "                else:\n",
    "                    #s_window=[0,0,0]#padding value\n",
    "                    s_window=[0]*24\n",
    "                window.append(s_window)\n",
    "\n",
    "\n",
    "            label=int(self.real_result[game_id][vframe])\n",
    "            return game_id,np.array(window),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "data load fin\n",
      "('102844412722519367', array([[ 7.81774372e-02, -9.09460038e-02,  7.78204650e-02,\n",
      "         9.61409733e-02,  1.08621843e-01,  1.11259036e-01,\n",
      "         8.87645483e-02,  7.18758106e-02, -1.09420896e-01,\n",
      "         4.75965701e-02, -2.98951436e-02, -6.20251102e-03,\n",
      "         4.93307738e-03,  7.52217099e-02, -4.72272933e-02,\n",
      "         1.06537908e-01,  7.55111203e-02, -5.54302149e-02,\n",
      "         8.91942605e-02,  8.26181173e-02, -2.40726307e-01,\n",
      "        -6.17996342e-02,  9.95216295e-02,  1.37379766e-03],\n",
      "       [ 6.81920797e-02, -7.89245814e-02,  6.62365481e-02,\n",
      "         8.11836347e-02,  9.15589035e-02,  1.00506157e-01,\n",
      "         7.63600469e-02,  6.16151430e-02, -9.27567407e-02,\n",
      "         4.14573923e-02,  5.30841313e-02, -3.88414203e-03,\n",
      "         5.57345152e-03,  6.25080466e-02, -3.85850780e-02,\n",
      "         9.09765288e-02,  6.39608204e-02, -4.57151942e-02,\n",
      "         7.85905272e-02,  7.02649206e-02, -2.31150031e-01,\n",
      "        -5.20319156e-02,  8.43341351e-02,  1.37379766e-03],\n",
      "       [ 5.80033511e-02, -6.69933110e-02,  5.67624010e-02,\n",
      "         6.96476400e-02,  7.91616663e-02,  8.96027237e-02,\n",
      "         6.53401166e-02,  5.28862998e-02, -7.96127617e-02,\n",
      "         3.53417918e-02,  1.59420013e-01, -1.91174785e-03,\n",
      "         5.76631771e-03,  5.20854145e-02, -3.03885452e-02,\n",
      "         7.76674002e-02,  5.36479242e-02, -3.69279310e-02,\n",
      "         6.87343180e-02,  5.89919612e-02, -2.31060579e-01,\n",
      "        -4.26580347e-02,  7.01462403e-02,  2.00727582e-03],\n",
      "       [ 4.84841764e-02, -5.56309856e-02,  4.87228893e-02,\n",
      "         6.04385622e-02,  6.82362020e-02,  7.84859508e-02,\n",
      "         5.51704727e-02,  4.57286127e-02, -6.75759390e-02,\n",
      "         3.09235938e-02,  2.27896631e-01,  4.13946575e-04,\n",
      "         6.21053157e-03,  4.36164178e-02, -2.42901240e-02,\n",
      "         6.50772154e-02,  4.46625985e-02, -2.98827868e-02,\n",
      "         5.98639660e-02,  4.90774810e-02, -2.37071738e-01,\n",
      "        -3.40597779e-02,  5.62900938e-02,  7.20083714e-04],\n",
      "       [ 4.65265587e-02, -5.30940667e-02,  4.92899232e-02,\n",
      "         6.22641556e-02,  6.83861226e-02,  7.48505071e-02,\n",
      "         5.40927164e-02,  4.69567589e-02, -6.66984469e-02,\n",
      "         3.24437208e-02,  2.39965841e-01,  1.83852459e-03,\n",
      "         7.05421111e-03,  4.47998419e-02, -2.57066693e-02,\n",
      "         6.26147017e-02,  4.45028506e-02, -3.10333017e-02,\n",
      "         5.88380806e-02,  4.83117253e-02, -2.49595761e-01,\n",
      "        -3.26679461e-02,  5.27480058e-02,  3.80885601e-03],\n",
      "       [ 3.83548923e-02, -4.33637723e-02,  3.87717858e-02,\n",
      "         4.85413149e-02,  4.79691140e-02,  6.47664145e-02,\n",
      "         4.17154692e-02,  3.80705409e-02, -4.74022292e-02,\n",
      "         2.89459974e-02,  2.38987789e-01,  3.68500291e-03,\n",
      "         7.24824518e-03,  3.43755856e-02, -2.10609995e-02,\n",
      "         4.67314571e-02,  3.42096873e-02, -2.40308400e-02,\n",
      "         4.93673310e-02,  3.77202742e-02, -2.39120722e-01,\n",
      "        -2.57727411e-02,  3.89186330e-02,  4.09334898e-04],\n",
      "       [ 2.00749021e-02, -2.05035079e-02,  1.90602839e-02,\n",
      "         2.29948647e-02,  1.39557114e-02,  4.09658886e-02,\n",
      "         1.66524630e-02,  1.96907613e-02, -1.42694563e-02,\n",
      "         1.85023751e-02,  2.71353900e-01,  6.19346509e-03,\n",
      "         6.27555838e-03,  1.41419396e-02, -9.87040624e-03,\n",
      "         1.67542566e-02,  1.39351450e-02, -8.90370924e-03,\n",
      "         2.88294274e-02,  1.62975062e-02, -2.22484231e-01,\n",
      "        -1.07828127e-02,  1.07131107e-02,  3.73959541e-04],\n",
      "       [-4.10935283e-03,  1.00508779e-02, -5.43320505e-03,\n",
      "        -8.61198641e-03, -2.61503272e-02,  7.90203456e-03,\n",
      "        -1.56820323e-02, -3.97820072e-03,  2.52327006e-02,\n",
      "         3.78710660e-03,  3.12538952e-01,  8.67184531e-03,\n",
      "         4.25279047e-03, -1.13080367e-02,  5.01146773e-03,\n",
      "        -2.08448209e-02, -1.16220713e-02,  1.07550304e-02,\n",
      "         1.66046445e-03, -1.09240534e-02, -2.04102531e-01,\n",
      "         8.67542904e-03, -2.56685670e-02,  6.80625439e-04],\n",
      "       [-2.16229428e-02,  3.10177281e-02, -2.02542413e-02,\n",
      "        -2.39948723e-02, -4.92049269e-02, -1.82799716e-02,\n",
      "        -3.77274118e-02, -1.72237884e-02,  5.06526418e-02,\n",
      "        -4.18515177e-03,  3.10218811e-01,  1.06128072e-02,\n",
      "         2.54611415e-03, -2.44442783e-02,  1.20743550e-02,\n",
      "        -4.58201654e-02, -2.75056195e-02,  2.15013586e-02,\n",
      "        -1.71266571e-02, -2.79073436e-02, -2.20068201e-01,\n",
      "         2.17386093e-02, -5.14545552e-02,  2.94536352e-04],\n",
      "       [-3.88363861e-02,  5.35537302e-02, -3.29210982e-02,\n",
      "        -3.91365848e-02, -6.94702119e-02, -4.62609380e-02,\n",
      "        -5.84531203e-02, -2.96508893e-02,  7.09181353e-02,\n",
      "        -1.31257484e-02,  3.34405303e-01,  1.21064754e-02,\n",
      "         1.45672448e-03, -3.68182585e-02,  1.85651146e-02,\n",
      "        -7.01619163e-02, -4.15395051e-02,  3.04726288e-02,\n",
      "        -3.62593494e-02, -4.42653298e-02, -2.17982441e-01,\n",
      "         3.37891951e-02, -7.62187392e-02,  0.00000000e+00],\n",
      "       [-5.21378480e-02,  7.10637569e-02, -3.95085104e-02,\n",
      "        -4.50095572e-02, -7.80397803e-02, -7.00654685e-02,\n",
      "        -7.24572837e-02, -3.62638049e-02,  8.04546773e-02,\n",
      "        -1.93122104e-02,  3.45874310e-01,  1.29955858e-02,\n",
      "         7.22152414e-04, -4.23272960e-02,  2.11849175e-02,\n",
      "        -8.62489864e-02, -4.94820103e-02,  3.43731679e-02,\n",
      "        -5.05375825e-02, -5.46229370e-02, -2.28219539e-01,\n",
      "         4.21067849e-02, -9.38344896e-02,  5.33461571e-06],\n",
      "       [-6.59204721e-02,  8.90815109e-02, -4.53285314e-02,\n",
      "        -4.97346483e-02, -8.49144235e-02, -9.56181288e-02,\n",
      "        -8.62800553e-02, -4.23648134e-02,  8.75231326e-02,\n",
      "        -2.60362308e-02,  3.55454355e-01,  1.35847991e-02,\n",
      "         2.86700903e-04, -4.71042991e-02,  2.32447553e-02,\n",
      "        -1.02320231e-01, -5.65541685e-02,  3.71294394e-02,\n",
      "        -6.55762926e-02, -6.47001117e-02, -2.36021802e-01,\n",
      "         5.01840077e-02, -1.11123748e-01,  0.00000000e+00],\n",
      "       [-8.31801072e-02,  1.09492533e-01, -5.96362650e-02,\n",
      "        -6.79911822e-02, -1.07863687e-01, -1.22651085e-01,\n",
      "        -1.07444108e-01, -5.68485148e-02,  1.07906640e-01,\n",
      "        -3.66269499e-02,  3.68709862e-01,  1.43104177e-02,\n",
      "        -5.23668656e-04, -6.23156503e-02,  3.16431969e-02,\n",
      "        -1.27834290e-01, -7.13154972e-02,  4.71125282e-02,\n",
      "        -8.59917402e-02, -8.20356235e-02, -2.26260096e-01,\n",
      "         6.19212836e-02, -1.34298667e-01,  4.89267707e-03],\n",
      "       [-9.95994136e-02,  1.29956141e-01, -7.06698075e-02,\n",
      "        -8.19326043e-02, -1.24872848e-01, -1.50889277e-01,\n",
      "        -1.25976473e-01, -6.83271140e-02,  1.22446977e-01,\n",
      "        -4.65176851e-02,  3.86059940e-01,  1.45952720e-02,\n",
      "        -8.73651414e-04, -7.40021914e-02,  3.77449878e-02,\n",
      "        -1.50280327e-01, -8.32331255e-02,  5.42339012e-02,\n",
      "        -1.05011471e-01, -9.69727561e-02, -2.16812924e-01,\n",
      "         7.23242015e-02, -1.55408204e-01,  7.03334808e-06],\n",
      "       [-1.27154350e-01,  1.60874248e-01, -9.73451585e-02,\n",
      "        -1.18834496e-01, -1.68071404e-01, -1.91529691e-01,\n",
      "        -1.61135599e-01, -9.56628695e-02,  1.60096020e-01,\n",
      "        -6.50617182e-02,  4.12803620e-01,  1.54254893e-02,\n",
      "        -2.69187475e-03, -1.04506403e-01,  5.53762317e-02,\n",
      "        -1.92838460e-01, -1.10203050e-01,  7.50507116e-02,\n",
      "        -1.38182312e-01, -1.27084866e-01, -1.83338836e-01,\n",
      "         9.22423676e-02, -1.92245871e-01,  8.92013311e-04],\n",
      "       [-1.44977301e-01,  1.79708019e-01, -1.10131003e-01,\n",
      "        -1.34458438e-01, -1.85947523e-01, -2.20164284e-01,\n",
      "        -1.80591986e-01, -1.09175518e-01,  1.75715566e-01,\n",
      "        -7.63576403e-02,  4.21270013e-01,  1.53530817e-02,\n",
      "        -3.88382515e-03, -1.18951991e-01,  6.42167553e-02,\n",
      "        -2.16632769e-01, -1.23549223e-01,  8.46439153e-02,\n",
      "        -1.58675373e-01, -1.43218786e-01, -1.81002960e-01,\n",
      "         1.03671201e-01, -2.13100359e-01,  8.09907913e-04],\n",
      "       [-1.53876707e-01,  1.87985152e-01, -1.10373981e-01,\n",
      "        -1.30932182e-01, -1.81784779e-01, -2.37770945e-01,\n",
      "        -1.86140344e-01, -1.09996192e-01,  1.71825573e-01,\n",
      "        -8.09281468e-02,  4.18071508e-01,  1.47089250e-02,\n",
      "        -4.14480595e-03, -1.18562654e-01,  6.45357221e-02,\n",
      "        -2.23824561e-01, -1.24391429e-01,  8.33972767e-02,\n",
      "        -1.67767063e-01, -1.46819323e-01, -2.01753661e-01,\n",
      "         1.07172005e-01, -2.19871178e-01,  1.13731623e-03],\n",
      "       [-1.66062757e-01,  1.99657276e-01, -1.14154689e-01,\n",
      "        -1.33628175e-01, -1.84897333e-01, -2.59958535e-01,\n",
      "        -1.96190745e-01, -1.14776038e-01,  1.73348293e-01,\n",
      "        -8.76890048e-02,  4.23191369e-01,  1.45788649e-02,\n",
      "        -4.57151979e-03, -1.23049714e-01,  6.71191514e-02,\n",
      "        -2.36946583e-01, -1.28413185e-01,  8.47407430e-02,\n",
      "        -1.81196764e-01, -1.54301971e-01, -2.05845878e-01,\n",
      "         1.12864487e-01, -2.30998248e-01,  1.30513310e-03],\n",
      "       [-1.77033439e-01,  2.09627315e-01, -1.16748750e-01,\n",
      "        -1.35305181e-01, -1.86323717e-01, -2.80040830e-01,\n",
      "        -2.04540104e-01, -1.18733354e-01,  1.72954440e-01,\n",
      "        -9.36859325e-02,  4.27150190e-01,  1.46282306e-02,\n",
      "        -5.13156317e-03, -1.26798958e-01,  6.91598952e-02,\n",
      "        -2.48319685e-01, -1.30930796e-01,  8.53740796e-02,\n",
      "        -1.93412408e-01, -1.60389766e-01, -2.07947522e-01,\n",
      "         1.17554575e-01, -2.40123913e-01,  6.25550747e-05],\n",
      "       [-1.94150522e-01,  2.24734679e-01, -1.22477740e-01,\n",
      "        -1.41629502e-01, -1.92269519e-01, -3.10229421e-01,\n",
      "        -2.18519360e-01, -1.27044484e-01,  1.75289273e-01,\n",
      "        -1.03395365e-01,  4.35270637e-01,  1.50065012e-02,\n",
      "        -6.48802985e-03, -1.35545626e-01,  7.40112215e-02,\n",
      "        -2.67563522e-01, -1.36146873e-01,  8.85860696e-02,\n",
      "        -2.12874308e-01, -1.70891166e-01, -2.02967525e-01,\n",
      "         1.25386000e-01, -2.54829258e-01,  1.55270100e-04],\n",
      "       [-1.75730586e-01,  2.07558557e-01, -1.06004201e-01,\n",
      "        -1.18894197e-01, -1.65350705e-01, -2.83118516e-01,\n",
      "        -1.96593314e-01, -1.09694637e-01,  1.51829228e-01,\n",
      "        -9.18722153e-02,  4.22966629e-01,  1.43346572e-02,\n",
      "        -4.50968137e-03, -1.15464576e-01,  6.21796399e-02,\n",
      "        -2.39425242e-01, -1.19972833e-01,  7.52811953e-02,\n",
      "        -1.91024601e-01, -1.52298421e-01, -2.17902616e-01,\n",
      "         1.13082357e-01, -2.32657194e-01,  0.00000000e+00],\n",
      "       [-1.57554537e-01,  1.90725267e-01, -9.07268524e-02,\n",
      "        -9.87702385e-02, -1.41096756e-01, -2.55773664e-01,\n",
      "        -1.75610542e-01, -9.38046500e-02,  1.30554006e-01,\n",
      "        -8.09045956e-02,  4.11686867e-01,  1.36714159e-02,\n",
      "        -2.72504543e-03, -9.73146930e-02,  5.14017418e-02,\n",
      "        -2.12589473e-01, -1.04944803e-01,  6.33827448e-02,\n",
      "        -1.69710755e-01, -1.34687379e-01, -2.27430150e-01,\n",
      "         1.01358719e-01, -2.11233467e-01,  1.43289566e-04],\n",
      "       [-1.35222316e-01,  1.69769749e-01, -7.46823028e-02,\n",
      "        -7.91512877e-02, -1.17482781e-01, -2.20559269e-01,\n",
      "        -1.51620105e-01, -7.68759921e-02,  1.10150017e-01,\n",
      "        -6.77815601e-02,  3.99946243e-01,  1.30018769e-02,\n",
      "        -8.28537391e-04, -7.86070228e-02,  4.01690863e-02,\n",
      "        -1.82163432e-01, -8.90551060e-02,  5.15940562e-02,\n",
      "        -1.43935919e-01, -1.14939630e-01, -2.32271135e-01,\n",
      "         8.78526047e-02, -1.86255798e-01,  0.00000000e+00]]), 0)\n"
     ]
    }
   ],
   "source": [
    "train=Mul_data('train')\n",
    "val=Mul_data('val')\n",
    "print(train[100])\n",
    "#sampler1 = torch.utils.data.sampler.WeightedRandomSampler(weights=train.WeightedSampling.tolist(), num_samples=44000)\n",
    "#train_loader=torch.utils.data.DataLoader(train,batch_size=32,sampler=sampler1)\n",
    "train_loader=torch.utils.data.DataLoader(train,batch_size=32)\n",
    "val_loader=torch.utils.data.DataLoader(val,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=24\n",
    "hidden_size=23\n",
    "length=7\n",
    "num_layers=3\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._clf1 = nn.LSTM(input_size, hidden_size,3,batch_first=True)\n",
    "        self._lin = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                 nn.Linear(hidden_size,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.cuda()\n",
    "        hidden = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).cuda() # (num_layers * num_directions, batch, hidden_size)\n",
    "        cell = Variable(torch.zeros(num_layers,x.size(0),hidden_size)).cuda() # (num_layers * num_directions, batch, hidden_size)        out,hidden = self._clf1(x,h0)\n",
    "        out,hidden = self._clf1(x,(hidden,cell))#batch*7*3\n",
    "        out = self._lin(out[:,-1,:])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=LSTM().cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.01,momentum=0.9,weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0 train_loss : 0 , val_loss : 0.2744726240634918,p 0.6687342062945095, r 0.6426048565121413, f 0.655409208600698\n",
      "\n",
      "1\n",
      "epoch 1 train_loss : 0 , val_loss : 0.2749035060405731,p 0.6714351638209506, r 0.6423841059602649, f 0.6565884476534295\n",
      "\n",
      "2\n",
      "epoch 2 train_loss : 0 , val_loss : 0.2815600335597992,p 0.6435792643579265, r 0.6604856512141281, f 0.651922867414751\n",
      "\n",
      "3\n",
      "epoch 3 train_loss : 0 , val_loss : 0.2732354402542114,p 0.6708773541570969, r 0.6448123620309051, f 0.6575866726699684\n",
      "\n",
      "4\n",
      "epoch 4 train_loss : 0 , val_loss : 0.2841683030128479,p 0.6475172567356936, r 0.6419426048565121, f 0.644717880501053\n",
      "\n",
      "5\n",
      "epoch 5 train_loss : 0 , val_loss : 0.2742288410663605,p 0.6788560712611346, r 0.6392935982339956, f 0.6584811277853571\n",
      "\n",
      "6\n",
      "epoch 6 train_loss : 0 , val_loss : 0.28483960032463074,p 0.6340282164666246, r 0.6646799116997792, f 0.6489923483133959\n",
      "\n",
      "7\n",
      "epoch 7 train_loss : 0 , val_loss : 0.2766371965408325,p 0.65608228980322, r 0.6476821192052981, f 0.6518551433014886\n",
      "\n",
      "8\n",
      "epoch 8 train_loss : 0 , val_loss : 0.2772142291069031,p 0.662, r 0.6576158940397351, f 0.6598006644518273\n",
      "\n",
      "9\n",
      "epoch 9 train_loss : 0 , val_loss : 0.27752450108528137,p 0.6867354281602303, r 0.6320088300220751, f 0.6582365789171168\n",
      "\n",
      "10\n",
      "epoch 10 train_loss : 0 , val_loss : 0.2812376618385315,p 0.6442823428448831, r 0.6629139072847682, f 0.6534653465346535\n",
      "\n",
      "11\n",
      "epoch 11 train_loss : 0 , val_loss : 0.27751708030700684,p 0.6796893386679219, r 0.6375275938189845, f 0.6579337054334207\n",
      "\n",
      "12\n",
      "epoch 12 train_loss : 0 , val_loss : 0.27450042963027954,p 0.6684174469056863, r 0.6461368653421633, f 0.6570883376360983\n",
      "\n",
      "13\n",
      "epoch 13 train_loss : 0 , val_loss : 0.27745765447616577,p 0.6614618692011768, r 0.6452538631346578, f 0.6532573471896301\n",
      "\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "weight_dir='./2step_winlossone2+채팅&audio2/'\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "with open(weight_dir+'train_result','a') as f:\n",
    "    f.write('=====result=======\\n')\n",
    "f1_best=0\n",
    "for epoch in range(200):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for i, (g,inputs,labels) in enumerate(train_loader):\n",
    "        inputs=inputs.float()\n",
    "        inputs=inputs.cuda()\n",
    "        labels=labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out=model(inputs)\n",
    "        out=out.cuda()\n",
    "        loss=criterion(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    val_losses=AverageMeter()\n",
    "    acc=0\n",
    "    gt_sum=0\n",
    "    tp_sum=0\n",
    "    fp_sum=0\n",
    "    fn_sum=0\n",
    "    acc=0\n",
    "    sum=0\n",
    "    pred_sum=0\n",
    "    with open(weight_dir+'train_result','a') as f:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for it, (g,inputs,labels) in enumerate(val_loader):\n",
    "                inputs=inputs.float()\n",
    "                inputs=inputs.cuda()\n",
    "                labels=labels.cuda()\n",
    "                out=model(inputs)\n",
    "                out=out.cuda()\n",
    "                loss=criterion(out,labels)\n",
    "                val_losses.update(loss,labels.size(0))\n",
    "                TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(out.cpu(),labels.cpu())\n",
    "                tp_sum += TP\n",
    "                fp_sum += FP\n",
    "                fn_sum += FN\n",
    "                pred_sum += pred_len\n",
    "                gt_sum += gt_len\n",
    "                acc=acc+TP+TN\n",
    "                sum+=len(out)\n",
    "            if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "                precision = tp_sum/(tp_sum+fp_sum)\n",
    "                recall = tp_sum / (tp_sum+fn_sum)\n",
    "                f1 = (2*precision*recall / (precision + recall))\n",
    "                accuracy=acc/sum\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))\n",
    "                if f1_best<f1:\n",
    "                    f.write(\"== best epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,precision,recall,f1))\n",
    "                    torch.save(model.state_dict(),'{}'.format(weight_dir+\"best\"))\n",
    "                    f1_best=f1\n",
    "\n",
    "            else:\n",
    "                print(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                f.write(\"epoch {} train_loss : {} , val_loss : {},p {}, r {}, f {}\\n\".format(epoch,losses.avg,val_losses.avg,0,0,0))\n",
    "                torch.save(model.state_dict(),'{}'.format(weight_dir+str(epoch)+\"train\"))                \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load fin\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 1 26 1 tensor(5) tensor(5)\n",
      "7 0 23 2 tensor(7) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 23 1 tensor(8) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 16 16 tensor(0) tensor(16)\n",
      "12 0 15 5 tensor(12) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 20 4 tensor(8) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 14 18 tensor(0) tensor(18)\n",
      "0 2 22 8 tensor(2) tensor(8)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "10 0 19 3 tensor(10) tensor(13)\n",
      "6 20 6 0 tensor(26) tensor(6)\n",
      "3 0 27 2 tensor(3) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 4 15 0 tensor(17) tensor(13)\n",
      "3 5 24 0 tensor(8) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 24 0 tensor(8) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 19 13 tensor(0) tensor(13)\n",
      "0 7 2 23 tensor(7) tensor(23)\n",
      "10 5 17 0 tensor(15) tensor(10)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 2 30 tensor(0) tensor(30)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "5 2 19 6 tensor(7) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 1 19 0 tensor(13) tensor(12)\n",
      "9 4 19 0 tensor(13) tensor(9)\n",
      "12 0 13 7 tensor(12) tensor(19)\n",
      "8 1 22 1 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 0 10 4 tensor(18) tensor(22)\n",
      "17 11 4 0 tensor(28) tensor(17)\n",
      "28 4 0 0 tensor(32) tensor(28)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 5 10 2 tensor(20) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 4 10 0 tensor(22) tensor(18)\n",
      "6 3 22 1 tensor(9) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "2 20 4 6 tensor(22) tensor(8)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 7 15 0 tensor(17) tensor(10)\n",
      "18 2 12 0 tensor(20) tensor(18)\n",
      "4 3 24 1 tensor(7) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 6 10 0 tensor(22) tensor(16)\n",
      "23 0 7 2 tensor(23) tensor(25)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 5 16 0 tensor(16) tensor(11)\n",
      "17 0 14 1 tensor(17) tensor(18)\n",
      "16 7 7 2 tensor(23) tensor(18)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "5 17 1 9 tensor(22) tensor(14)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "26 0 6 0 tensor(26) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 23 0 tensor(9) tensor(7)\n",
      "15 1 16 0 tensor(16) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 0 27 2 tensor(3) tensor(5)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "14 0 15 3 tensor(14) tensor(17)\n",
      "1 0 27 4 tensor(1) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 0 23 5 tensor(4) tensor(9)\n",
      "13 9 10 0 tensor(22) tensor(13)\n",
      "10 0 22 0 tensor(10) tensor(10)\n",
      "0 20 12 0 tensor(20) tensor(0)\n",
      "11 7 14 0 tensor(18) tensor(11)\n",
      "12 1 19 0 tensor(13) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 17 15 0 tensor(17) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 4 25 0 tensor(7) tensor(3)\n",
      "15 3 9 5 tensor(18) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 23 1 tensor(8) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 4 22 0 tensor(10) tensor(6)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "27 1 4 0 tensor(28) tensor(27)\n",
      "25 7 0 0 tensor(32) tensor(25)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "12 14 6 0 tensor(26) tensor(12)\n",
      "19 8 5 0 tensor(27) tensor(19)\n",
      "6 20 6 0 tensor(26) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 5 20 0 tensor(12) tensor(7)\n",
      "22 1 8 1 tensor(23) tensor(23)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "8 0 24 0 tensor(8) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 0 30 0 tensor(2) tensor(2)\n",
      "26 0 3 3 tensor(26) tensor(29)\n",
      "10 11 5 6 tensor(21) tensor(16)\n",
      "16 0 16 0 tensor(16) tensor(16)\n",
      "19 13 0 0 tensor(32) tensor(19)\n",
      "11 0 21 0 tensor(11) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 2 29 0 tensor(3) tensor(1)\n",
      "17 0 14 1 tensor(17) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 0 27 3 tensor(2) tensor(5)\n",
      "15 0 5 12 tensor(15) tensor(27)\n",
      "12 6 14 0 tensor(18) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 0 5 8 tensor(19) tensor(27)\n",
      "17 3 8 4 tensor(20) tensor(21)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 17 15 tensor(0) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 3 16 8 tensor(8) tensor(13)\n",
      "0 0 18 14 tensor(0) tensor(14)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 24 0 tensor(8) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 16 16 tensor(0) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 0 8 14 tensor(10) tensor(24)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 16 16 tensor(0) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 22 2 tensor(8) tensor(10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "0 3 16 13 tensor(3) tensor(13)\n",
      "10 4 18 0 tensor(14) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "14 8 10 0 tensor(22) tensor(14)\n",
      "6 0 21 5 tensor(6) tensor(11)\n",
      "8 2 20 2 tensor(10) tensor(10)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 8 9 0 tensor(23) tensor(15)\n",
      "9 0 23 0 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 3 29 0 tensor(3) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "3 11 18 0 tensor(14) tensor(3)\n",
      "23 0 0 9 tensor(23) tensor(32)\n",
      "20 0 12 0 tensor(20) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "29 2 1 0 tensor(31) tensor(29)\n",
      "10 1 19 2 tensor(11) tensor(12)\n",
      "0 10 22 0 tensor(10) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "20 1 10 1 tensor(21) tensor(21)\n",
      "7 1 5 19 tensor(8) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "19 0 12 1 tensor(19) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 0 27 0 tensor(5) tensor(5)\n",
      "24 0 8 0 tensor(24) tensor(24)\n",
      "7 1 24 0 tensor(8) tensor(7)\n",
      "10 3 19 0 tensor(13) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "20 0 8 4 tensor(20) tensor(24)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "23 0 7 2 tensor(23) tensor(25)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "6 0 26 0 tensor(6) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "18 0 10 4 tensor(18) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 0 13 0 tensor(19) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 0 4 13 tensor(15) tensor(28)\n",
      "8 11 13 0 tensor(19) tensor(8)\n",
      "17 10 5 0 tensor(27) tensor(17)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 23 1 tensor(8) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "13 6 13 0 tensor(19) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 2 24 0 tensor(8) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 15 8 tensor(9) tensor(17)\n",
      "13 0 19 0 tensor(13) tensor(13)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 0 18 3 tensor(11) tensor(14)\n",
      "5 13 14 0 tensor(18) tensor(5)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 2 26 0 tensor(6) tensor(4)\n",
      "17 7 8 0 tensor(24) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 0 27 0 tensor(5) tensor(5)\n",
      "21 3 8 0 tensor(24) tensor(21)\n",
      "31 0 1 0 tensor(31) tensor(31)\n",
      "14 0 18 0 tensor(14) tensor(14)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 0 9 4 tensor(19) tensor(23)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "20 7 1 4 tensor(27) tensor(24)\n",
      "10 0 21 1 tensor(10) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "15 7 10 0 tensor(22) tensor(15)\n",
      "12 3 17 0 tensor(15) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "26 0 0 6 tensor(26) tensor(32)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 26 6 0 tensor(26) tensor(0)\n",
      "7 1 23 1 tensor(8) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 0 17 3 tensor(12) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 6 12 0 tensor(20) tensor(14)\n",
      "7 0 25 0 tensor(7) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 2 22 1 tensor(9) tensor(8)\n",
      "18 8 6 0 tensor(26) tensor(18)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "17 11 0 4 tensor(28) tensor(21)\n",
      "29 3 0 0 tensor(32) tensor(29)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "30 0 0 2 tensor(30) tensor(32)\n",
      "12 13 7 0 tensor(25) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "25 7 0 0 tensor(32) tensor(25)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 0 11 4 tensor(17) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 0 23 8 tensor(1) tensor(9)\n",
      "28 0 2 2 tensor(28) tensor(30)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "14 2 15 1 tensor(16) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 1 21 0 tensor(11) tensor(10)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 23 1 tensor(8) tensor(8)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 22 2 tensor(8) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "12 9 11 0 tensor(21) tensor(12)\n",
      "2 1 29 0 tensor(3) tensor(2)\n",
      "5 0 26 1 tensor(5) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 9 23 tensor(0) tensor(23)\n",
      "0 0 30 2 tensor(0) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 24 0 tensor(8) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 14 13 0 tensor(19) tensor(5)\n",
      "6 0 23 3 tensor(6) tensor(9)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "3 16 9 4 tensor(19) tensor(7)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 0 16 12 tensor(4) tensor(16)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "6 3 23 0 tensor(9) tensor(6)\n",
      "3 0 26 3 tensor(3) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 6 16 0 tensor(16) tensor(10)\n",
      "30 0 0 2 tensor(30) tensor(32)\n",
      "2 3 25 2 tensor(5) tensor(4)\n",
      "14 0 17 1 tensor(14) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 5 17 0 tensor(15) tensor(10)\n",
      "3 0 29 0 tensor(3) tensor(3)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 0 24 8 tensor(0) tensor(8)\n",
      "0 0 3 29 tensor(0) tensor(29)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 4 28 tensor(0) tensor(28)\n",
      "7 1 22 2 tensor(8) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 23 9 tensor(0) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 4 24 0 tensor(8) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 22 10 tensor(0) tensor(10)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 6 23 0 tensor(9) tensor(3)\n",
      "14 0 9 9 tensor(14) tensor(23)\n",
      "0 6 17 9 tensor(6) tensor(9)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 26 6 tensor(0) tensor(6)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 12 20 tensor(0) tensor(20)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 0 23 3 tensor(6) tensor(9)\n",
      "7 15 10 0 tensor(22) tensor(7)\n",
      "0 3 27 2 tensor(3) tensor(2)\n",
      "0 0 10 22 tensor(0) tensor(22)\n",
      "26 3 3 0 tensor(29) tensor(26)\n",
      "8 0 24 0 tensor(8) tensor(8)\n",
      "20 3 6 3 tensor(23) tensor(23)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 0 13 3 tensor(16) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 24 0 tensor(8) tensor(7)\n",
      "12 5 15 0 tensor(17) tensor(12)\n",
      "2 0 30 0 tensor(2) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 5 8 1 tensor(23) tensor(19)\n",
      "2 9 21 0 tensor(11) tensor(2)\n",
      "9 0 13 10 tensor(9) tensor(19)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 30 2 0 tensor(30) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 0 3 15 tensor(14) tensor(29)\n",
      "12 0 19 1 tensor(12) tensor(13)\n",
      "4 14 14 0 tensor(18) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "13 11 8 0 tensor(24) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 0 13 3 tensor(16) tensor(19)\n",
      "22 0 8 2 tensor(22) tensor(24)\n",
      "3 0 29 0 tensor(3) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 0 13 0 tensor(19) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "6 10 13 3 tensor(16) tensor(9)\n",
      "13 5 14 0 tensor(18) tensor(13)\n",
      "21 11 0 0 tensor(32) tensor(21)\n",
      "17 0 15 0 tensor(17) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "11 5 16 0 tensor(16) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 8 21 0 tensor(11) tensor(3)\n",
      "12 0 17 3 tensor(12) tensor(15)\n",
      "6 2 21 3 tensor(8) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 0 7 6 tensor(19) tensor(25)\n",
      "12 0 9 11 tensor(12) tensor(23)\n",
      "0 15 17 0 tensor(15) tensor(0)\n",
      "6 12 14 0 tensor(18) tensor(6)\n",
      "10 8 14 0 tensor(18) tensor(10)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "24 0 8 0 tensor(24) tensor(24)\n",
      "12 15 5 0 tensor(27) tensor(12)\n",
      "3 12 16 1 tensor(15) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 2 14 0 tensor(18) tensor(16)\n",
      "7 0 17 8 tensor(7) tensor(15)\n",
      "9 0 20 3 tensor(9) tensor(12)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "11 0 20 1 tensor(11) tensor(12)\n",
      "1 5 26 0 tensor(6) tensor(1)\n",
      "4 0 27 1 tensor(4) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "19 3 8 2 tensor(22) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 9 23 0 tensor(9) tensor(0)\n",
      "24 8 0 0 tensor(32) tensor(24)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "3 1 28 0 tensor(4) tensor(3)\n",
      "21 0 3 8 tensor(21) tensor(29)\n",
      "0 0 21 11 tensor(0) tensor(11)\n",
      "0 21 9 2 tensor(21) tensor(2)\n",
      "7 25 0 0 tensor(32) tensor(7)\n",
      "13 0 19 0 tensor(13) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 4 27 0 tensor(5) tensor(1)\n",
      "20 9 3 0 tensor(29) tensor(20)\n",
      "22 5 5 0 tensor(27) tensor(22)\n",
      "12 0 20 0 tensor(12) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 1 10 3 tensor(19) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 0 21 4 tensor(7) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 1 22 0 tensor(10) tensor(9)\n",
      "7 0 25 0 tensor(7) tensor(7)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 7 15 0 tensor(17) tensor(10)\n",
      "23 3 0 6 tensor(26) tensor(29)\n",
      "16 3 7 6 tensor(19) tensor(22)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "0 32 0 0 tensor(32) tensor(0)\n",
      "16 5 11 0 tensor(21) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 1 8 7 tensor(17) tensor(23)\n",
      "0 14 18 0 tensor(14) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 7 25 0 tensor(7) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 4 28 0 tensor(4) tensor(0)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "18 0 0 14 tensor(18) tensor(32)\n",
      "21 4 0 7 tensor(25) tensor(28)\n",
      "1 0 30 1 tensor(1) tensor(2)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "8 24 0 0 tensor(32) tensor(8)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "21 0 11 0 tensor(21) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 0 25 2 tensor(5) tensor(7)\n",
      "3 0 29 0 tensor(3) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "12 3 17 0 tensor(15) tensor(12)\n",
      "5 0 27 0 tensor(5) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "20 0 7 5 tensor(20) tensor(25)\n",
      "19 1 12 0 tensor(20) tensor(19)\n",
      "13 6 13 0 tensor(19) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 0 15 8 tensor(9) tensor(17)\n",
      "24 0 8 0 tensor(24) tensor(24)\n",
      "0 23 9 0 tensor(23) tensor(0)\n",
      "18 12 2 0 tensor(30) tensor(18)\n",
      "8 3 14 7 tensor(11) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "16 1 0 15 tensor(17) tensor(31)\n",
      "0 13 19 0 tensor(13) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 0 13 9 tensor(10) tensor(19)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 24 0 tensor(8) tensor(8)\n",
      "26 6 0 0 tensor(32) tensor(26)\n",
      "6 2 24 0 tensor(8) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 12 20 0 tensor(12) tensor(0)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 24 0 tensor(8) tensor(7)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "18 14 0 0 tensor(32) tensor(18)\n",
      "30 1 1 0 tensor(31) tensor(30)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 4 10 2 tensor(20) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 23 1 tensor(8) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "10 8 11 3 tensor(18) tensor(13)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 5 25 0 tensor(7) tensor(2)\n",
      "1 0 30 1 tensor(1) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 11 21 tensor(0) tensor(21)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "4 0 28 0 tensor(4) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 4 28 tensor(0) tensor(28)\n",
      "0 0 27 5 tensor(0) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 9 23 tensor(0) tensor(23)\n",
      "0 0 18 14 tensor(0) tensor(14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 24 1 tensor(7) tensor(6)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "28 2 1 1 tensor(30) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "22 10 0 0 tensor(32) tensor(22)\n",
      "7 9 16 0 tensor(16) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 1 25 0 tensor(7) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 0 20 1 tensor(11) tensor(12)\n",
      "21 8 3 0 tensor(29) tensor(21)\n",
      "8 6 18 0 tensor(14) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 2 14 0 tensor(18) tensor(16)\n",
      "26 0 6 0 tensor(26) tensor(26)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 10 22 tensor(0) tensor(22)\n",
      "21 0 3 8 tensor(21) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 0 25 0 tensor(7) tensor(7)\n",
      "1 0 30 1 tensor(1) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "17 2 13 0 tensor(19) tensor(17)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 5 27 0 tensor(5) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 2 23 1 tensor(8) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "2 1 29 0 tensor(3) tensor(2)\n",
      "5 0 26 1 tensor(5) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 2 7 23 tensor(2) tensor(23)\n",
      "9 3 18 2 tensor(12) tensor(11)\n",
      "2 3 27 0 tensor(5) tensor(2)\n",
      "5 0 27 0 tensor(5) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 20 12 tensor(0) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 23 1 tensor(8) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "6 10 16 0 tensor(16) tensor(6)\n",
      "9 0 20 3 tensor(9) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 0 1 24 tensor(7) tensor(31)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "9 22 1 0 tensor(31) tensor(9)\n",
      "25 0 7 0 tensor(25) tensor(25)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 3 11 2 tensor(19) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 0 19 6 tensor(7) tensor(13)\n",
      "21 0 10 1 tensor(21) tensor(22)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "18 0 6 8 tensor(18) tensor(26)\n",
      "0 8 22 2 tensor(8) tensor(2)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "11 0 17 4 tensor(11) tensor(15)\n",
      "31 0 0 1 tensor(31) tensor(32)\n",
      "2 0 26 4 tensor(2) tensor(6)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 6 26 0 tensor(6) tensor(0)\n",
      "0 11 2 19 tensor(11) tensor(19)\n",
      "0 0 15 17 tensor(0) tensor(17)\n",
      "0 16 16 0 tensor(16) tensor(0)\n",
      "7 1 24 0 tensor(8) tensor(7)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "23 7 0 2 tensor(30) tensor(25)\n",
      "12 7 13 0 tensor(19) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 6 18 0 tensor(14) tensor(8)\n",
      "12 9 11 0 tensor(21) tensor(12)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 0 28 1 tensor(3) tensor(4)\n",
      "4 1 27 0 tensor(5) tensor(4)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "23 5 4 0 tensor(28) tensor(23)\n",
      "21 4 7 0 tensor(25) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 7 17 0 tensor(15) tensor(8)\n",
      "17 15 0 0 tensor(32) tensor(17)\n",
      "24 1 0 7 tensor(25) tensor(31)\n",
      "0 0 28 4 tensor(0) tensor(4)\n",
      "3 6 23 0 tensor(9) tensor(3)\n",
      "28 0 0 4 tensor(28) tensor(32)\n",
      "0 0 29 3 tensor(0) tensor(3)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "14 0 13 5 tensor(14) tensor(19)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "18 3 4 7 tensor(21) tensor(25)\n",
      "10 1 21 0 tensor(11) tensor(10)\n",
      "23 0 9 0 tensor(23) tensor(23)\n",
      "7 0 24 1 tensor(7) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 0 11 8 tensor(13) tensor(21)\n",
      "13 0 19 0 tensor(13) tensor(13)\n",
      "21 2 9 0 tensor(23) tensor(21)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 3 26 0 tensor(6) tensor(3)\n",
      "23 9 0 0 tensor(32) tensor(23)\n",
      "27 5 0 0 tensor(32) tensor(27)\n",
      "9 0 21 2 tensor(9) tensor(11)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "13 1 18 0 tensor(14) tensor(13)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "9 0 23 0 tensor(9) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 1 13 0 tensor(19) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "29 1 0 2 tensor(30) tensor(31)\n",
      "16 1 10 5 tensor(17) tensor(21)\n",
      "11 0 20 1 tensor(11) tensor(12)\n",
      "7 0 24 1 tensor(7) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 0 23 1 tensor(8) tensor(9)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "8 6 18 0 tensor(14) tensor(8)\n",
      "12 0 17 3 tensor(12) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "24 0 6 2 tensor(24) tensor(26)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "0 2 30 0 tensor(2) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "18 0 10 4 tensor(18) tensor(22)\n",
      "0 1 31 0 tensor(1) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "16 0 14 2 tensor(16) tensor(18)\n",
      "16 6 5 5 tensor(22) tensor(21)\n",
      "12 6 14 0 tensor(18) tensor(12)\n",
      "11 0 18 3 tensor(11) tensor(14)\n",
      "20 10 2 0 tensor(30) tensor(20)\n",
      "5 2 25 0 tensor(7) tensor(5)\n",
      "0 2 17 13 tensor(2) tensor(13)\n",
      "14 7 11 0 tensor(21) tensor(14)\n",
      "6 2 24 0 tensor(8) tensor(6)\n",
      "3 0 22 7 tensor(3) tensor(10)\n",
      "2 0 29 1 tensor(2) tensor(3)\n",
      "16 7 9 0 tensor(23) tensor(16)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 31 1 tensor(0) tensor(1)\n",
      "0 0 14 18 tensor(0) tensor(18)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 22 2 tensor(8) tensor(9)\n",
      "0 0 2 30 tensor(0) tensor(30)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 0 32 tensor(0) tensor(32)\n",
      "25 3 0 4 tensor(28) tensor(29)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "5 3 7 17 tensor(8) tensor(22)\n",
      "0 28 4 0 tensor(28) tensor(0)\n",
      "5 10 17 0 tensor(15) tensor(5)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 25 7 tensor(0) tensor(7)\n",
      "0 0 7 25 tensor(0) tensor(25)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "21 0 11 0 tensor(21) tensor(21)\n",
      "31 1 0 0 tensor(32) tensor(31)\n",
      "0 11 21 0 tensor(11) tensor(0)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "3 4 19 6 tensor(7) tensor(9)\n",
      "3 11 18 0 tensor(14) tensor(3)\n",
      "2 0 24 6 tensor(2) tensor(8)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "0 19 13 0 tensor(19) tensor(0)\n",
      "0 8 24 0 tensor(8) tensor(0)\n",
      "2 8 9 13 tensor(10) tensor(15)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "1 1 30 0 tensor(2) tensor(1)\n",
      "32 0 0 0 tensor(32) tensor(32)\n",
      "1 22 9 0 tensor(23) tensor(1)\n",
      "0 0 32 0 tensor(0) tensor(0)\n",
      "7 1 19 5 tensor(8) tensor(12)\n",
      "20 9 3 0 tensor(29) tensor(20)\n",
      "22 10 0 0 tensor(32) tensor(22)\n",
      "12 5 0 0 tensor(17) tensor(12)\n",
      "4623 2056 1611\n",
      "[1100/1101], prec:0.6921694864500674, recall:0.7415784408084697, f1:71.60226128707505, acc: 0.8958741516881051\n"
     ]
    }
   ],
   "source": [
    "weight_dir='./winloss_one2+ent_emd+채팅/'\n",
    "\n",
    "test=Mul_data('test')\n",
    "test_loader=torch.utils.data.DataLoader(test,batch_size=32)\n",
    "dataset=weight_dir+'best'\n",
    "checkpoint=torch.load(dataset,map_location='cuda:0')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "pred_sum = 0#model output\n",
    "gt_sum = 0#label\n",
    "tp_sum=0\n",
    "fp_sum=0\n",
    "fn_sum=0\n",
    "acc=0\n",
    "sum=0\n",
    "result={}\n",
    "with torch.no_grad():\n",
    "    for it, (game_id,inputs,labels) in enumerate(test_loader):\n",
    "        inputs=inputs.float()\n",
    "        labels=labels\n",
    "        output=model(inputs)\n",
    "        TP,FP,TN,FN,pred_len, gt_len,pred=fmeasure(output.cpu(),labels.cpu())\n",
    "        for idx,g in enumerate(game_id):\n",
    "            if g not in result.keys():\n",
    "                result[g]=pred[idx].tolist()\n",
    "            else:\n",
    "                result[g]+=pred[idx].tolist()\n",
    "        print(TP,FP,TN,FN,pred_len, gt_len)\n",
    "        tp_sum += TP\n",
    "        fp_sum += FP\n",
    "        fn_sum += FN\n",
    "        pred_sum += pred_len\n",
    "        gt_sum += gt_len\n",
    "        acc=acc+TP+TN\n",
    "        sum+=len(output)\n",
    "    with open(weight_dir+'/train_result','a') as f:\n",
    "        if tp_sum>0 and fp_sum>0 and fn_sum>0:\n",
    "            precision = tp_sum/(tp_sum+fp_sum)\n",
    "            recall = tp_sum / (tp_sum+fn_sum)\n",
    "            f1 = (2*precision*recall / (precision + recall)) * 100\n",
    "            accuracy=acc/sum\n",
    "            print( tp_sum, fp_sum, fn_sum)\n",
    "            print('[{}/{}], prec:{}, recall:{}, f1:{}, acc: {}'.format(it, len(test_loader), precision, recall, f1,accuracy))\n",
    "            f.write('{}, prec:{}, recall:{}, f1:{}, acc : {}\\n'.format(dataset, precision, recall, f1,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fmeasure(output, target):\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "\n",
    "    #overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    #overlap = overlap.view(-1,1)\n",
    "    TP = len(np.where((pred==1)&(target==1)==True)[0]) # True positive\n",
    "    FP = len(np.where((pred==1)&(target==0)==True)[0]) # Condition positive = TP + FN\n",
    "    TN = len(np.where((pred==0)&(target==0)==True)[0])\n",
    "    FN = len(np.where((pred==0)&(target==1)==True)[0])\n",
    "\n",
    "    \n",
    "    #overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return TP,FP,TN,FN,pred_len, gt_len,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102844212431058132\n",
      "precision : 0.6369426751592356, recall : 0.5249343832020997, f1 : 0.5755395683453237, accuracy : 0.880275974025974\n",
      "102844341902586509\n",
      "precision : 0.6186440677966102, recall : 0.8656126482213439, f1 : 0.7215815485996705, accuracy : 0.9209541627689429\n",
      "102844401152267937\n",
      "precision : 0.6911487758945386, recall : 0.9129353233830846, f1 : 0.7867095391211146, accuracy : 0.9130624726955002\n",
      "102844212430927059\n",
      "precision : 0.7380952380952381, recall : 0.6575757575757576, f1 : 0.6955128205128205, accuracy : 0.9000788850907179\n",
      "102844412708953395\n",
      "precision : 0.7383177570093458, recall : 0.8586956521739131, f1 : 0.7939698492462312, accuracy : 0.9401750972762646\n",
      "102844212429944013\n",
      "precision : 0.6708074534161491, recall : 0.8733153638814016, f1 : 0.7587822014051523, accuracy : 0.8993157380254154\n",
      "102844341912679064\n",
      "precision : 0.6708333333333333, recall : 0.7123893805309734, f1 : 0.6909871244635193, accuracy : 0.9257731958762887\n",
      "102844235753749959\n",
      "precision : 0.6885964912280702, recall : 0.3994910941475827, f1 : 0.5056360708534622, accuracy : 0.8614620938628159\n",
      "102844341908026005\n",
      "precision : 0.6421173762945915, recall : 0.8467374810318664, f1 : 0.7303664921465969, accuracy : 0.8587589989715461\n",
      "102844283023206486\n",
      "precision : 0.5988372093023255, recall : 0.865546218487395, f1 : 0.7079037800687286, accuracy : 0.8608078602620087\n",
      "102844224147717245\n",
      "precision : 0.7099447513812155, recall : 0.8290322580645161, f1 : 0.7648809523809524, accuracy : 0.9138495092693566\n",
      "102844412704890154\n",
      "precision : 0.7432950191570882, recall : 0.6319218241042345, f1 : 0.6830985915492959, accuracy : 0.9132530120481928\n",
      "102844212430599377\n",
      "precision : 0.7301587301587301, recall : 0.5847457627118644, f1 : 0.6494117647058824, accuracy : 0.9361884368308351\n",
      "102844412711443769\n",
      "precision : 0.8051209103840683, recall : 0.8348082595870207, f1 : 0.8196958725561189, accuracy : 0.902122641509434\n",
      "102844235747982779\n",
      "precision : 0.6972222222222222, recall : 0.6924137931034483, f1 : 0.6948096885813149, accuracy : 0.8383431085043989\n",
      "==precision : 0.6920054673888509, recall : 0.7393436800137667, f1 : 0.7052590576357455, accuracy : 0.8976280791345128\n"
     ]
    }
   ],
   "source": [
    "def fmeasure2(frames,label):\n",
    "    average = [0,0,0,0,0]\n",
    "    for key in frames.keys():\n",
    "        TP = len(np.where((np.array(frames[key])==1)&(label[key]==1)==True)[0])\n",
    "        FP = len(np.where((np.array(frames[key])==1)&(label[key]==0)==True)[0])\n",
    "        TN = len(np.where((np.array(frames[key])==0)&(label[key]==0)==True)[0])\n",
    "        FN = len(np.where((np.array(frames[key])==0)&(label[key]==1)==True)[0])\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "        if precision==0 and recall == 0:\n",
    "            print('!')\n",
    "        else:\n",
    "            f1 = (2*precision*recall / (precision + recall))\n",
    "            print(key)\n",
    "            print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "            average[0]+= precision\n",
    "            average[1]+= recall\n",
    "            average[2]+= f1\n",
    "            average[3]+= accuracy\n",
    "            average[4]+=1\n",
    "    print('==precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))\n",
    "with open('../../label/label.pickle',\"rb\") as f4:  \n",
    "    real_result=pickle.load(f4)\n",
    "fmeasure2(result,real_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=torch.transpose(b,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1380, 0.0111],\n",
       "         [0.8294, 0.4059],\n",
       "         [0.0521, 0.1911]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/chat_feature_pred_128_train.json',\"rb\") as f1:  \n",
    "    chat_result=json.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1654"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chat_result['102844235753356742'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('../data/audio_energy_2_normaized.pickle',\"rb\") as f3:  \n",
    "            audio_result=pickle.load(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.277879204882054e-07"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_result['102844235753356742'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        with open('../data/audio_H.pickle',\"rb\") as f2:  \n",
    "            image_result=pickle.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16571"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_result['102844235753356742'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyein",
   "language": "python",
   "name": "hyein"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
